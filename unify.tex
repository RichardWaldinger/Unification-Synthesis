% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%

%\documentclass[runningheads]{llncs}
\documentclass[runningheads]{llncs}
%\usepackage{float}
%\usepackage{geometry}
%\usepackage{showframe}

    %\renewcommand\UrlFont{\color{blue}\rmfamily}
 %   \usepackage[sort&compress,square,semicolon,authoryear]{natbib}
    \usepackage[square,sort,comma,super,authoryear]{natbib}

  \bibliographystyle{apalike}
 % \bibliographystyle{apalike}
% \bibliography{dinat}
   

\usepackage[fleqn]{amsmath}
\usepackage{amsmath, amssymb}
\usepackage{csquotes}
%\usepackage[fleqn]{mathtools}
% \usepackage{mathtools}
\usepackage{graphicx}
%\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{dutchcal}
%\usepackage{stix}
% unify2023/12/08
\usepackage{comment}
%\usepackage{program}
\usepackage{mathabx}
\usepackage{tabularx}
\usepackage{tabulary}
\usepackage{hhline}
\usepackage{mathrsfs}
\usepackage{setspace}
\usepackage{array}
\setlength{\doublerulesep}{2pt}
\renewcommand{\arraystretch}{1.5}
\usepackage[gen]{eurosym}
\usepackage{comment}
\usepackage{expl3}

\usepackage{hyperref}
\usepackage{xcolor}
\hypersetup{
    colorlinks=false,  
    linkcolor=black,
    linkbordercolor=black,
    urlcolor=black,
    allbordercolors={0 0 0},
    pdftitle={Unification Synthesis},
%    pdfpagemode=FullScreen,   
     pdfborderstyle={/S/U/W .1},     
    pdfborder={0 0 .4},
  %   pdfborderstyle={/S/U},
    breaklinks=true
    } 
%\hypersetup{pdfborder={0 0 0}}
%\newenvironment{frcseries}{\fontfamily{frc}\selectfont}{}
%\newcommand{\textfrc}[1]{{\frcseries#1}}


% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% %\renewcommand\UrlFont{\color{blue}\rmfamily}
\DeclareMathOperator{\uand}{\emph{and}\,}
\DeclareMathOperator{\uor}{\emph{or}\,}
\DeclareMathOperator{\unot}{\emph{not}\kern-.0pt}

\DeclareMathOperator{\lowand}{\,\, \raisebox{-9pt}{$\uand$} }

\DeclareMathOperator{\uf}{\emph{f}\,}
%DeclareMathOperator{\uim1plies}{\implies}
\DeclareMathOperator{\uimplies}{\Rightarrow}
\DeclareMathOperator{\uimpliedby}{\Leftarrow}
\DeclareMathOperator{\uiff}{\iff}
\DeclareMathOperator{\uif}{\emph{if}\,}
\DeclareMathOperator{\uthen}{\emph{then}\,}
\DeclareMathOperator{\uelse}{\emph{else}\,}

\DeclareMathOperator{\f}{\mathtt{f}}
\DeclareMathOperator{\unify}{\emph{unify}}
\DeclareMathOperator{\lex}{\emph{lex}}
\DeclareMathOperator{\isatm}{\emph{is-atom}} 
\DeclareMathOperator{\iscnst}{\emph{is-const}} 
\DeclareMathOperator{\isvar}{\emph{is-var}} 
\DeclareMathOperator{\lef}{\emph{left}}
\DeclareMathOperator{\rig}{\emph{right}}
\DeclareMathOperator{\head}{\emph{head}}
\DeclareMathOperator{\tail}{\emph{tail}}
\DeclareMathOperator{\first}{\emph{first}}
\DeclareMathOperator{\rest}{\emph{rest}}
\DeclareMathOperator{\ufirst}{\emph{first}}
\DeclareMathOperator{\usecond}{\emph{second}}
\DeclareMathOperator{\idem}{\emph{idem}}
\DeclareMathOperator{\mgi}{\emph{mgi}}
\DeclareMathOperator{\mgiu}{\emph{mgiu}}
%\DeclareMathOperator{\uu}{\emph{u}(\emph{u}(\ldots)\ldots)}

\DeclareMathOperator{\uu}{\thet{r}}
\DeclareMathOperator{\ul}{\thet{l}}

\DeclareRobustCommand{\loongLleftarrow}{%
  \Lleftarrow\relbar\joinrel\relbar\joinrel
}

\begin{document}
%\tableofcontents
%

\title{Automating the Derivation of \\ Unification Algorithms. }

%
\titlerunning{Automating the Derivation of Unification Algorithms}
\subtitle{A Case Study in Deductive Program Synthesis}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Richard Waldinger\inst{1}\orcidID{0000-0002-4520-3907}}
%
\authorrunning{R. Waldinger}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Artificial Intelligence Center, SRI, Menlo Park, CA 94025, USA 
\email{waldinger@ai.sri.com}\\
\url{\texorpdfstring{https://www.sri.com/bios/richard-j-waldinger}/}
}
%
\maketitle              % typeset the header of the contribution \nobreak
\begin{center}Draft: \today \end{center}
%
%\renewcommand{\if}{\operatorname{if}}
%\renewcommand{\thn}{\operatorname{then}}
%\renewcommand{\and}{\operatorname{and}}
\newcommand{\e}[1]{e_{#1}}
\renewcommand{\d}[1]{d_{#1}}
\newcommand{\E}[1]{E_{#1}}
\newcommand{\ttt}[1]{t_{#1}}
\newcommand{\expsub}[2]{{#1}_{#2}}
\newcommand{\x}[1]{x_{#1}}
\newcommand{\y}[1]{y_{#1}}
\newcommand{\thet}[1]{\theta_{#1}}
\newcommand{\Thet}[1]{\Theta_{#1}}

\newcommand{\bb}[1]{\mathbb{#1}}
%newcommand{\var}[2]${\uppercase{#2}}_{#1}$

\newcommand{\var}[1]{#1}
\newcommand{\varsub}[2]{{#1}_{#2}}
%\newcommand{\cons} {\boldsymbol{\cdot}}
\newcommand{\cons}{\, \,\begin{picture}(-1,1)(-1,-3)\circle*{3} \end{picture}\, \, \, \, }

\newcommand{\addto}{+ \,}
%\newcommand{\addto}{\,\sqbullet\,}
%\newcommand{\isatm}{\operatorname{is-atom}}
 
%\newcommand{\lef}{\operatorname{left}}

%\newcommand{\rig}{\operatorname{right}}
\newcommand{\apply}{\blacktriangleleft}

\newcommand{\compose}{ \blackdiamond }
\newcommand{\fail}{\bot}
\newcommand{\blk}{\ast}
\newcommand{\nil}{\emph{nil}}
\newcommand{\emptysubst}{\{\}}
\newcommand{\moregen}{\succsim_{gen}}
\newcommand{\weakmoregen}{\succsim_{gen^-}}
%\newcommand{\is-subst}[1]{\operatorname{is-subst}{#1}}
\newcommand{\issubst}{\emph{is-subst}}
\newcommand{\isprop}{\emph{is-proper}}
\newcommand{\occursin}{\, \varepsilon \,}
%\newcommand{\occursin}{\, \mathcal{E} \,}
%\newcommand{\occursin}{\, \euro{} \,}
\newcommand{\occurseq}{\, \underline{\varepsilon} \,}
\newcommand{\dom}{\emph{dom}}
\newcommand{\range}{\emph{range}}
\newcommand{\misses}{\emph{misses}}

\newcommand{\size}{\emph{size}}
\newcommand{\vars}{\emph{vars}}
\newcommand{\varssize}{\emph{vars-size}}
\renewcommand{\uiff} {\Leftrightarrow}
\newcommand{\true}{\emph{true}}
\newcommand{\false}{\emph{false}}
\newcommand{\cond}[3]{\emph{if}\,( {#1},\allowbreak \ {#2},\allowbreak \ {#3})}
\newcommand{\repl}[2]{\{{#1}\mapsto{#2}\}}
\newcommand{\ucond}[3]
{\begin{aligned}[t]
&\uif {#1}  \\
&\uthen {#2}\\
&\uelse 
{\begin{aligned}[t]
&\{\unot  ({#1})\} \\
&{#3}
\end{aligned}}
\end{aligned}
}
%\newcommand{}{\emph{u(u(\ldots)\ldots)}}
\setlength{\abovedisplayskip}{2pt}
\setlength{\belowdisplayskip}{2pt}
\setlength{\mathindent}{1cm}
\setlength{\tabcolsep}{10pt}
\newcolumntype{T}{|m{0.26\linewidth}|m{0.26\textwidth}||m{0.28\textwidth}|}
\newcolumntype{V}{ 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\newcolumntype{U}{| Y | Y || Y |}
\newcommand{\SNARK} {\textsc{snark}}
\makeatletter
\newcommand{\vast}{\bBigg@{4}}
\newcommand{\Vast}{\bBigg@{4}}
\makeatother


\begin{abstract}
The unification algorithm has long been a target for program synthesis research, but a fully automatic derivation remains a research goal. In deductive program synthesis, computer programming is phrased as a task in theorem proving; a declarative specification is expressed in logical form and presented to an automatic theorem prover, and a program meeting the specification is extracted from the proof. The correctness of the program is supported by the proof, which also provides an explanation of how the program works. The proof is conducted in an appropriate axiomatic subject-domain theory, which defines the concepts in the specification and the constructs in the target programming language and provides the background knowledge necessary to connect them. \\

For the unification proof, we generalize and automate the manual proof presented in \citep{man:wal}. The new program unifies two given symbolic expressions (s-expressions) relative to a given “environment” substitution. The proof establishes the existence of an output substitution that is a most-general idempotent unifier of the given expressions and is an “extension" of the environment substitution. If no such substitution exists and the expressions are not unifiable, the program is to produce a failure indicator $\bot$. \\
     
     Initially the environment substitution is the empty substitution, which makes no replacements at all;  during execution of recursive calls, the environment substitution records the replacements that have been found so far. \SNARK's own unification algorithm employs an environment, and such algorithms appear in the literature \citep[e.g.,][]{lug}.  In addition to being more efficient, we believe the three-argument algorithm with an environment is easier to synthesize automatically than the two-argument version from the Manna-Waldinger paper.\\

    The proof is conducted relative to an axiomatic theory of expressions and substitutions. The structure of the derived program reflects the proof from which it was extracted. Conditional expressions in the program are obtained from case analysis in the proof; recursion is introduced using well-founded induction, with respect to a well-founded relation axiomatized in the theory. The proof was obtained automatically by the  first-order resolution theorem prover \SNARK\ \citep{sti}. The extracted program, as we remarked, improves on Manna and Waldinger's and contains some novel elements.
\end{abstract}
\keywords{program synthesis \and\
theorem proving \and\
automated deduction \and\
formal methods \and\
mathematical induction \and\
resolution principle\and\
well-founded relation \and\
case analysis \and\
software development \and\
artificial intelligence}



%
%
%
\begin{quote}
  In the literature unification is often treated as a simple and straightforward matter, even though it is recognized as a deep and fundamental concept. However when a thorough presentation is attempted, it is then realized that the matter is fairly subtle and treacherous.
  \\---\citep{las:mah:mar}
 
\end{quote}

\begin{quote}
  You have used the unification algorithm to construct the unification algorithm.  You have achieved precisely nothing!
  \\---[Geoff Sutcliffe, personal communication, 2023]
\end{quote}

\begin{quote}
I'm sorry to write such a long letter---I didn't have time to make it shorter.
\\---[Blaise Pascal, Lettres Provinciales, 1657]
\end{quote}


\section{Introduction}

Program synthesis, the automatic construction of computer programs, was one of the first applications of automated theorem proving and is still one of the most appealing.  Several early researchers  \citep[e.g.,][]{sla, wal:lee, ccg} exhibited the synthesis of simple programs as demonstrations.  The NASA system Amphion  \citep{low} used a theorem prover to construct software for, among other things, the Cassini mission to Saturn.  Yet deductive program synthesis has had little impact on the practice of software engineering, even though it seems as if programming and theorem proving are cognitively similar, and that many of the difficulties software engineers have in program construction are like those mathematicians have in proving theorems. Considering the progress theorem provers have made in recent years, it is natural to wonder how well they can now do in program construction.
     
     In deductive program synthesis, we regard the task of constructing a program as one of proving a theorem.  A given specification describes the purpose of the desired program without giving any indication of the method by which that purpose is to be achieved. For this reason, a correct specification may be easier to construct than a completed program. The specification is phrased as a conjecture, i.e., a potential theorem to be proved, and is submitted to a theorem prover.  For an applicative program, the conjecture typically states the existence of an output entity that, for a given input entity, satisfies the specification.  The proof is conducted with respect to a subject domain theory, an axiomatic theory that defines the concepts of the specification language, the constructs of the target programming language, and the background knowledge necessary to connect them.  The proof is restricted to be sufficiently constructive so that, in proving the existence of a desired output, it is forced to indicate a method for finding such an entity.  That method becomes the basis for an algorithm that is extracted from the proof.  

In this paper, we first provide an introduction to a theory of expressions and substitutions, which serves as the subject domain theory for the derivation. We focus on concepts that play a role in the derivation of unification algorithms.
We then outline how to adapt a resolution-style theorem prover for program synthesis, with special emphasis on the use of case analysis to produce conditional expressions and mathematical induction to produce recursion.  We limit our discussion to the use of a first-order-logic theorem prover to produce applicative (side-effect-free) programs. Our illustrative examples will be taken from the proof-based derivation of a unification algorithm.  

    Unification was introduced to the theorem-proving community as part of the resolution principle  \citep{rob}.  Robinson credited it to  Herbrand's [\citeyear{her}] thesis, but added to its conceptualization. Unification is a process of central importance not just for theorem proving, but also for such applications as logic programming, type checking, and natural language understanding.  Surprisingly, unification algorithms presented in widely used textbooks by highly qualified authors and incorporated into at least one reasoning system are incorrect  \citep{nor}.
    
    We outline \SNARK's derivation proof for a unification algorithm for symbolic expressions.  We present the algorithm extracted from that proof, which contains some novelties discovered by \SNARK.  Finally, we present \SNARK's full proof and derivation.

    Our hope is that this example may serve as an introduction to deductive program synthesis. A reader with some mathematical training should be able to make sense of it without having read the earlier work.
    
 \section{A Theory of Expressions, Substitutions, and Unifiers}   
Our introduction is brisk and  semi-formal, and we omit the proof of some known results, so fasten your seat belts. We do not attempt to survey the entire field; for a more general introduction, see \citep{baa:sny}.  Even people familiar with the theory may want to scan the following section, because we have altered some of the concepts to facilitate the automation of the proofs.

\subsection{Expressions}\label{par:exp} The expressions in this version of the theory are symbolic expressions modeled on the S-expressions of Lisp  \citep{jmc}.  We distinguish between atoms and nonatomic expressions (conses).  The atoms comprise constants $(a, b, c, \ldots)$, and $\nil$ and variables $(\var{W}, \var{X}, \var{Y}, \var{Z})$.  These are characterized by the relations $\iscnst(e)$ and $\isvar(e)$, respectively.
For the unification study, we also include a special constant $\blk$, called the $\emph{black hole}$; this has the properties of an ordinary constant.

A nonatomic expression $ \e{l} \cons e_{2} $ is the cons ($\cons$) of two subexpressions $e_{1}$ and $e_{r}$.   For instance, the constant $a$ and the variable  $\var{X}$ are atomic expressions, and their cons,  $(a \cons \var{X})$, is a nonatomic expression, and so is $(a \cons (a \cons \var{X}))$. We can think of an expression as a binary tree whose tips are atoms. 

\subsubsection{Left and Right Functions.}We define functions $\lef$ and $\rig$ to decompose a nonatomic expression into its respective components. We characterize atomicity by the relation $\isatm$. The left and right functions satisfy the \emph{nonatomic property},
\begin{align*}
&\unot ({\isatm}(e)) \uimplies \\
&\,e =  {\lef}(e) \cons {\rig}(e),
\end{align*} 
\noindent for all expressions $e$, and the \emph{atomic property},
\begin{align*} 
&{\isatm}(e) \uimplies \\
&\unot (e =  \expsub{e}{l} \cons \expsub{e}{r}),
\end{align*} 
\noindent for all expressions $e$, $\expsub{e}{l}$, and $\expsub{e}{r}$.


 Two nonatomic expressions $d$ and $e$ are equal 
if their corresponding left and right components are equal.  That is, $d = e$ provided that $\lef(d) = \lef(e)$ and $\rig(d) = \rig(e).$ It follows that, for any expressions $\e{l}$ and $\e{r}$, 
     $\lef(\e{l} \cons \e{r}) = \e{l}$ and $\rig(\e{l} \cons \e{r}) = \e{r}$. 

\subsubsection{The Occurrence Relations.} For any two expressions $\e{1}$ and $\e{2}$, we write $\e{1}$ \emph{occurs in} $\e{2}$ as  $\e{1} \occurseq \e{2}$ and  $\e{1}$ \emph{occurs properly} in $\e{2}$ as  $\e{1} \occursin \e{2}$. We say that 
$\e{1}$ occurs in $\e{2}$ if $\e{1}$ occurs properly in $\e{2}$ or if they are identical, as expressed in  the \emph{reflexive closure property},
\[ \e{1} \occurseq \e{2} \uiff (\e{1} \occursin \e{2} \uor \e{1} = \e{2}).\]
We shall also call $\occurseq$ and $\occursin$ the \emph{subexpression} and the \emph{proper subexpression} relation, respectively. They satisfy the \emph {atomic property},  that
\begin{align*}
&\isatm(e) \uimplies 
\unot(d \occursin e) 
\end{align*} 
and the \emph{cons property}, that
\begin{align*}
&d  \occursin  (\e{1} \cons \e{2}) \uiff 
(d   \occurseq  \e{1} \uor d  \occurseq  \e{2}),
\end{align*}
for all expressions $d$,  $e_1$, and $e_1$.

\subsubsection{Size and Vars Functions.} We define the \emph{size} of an expression to be the number of nonvariable symbols, including conses, in an expression; that is
\[
\begin{split}
    \size(c) =\, & 1 &&\text{if $c$ is a constant} \\
    \size(v) =\, & 0 &&\text{if $v$ is a variable} \\
    \size(\e{1} \cons \e{2}) =\, & 1 + \size(\e{1}) + \size(\e{2}) &&\text{if $\e{1}$ and $\e{2}$ are expressions.}
    \end{split}
\]
The $\size$ function has been defined so that variables are less than constants.  We can also show that 
  \[\e{1} \occursin \e{2} \uimplies \size(\e{1})  < \size(\e{2}),\]
  for any expressions $\e{1}$ and $\e{2},$
  and hence, if $e$ is a nonatomic expression, that
  \[\begin{aligned}
\size(\lef(e))) &< \size(e) \\
\size(\rig(e))) &< \size(e).
        \end{aligned}\]
We denote by $\vars(\var{e})$ the set of variables that occur in $\var{e}$, defined by
\[\begin{split}
    \vars(v) =\, & \{v\} &&\text{if $v$ is a variable} \\
    \vars(c) =\, & \{\} &&\text{if $c$ is a constant} \\
    \vars(\e{1} \cons \e{2}) =\, & \vars(\e{1}) \cup \vars(\e{2}) &&\text{if $\e{1}$ and $\e{2}$ are expressions.}
    \end{split}
\]
We have the \emph{occurs-subset property} of $\vars$, namely
\[\e{1} \occurseq \e{2} \uimplies \vars(\e{1}) \subseteq \vars(\e{2}),\]
for all expressions $\e{1}$ and $\e{2}$. The subset relation here is not always proper; for example, $x \occursin (x \cons x)$  but 
\[
\begin{aligned}
\vars(x) 
     &= 
  \{x\} \\
    &=  \vars((x \cons x)) \\
\end{aligned}
\] 

\subsubsection{Pairs, Triples, and Tuples.} Imitating Lisp, we sometimes use the \emph{empty tuple}  $\langle \rangle$ as an alternative notation for $\nil$; the \emph{singleton tuple} $\langle e  \rangle$ as an abbreviation for $\e \cons \nil$; the \emph{pair} $\langle \e{1}, \e{2} \rangle$ as an abbreviation for $\e{1} \cons (\e{2} \cons \nil\,)$; and, in general, the \emph{tuple} $\langle \e{1}, \e{2}, \ldots, \e{n} \rangle$ as an abbreviation for $e{1} \cons (\e{2} \cons (\ldots (\e{n} \cons \nil\,)\ldots))$. Tuples of length three are called \emph{triples}. Substitutions distribute over tuples; that is, we have the \emph{distributivity property}, that the result of applying a substitution $\theta$ to the tuple $\langle \e{1}, \e{2}, \ldots, \e{n} \rangle$ is  $\langle \e{1} \apply \theta, \e{2}\apply \theta, \ldots, \e{n}\apply \theta \rangle.$ We can also establish the \emph{vars-union property} of tuples, that 
\[\vars(\langle \e{1}, \e{2}, \ldots, \e{n} \rangle)
= \vars(\e{1}) \cup \vars(\e{2}) \cup \ldots \cup \vars(\e{n}).
\]

When regarding symbolic expressions as tuples, it is conventional to use the symbols $\emph{head}$ and $\emph{tail}$ instead of $\lef$ and $\rig$.  Thus
\[
\begin{split}
\emph{head}(\langle \e{1}, \e{2}, \ldots, \e{n} \rangle) &= \e{1}\\  \emph{tail}(\langle \e{1}, \e{2}, \ldots, \e{n} \rangle) &= \langle \e{2}, \ldots, \e{n} \rangle.
\end{split}\]
We also use $\ufirst$, $\usecond$, etc.  Thus
\[\begin{split}
\ufirst(\langle \e{1}, \e{2}, \ldots, \e{n} \rangle) &= \e{1},  \\ \usecond(\langle \e{1}, \e{2}, \ldots, \e{n} \rangle) &=  \e{2},
\end{split}
\]
etc.

 It is more common to define unification on functional terms, such as $\operatorname{f}(\e{1},\e{2},\allowbreak \ldots, \e{n})$, but this is more complex and gives us no additional computational power; if we take function symbols to be constants we can encode $\emph{f}\,(\e{1},\e{2}, \ldots, \e{n})$ as 
          $(\emph{f} \cons \langle \e{1}, \e{2}, \ldots, \e{n} \rangle),$ that is 
                    $(\emph{f} \cons (\e{1} \cons (\e{2} \ldots \cons \nil)\ldots )),$
          as in Lisp.
   

\subsection{Substitutions}
A substitution $\{\varsub{x}{1} \mapsto \e{1}, \varsub{x}{2} \mapsto \e{2}, \ldots, \varsub{x}{n} \mapsto \e{n}\}$ is a function from expressions to expressions that replaces all occurrences of each variable $\varsub{x}{i}$ with the corresponding term $\e{i}$, where we assume that the $\varsub{x}{i}$'s are distinct and that each variable $\varsub{x}{i}$ is distinct from its corresponding term $\e{i}$.  The replacements are viewed as being performed simultaneously.

We denote by $e \apply \theta$ the result of applying the substitution $\theta$ to the expression $e$; we shall also say that $e \apply \theta$ is an \emph{instance} of $e$ under $\theta$. For example, $(\var{X} \cons (a \cons \var{X})) \apply \{\var{X} \mapsto \var{Y},  \var{Y} \mapsto c\}$ is $(\var{Y} \cons (a \cons \var{Y}))$. Both occurrences of $\var{X}$ are replaced and, because the replacements are done simultaneously, the second replacement $\var{Y} \mapsto c$ has no effect.

Two substitutions are equal if they have the same effect on all expressions;  that is, $\thet{1}=\thet{2}$ provided that, for any expression $e$,  $e \,\apply\, \thet{1} = e\, \apply\, \thet{2}$.  To show equality of  $\thet{1}$ and $\thet{2}$, it suffices to show that they have the same effect on variables; that is, for any variable $\var{x}$, $\var{x} \apply \thet{1} = \var{x} \apply \thet{2}$. For example, $\{\var{X} \mapsto a,  \var{Y} \mapsto b\}$ and $\{\var{Y} \mapsto b,  \var{X} \mapsto a\}$ are equal substitutions.

Applying a substitution to expressions preserves the  subexpression relations; that is 
\begin{align*}
& \e{1} \occursin \e{2} \, \uimplies\\
& (\e{1} \apply \theta) \occursin (\e{2} \apply \theta)
\end{align*} 
and
\begin{align*}
& \e{1} \occurseq \e{2} \, \uimplies\\
& (\e{1} \apply \theta) \occurseq (\e{2} \apply \theta),
\end{align*} 
for all expressions $\e{1}$ and $\e{2}$ and substitutions $\theta$.

By an abuse of notation, we call the set of replaced variables $\{\varsub{x}{1}, \varsub{x}{2},\ldots, \varsub{x}{n}\}$ of a substitution $\theta$ its \emph{domain}, denoted by $\dom(\theta)$;  and the set of variables that occur in the introduced expressions $\e{1}$, $\e{2}$, \ldots, or $\e{n}$ its \emph{range}, denoted by  $\range(\theta)$.  For example, the domain of $\{\var{X} \mapsto (\var{W} \cons a), \var{Y} \mapsto (\var{X} \cons b)\}$ is $\{\var{X}, \var{Y}\}$, and its range is $\{\var{X}, \var{W}\}$. 

A substitution $\theta$ is said to \emph{miss} an expression $e$. written $\misses(\theta, e)$, if applying the substitution has no effect on the expression; that is, if $e \apply \theta = e$. This happens if no variable in the domain of $\theta$ occurs in $e$. The misses relation applied to tuples of expressions satisfies the property
\[\misses(\theta, \langle \e{1}, \ldots \e{n} \rangle) \uiff
 [\misses(\theta, \e{1}) \uand \ldots \uand \misses(\theta, \e{n})],\] 
 for all substitutions $\theta$ and expressions $\e{1}$, \ldots, and $\e{n}$.


The domain and range of a substitution need not be disjoint. 
We have
 $u \in \dom(\theta) \uiff  u \apply \theta \neq u$  and $v \in \range(\theta) \uiff (\exists u)[v \occurseq (u \apply \theta) \uand u \neq v].$  If a variable belongs to the range of a substitution, we also say that the substitution \emph{introduces} the variable. 
 
 % A variable is said to \emph{occur in} (omit???) a substitution if it belongs to its domain or range. We denote the set of all variable that occur in the substitution $\theta$, i.e., the union of the domain and range, by  $\range(\theta).$  

 It can be proved that two substitutions agree on an expression $\var{e}$ if they agree on all the variables of the expression;  that is $\var{e} \apply \thet{1} = \var{e} \apply \thet{2}$ precisely when $ \var{v} \apply \thet{1} = \var{v} \apply \thet{2}$ for all variables $\var{v}$ that occur in $\var{e}.$






The \emph{empty substitution} $\{\}$ makes no replacements at all.  Therefore $e \apply \{\} = e$ for any expression $e$. We introduce one \emph{improper} substitution, the \emph{failure} substitution $\fail$.  This substitution maps any expression into the black hole; that is, $e \apply \bot = \blk$, for any expression $e$. We say that the predicate $\isprop$ holds for any proper substitution; that is, $\isprop(\theta)\uiff(\theta \neq \bot)$. The improper substitution does not follow the axioms for proper substitutions.

To apply a proper substitution to a nonatomic expression, apply it to the components; that is, $ (d \cons e) \apply \theta = (d \apply \theta) \cons (e \apply \theta)$. We call this the \emph{distributivity property}. Equivalently, we say that $e \apply \theta = \lef(e) \cons \rig(e)$ for any non-atomic expression $\e.$  Consequently, the result of applying a proper substitution to a nonatomic expression is nonatomic.  In contrast, the result of applying the improper substitution to any expression is $\blk$, an atomic constant.

\subsubsection{Addition.} The result of adding two substitutions $\thet{1}$ and $\thet{2}$, denoted by $\thet{1} \addto \thet{2}$, is the substitution that applies the replacements in parallel.  If the same variable occurs in the domains of both substitutions, the replacement in the first substitution is applied; the replacement in the second substitution is ignored.  More precisely, for any variable $\var{x}$,
\[\begin{split}
\var{x} \apply (\thet{1}\addto \thet{2})= \, &\var{x} \apply  \thet{1} &&\uif \var{x} \in \dom(\thet{1})  \\
    = \, &\var{x} \apply \thet{2} &&\uif \var{x} \notin \dom(\thet{1}).
\end{split} \]   Addition is not in general commutative.

% The result of adding the replacement $(\var{X} \mapsto e)$ to $\theta$, written $(\var{X} \mapsto e) \addto \theta$ is a substitution that agrees with $\theta$ except that it maps $\var{X}$ to $e$. That is 
% \[\begin{split}
% \var{Y} \apply ((\var{X} \mapsto e)\addto \theta)= \, &e &&\uif \var{X} = \var{Y} \\
%     = \, &\var{Y} \apply \theta &&\uif \var{X} \neq \var{Y}.
% \end{split}\]
%  $(\var{X} \mapsto e) \addto \{\}$  is the replacement $\{\var{X} \mapsto e\}.$

% \subsubsection{Subtraction.} (omit?) If $\theta$ is a substitution and $\var{x}$ is a variable, the substitution $\theta - \var{x}$ is the substitution that agrees with $\theta$ except that it makes no replacement for $\var{x}$.  More precisely, for any variable $\var{y}$,
% \[\begin{split}
% \var{y} \apply (\theta - \var{x})= \, &\var{y} \apply  \theta &&\uif \var{y} \neq \var{x}  \\
%     = \, &\var{y}  &&\uif \var{y} = \var{x}.
% \end{split} \] 
%  if $\var{x}$ is not in $\dom(\theta)$, $\theta - \var{x} = \theta$.

\subsubsection{Replacement.} A substitution that replaces a single variable $x$ with an expression $e$ is itself called a \emph{replacement}, denoted by $\{x \mapsto e\} $.  It satisfies the \emph{replacement identity property}
\[x \apply  \{x \mapsto e\}  = e\]
 and the \emph{replacement non-occur property}
\[d \apply  \{x \mapsto e\}  = d \, \uimpliedby  \,   \unot(x \occurseq d),\]
for all variables $x$ and expressions $d$ and $e$. In other words, a replacement has no effect on an expression if its variable doesn't occur in that expression. We call $x$ the \emph{replaced variable} and $e$ the \emph{introduced expression}.

If $\var{x}$ is a variable, we take $\{\var{x} \mapsto \var{x}\}$ to be the empty substitution $\emptysubst$. 

\subsubsection{Composition.} Applying  the \emph{composition} $\expsub {\theta}{1} \compose \thet{2}$ of two substitutions $\thet{1}$ and $\thet{2}$ has the same effect as applying them sequentially;  that is, we have a \emph{composition property} $e \apply (\thet{1}\! \compose \thet{2}) = (e \apply \thet{1}) \apply \thet{2} $. For example,
$\{\var{X} \mapsto (\var{Y} \cons a)\} \compose \{\var{X} \mapsto b, \var{Y} \mapsto c\} = \{\var{X} \mapsto (c \cons a), \var{Y} \mapsto c\}$.  Here, the replacement $\var{X} \mapsto b$ plays no role in the composition, because $\var{X}$ has already been replaced. Because of the composition property, we can write the application of a composition to an expression as $e \apply \thet{1}\! \compose \thet{2}$, without ambiguity.

The empty substitution \{\} acts as an identity under composition;  that is,  $\theta \compose \{\} = \{\} \compose \theta = \theta$. This holds even if $\theta$ is the improper failure substitution $\fail$. The failure substitution acts as an annihilator; that is,  $\theta \compose \fail = \fail \compose \theta = \fail$.

 Composition is associative; that is, $(\thet{1}\! \compose \thet{2}) \compose \thet{3}  = \thet{1} \compose (\thet{2} \compose \thet{3})$, whether or not the substitutions are proper.   For this reason, we can write the composition of three or more substitutions without parentheses, as in $\thet{1}\! \compose \thet{2} \compose \thet{3}$.

 The domain and range of the composition of two substitutions $\thet{1}$ and $\thet{2}$ satisfy the inclusions 
 $\dom(\thet{1}\! \compose \thet{2})  \subseteq  \dom(\thet{1}) \cup \dom(\thet{2})$ and  $\range(\thet{1}\! \compose \thet{2})  \subseteq  \range(\thet{1}) \cup \range(\thet{2})$, respectively.  We call these the \emph{composition property of domains}  and \emph{ranges}, respectively.
 
 The inclusions cannot be replaced by equalities; consider, for example, the composition $\{\var{X} \mapsto \var{Y}\} \compose \{\var{Y} \mapsto \var{X}\} = \{\var{Y} \mapsto \var{X}\}.$
 The domain of $\{\var{X} \mapsto \var{Y}\}$ is $\{\var{X}\}$ 
 and the domain of $\{\var{Y} \mapsto \var{X}\}$ 
 is $\{\var{Y}\}$, but $\var{X}$ doesn't belong to $\{\var{Y}\}$.  Because $\var{X}$ belongs to 
 \[\dom(\{\var{X} \mapsto \var{Y}\}) \cup \dom(\{\var{Y} \mapsto \var{X}\})\] but not to 
 \[\dom(
 \{\var{X} \mapsto \var{Y}\} 
 \compose 
 \{\var{Y} \mapsto \var{X}\}),\] 
 the two cannot be equal.
 Similarly, the range of  $\{\var{X} \mapsto \var{Y}\}$ is $\{\var{Y}\}$ and the range of $\{\var{Y} \mapsto \var{X}\}$ is $\{\var{X}\}$, but $\var{Y}$ doesn't belong to $\{\var{X}\}$.
% \subsection{Renamings}  A \emph{renaming} is a substitution that replaces all the variables in its domain with distinct variables.  Thus, $\rho$ is a renaming substitution $\{\varsub{x} {1} \mapsto \varsub{y}{1}, \varsub{x}{2} \mapsto \varsub{y}{2}, \ldots \mathbin{,}\varsub{x}{n} \mapsto \varsub{y}{n}\}$ if it never maps two variables in its domain into the same variable; that is, if $\varsub{x}{i}\neq \varsub{x}{j}$ implies $\varsub{y}{i} \neq \varsub{y}{j}$. 

\begin{comment}
\subsubsection{replacement.}

Because the operations in our algorithm are relative to an environment substitution,  We call the composition of an environment substitution and a replacement a \emph{relative replacement}. The lemmas we invoke for the relative replacement operation include 

the \emph{relative replacement identity} property  <<needed?>>
\[
\begin{aligned}
&\e{1} \apply (\thet{0} \compose \{\e{1} \mapsto \e{2} \}) = \e{2} \quad \uimpliedby \\
&\left[\begin{aligned}  
&\isvar(\e{1}) \uand \\
&\misses(\thet{0}, \e{1}) \uand \\
&\e{1} \neq \e{2} \uand \\
&\unot(\e{1} \occursin \e{2})  \uand \\
&\isprop(\thet{0})
\end{aligned}
\right]
\end{aligned}
\]  
 The condition that the environment $\thet{0}$ misses the replaced variable $\e{1}$ is necessary;  if $\thet{0}$ replaced $\e{1}$ by some new constant $b$, the relative replacement would also replace $\e{1}$ by $b$, not $\e{2}$. The condition that $\thet{0}$ is a proper substitution is necessary because otherwise $\e{1} \apply (\thet{0} \compose \{\e{1} \mapsto \e{2} \})$ would be the black hole $\blk$, so the property could be false if $\e{2}$ were anything but the black hole.

We also have 
the \emph{replacement nonoccur property}:

\[
\begin{aligned}
&e \apply (\thet{0} \compose \{\e{1} \mapsto \e{2} \}) = e \quad \uimpliedby \\
&\left[\begin{aligned}  
&\!\isvar(\e{1}) \uand \\
&\misses(\thet{0}, \e{1}) \uand \\
&\!\unot(\e{1} \occurseq e) \uand \\
&\isprop(\thet{0})
\end{aligned}\right]
\end{aligned}
\]

We mention the lemma that applies when the environment substitution misses the replaced variable, because this property plays a role in the derivation of our unification algorithm. 
\end{comment}
\subsubsection{Derangement.}\label{par:der}  Suppose $\theta$ is a substitution and $z$ is a variable in the range but not in the domain of $\theta$. Let $z'$ be a new variable, distinct from $z$ and all the variables in $\theta$. Then, we can construct a substitution $\thet{z'}$, called the \emph{derangement of z by z' in $\theta$}, that agrees with $\theta$ except that it contains $z'$ in its range in place of $z$.   This will turn out to be useful.

Formally we define $\thet{z'}$, the derangement of z by z' in $\theta$, by
\begin{align*}
  & \var{u} \apply \thet{z'} = (\var{u} \apply \theta) \apply \{\var{z} \mapsto \var{z'}\}
 \end{align*}
 for every variable $u$ in $\dom(\theta)$, and
 \begin{align*}
  & \var{u} \apply \thet{z'} = \var{u}  
 \end{align*}
 for every variable $\var{u}$ not in $\dom(\theta)$.

 This means [because $\var{z}$ is not in $\dom(\theta)$] that $\var{z} \apply \thet{z'} = \var{z}$; that is, $\var{z}$ is not in $\dom(\thet{z'}).$ 

 We can then prove the \emph{derangement property}, namely, that 
for any expression $e$ that contains no occurrences of $\var{z}$, 
  \[ e \apply \thet{z'} =  e \apply \theta \compose \{\var{z} \mapsto \var{z'}\}.
 \]
 That is,  applying $\thet{z'}$ yields the same result  as applying $\theta$ except that $\var{z}$  is replaced by $z'$.

The condition that $e$ contains no occurrences of $\var{z}$ is essential;  for instance, if $e$ is $\var{z}$ itself, we have
 $e \apply \thet{z'} = \var{z}$ 
 but 
   \begin{align*}
   e \apply \theta \compose \{\var{z} \mapsto \var{z'}\} 
     & =  \var{z} \apply \theta \apply \{\var{z} \mapsto \var{z'}\}   && \text{[because $e$ is $\var{z}$]} \\
     & =  \var{z} \apply \{\var{z} \mapsto \var{z'}\}   && \text{[because $\var{z}$ is not in $\dom(\theta)$]} \\
     & = \var{z'}                                        \\
     & \neq \var{z}
 \end{align*}
 
 To show that $\thet{z'}$ and $\theta \compose \{\var{z} \mapsto \var{z'}\}$ agree on $e$, it suffices to show that they agree on every variable $\var{u}$ that occurs in $e$; that is 
 \begin{align*}
   \var{u} \apply \thet{z'} = \var{u} \apply \theta \compose \{\var{z} \mapsto \var{z'}\}.  
 \end{align*}
 \noindent When $\var{u}$ is in $\dom(\theta),$ the equality follows from the definition of $\thet{z'}.$  But if $\var{u}$ is not in $\dom(\theta)$, we have
  \begin{align*}
   \var{u} \apply \theta \compose \{\var{z} \mapsto \var{z'}\} 
     & =  \var{u}  \apply \{\var{z} \mapsto \var{z'}\}   && \text{[because  $\var{u}$ is not in $\dom(\theta)$]} \\
     & = \var{u}                                         &&\text{[because $\var{u}$ occurs in $e$  and thus $\var{u} \neq \var{z}$]} \\
     & = \var{u} \apply \thet{z'} && \text{[by definition of $\thet{z'}$].}
 \end{align*}
This completes the proof of the \emph{derangement property}.
 
 



% \subsubsection{Replacement Applied to a Substitution.}  (omit?) For a substitution $\theta$ and variables $\var{x}$ and $\var{y}$, we denote by $\theta \apply \{\var{x} \mapsto \var{y}\}$ the result of replacing every occurrence of $\var{x}$ in $\theta$, whether on the left or the right side of a replacement, with $\var{y}$. 
%  the resulting substitution does not contain $\var{x}$ in either its domain or its range.

\subsubsection{Permutation Substitutions and Standardizing Apart.} A \emph{permutation} substitution merely rearranges the variable in its domain. That is, if $\pi$ is a permutation substitution  
 $\{\varsub{x} {1} \mapsto \e{1}, \varsub{x}{2} \mapsto \e{2}, \ldots, \varsub{x}{n} \mapsto \e{n}\},$ the expressions $\{\e{1}, \e{2}, \ldots, \e{n}\}$ are a permutation of the domain variables $\{\varsub{x}{1},\varsub{x}{2}\mathbin{,}  \ldots,  \varsub{x}{n}\}$. 
Every  permutation substitution $\pi$ has an \emph{inverse}; thus $\pi^{-1}$ is 
 $\{\e{1} \mapsto \varsub{x}{1}, \e{2} \mapsto \varsub{x}{2}, \ldots, \e{n} \mapsto \varsub{x}{n}\}.$ 
 This is a legal substitution because the expressions $\e{1}, \e{2}, \ldots, \e{n}$ are distinct variables. The inverse has the property that $\pi \compose \pi^{-1} = \pi^{-1} \compose \pi = \emptysubst$.  The empty substitution $\emptysubst$ is a permutation.
 
 Two permutation substitutions $\expsub{\pi}{1}$ and $\expsub{\pi}{2}$ \emph{standardize apart} two expressions $\e{1}$ and $\e{2}$ if the results of applying the substitutions to the respective expressions, that is, $\e{1}\apply \expsub{\pi}{1}$ and $\e{2} \apply \expsub{\pi}{2}$, have no variables in common.  It is always possible to standardize apart two expressions.  For instance, suppose  $\varsub{x}{1}$, $\varsub{x}{2}$, $\ldots$ $\varsub{x}{n}$ is a complete list of all the variables that occur in either expression.  Suppose $\varsub{y}{1}$, $\varsub{y}{2}$, $\ldots$ $\varsub{y}{n}$ and $\varsub{z}{1}$, $\varsub{z}{2}$, $\dots$ $\varsub{z}{n}$ are variables that are distinct from each other and from those on the original list of $\varsub{x}{i}$'s.  Then, the two permutation substitutions \[\expsub{\pi}{1}: \{\varsub{x}{1} \mapsto \varsub{y}{1}, \varsub{y}{1} \mapsto \varsub{x}{1}, \varsub{x}{2} \mapsto \varsub{y}{2}, \varsub{y}{2} \mapsto \varsub{x}{2}, \ldots, \varsub{x}{n} \mapsto \varsub{y}{n}, \varsub{y}{n} \mapsto \varsub{x}{n}\}\] and \[\expsub{\pi}{2}:\{\varsub{x}{1} \mapsto \varsub{z}{1}, \varsub{z}{1} \mapsto \varsub{x}{1}, \varsub{x}{2} \mapsto \varsub{z}{2}, \varsub{z}{2} \mapsto \varsub{x}{2}, \ldots, \varsub{x}{n} \mapsto \varsub{z}{n}, \varsub{z}{n} \mapsto \varsub{x}{n}\}\]
 will standardize  $\e{1}$ and $\e{2}$ apart.
 All the variables in $\e{1}\apply \expsub{\pi}{1}$ will be $\varsub{y}{i}$'s, and all the variables in $\e{2} \apply \expsub{\pi}{2}$ will be $\varsub{z}{i}$'s. One can even standardize apart two expressions with a single permutation, by renaming all the variables in one of the expressions to variables that don't occur in the other.
 
\subsubsection{Idempotent Substitutions.}  A substitution $\theta$ is \emph{idempotent}, written $\idem(\theta)$, if applying it twice (or more) has the same effect as applying it once;  that is, if $\theta \compose \theta = \theta$.  For example, the substitution $\{\var{X} \mapsto \var{Y}\}$ is idempotent, because after it has been applied once, all occurrences of $\var{X}$ have been removed from the expression, so subsequent applications have no effect.  On the other hand, the substitution $\{\var{X} \mapsto (\var{X} {\cons} \var{X})\}$ is not idempotent, because each application doubles the number of occurrences of $\var{X}$.
 
 A substitution is idempotent precisely when no variable appears in both its domain and its range.  To see this, suppose $\theta$ is such a substitution.  Then, for any expression $e$, the result $e \apply \theta$ of applying $\theta$ to $e$ contains no variables in the domain of $\theta$.  Hence applying $\theta$ a second time has no effect; that is $(e \apply \theta) \apply \theta = e \apply \theta$ and hence $e \apply (\theta \compose \theta) = e \apply \theta$. Since this holds for any expression $e$, we can conclude that it $\theta \compose \theta = \theta.$

 To show the inverse, suppose some variable $\var y$ is in both the domain and range of $\theta$. Then, because  $\var{y}$ is, in the domain, $\var{y} \apply \theta \neq \var{y}.$  And because $\var{y}$ is in the range, there is a variable $\var{x}$ such that $\var{y} \occurseq (\var{x} \apply \theta).$  Because $\var{y}$ is in its domain, applying $\theta$ again to $\var{x} \apply \theta$ alters $\var{x} \apply \theta$.  In other words, $(\var{x} \apply \theta) \apply \theta \neq \var{x} \apply \theta$;  that is, $\var{x} \apply (\theta \compose \theta) \neq \var{x} \apply \theta$, and therefore $\theta \compose \theta \neq \theta.;$  that is, $\theta$ is not idempotent.
 
 
 
 The empty substitution $\{\}$ is idempotent, but no other permutation substitution is.   The composition of two idempotent unifiers is not necessarily idempotent;  for example, \[\{\var{X} \mapsto \var{Y}\} \compose \{\var{Y} \mapsto (\var{X} {\cons} \var{X})\} = \{\var{X} \mapsto (\var{X} {\cons} \var{X}),\var{Y} \mapsto (\var{X} {\cons} \var{X})\},\] which has $\var{X}$ in both its domain and range.
 
 
\subsubsection{The Vars-Range Subset Properties.} For any expression $\var{e}$ and proper substitution $\theta$, we can informally establish the \emph{vars-range subset property}
\[\vars(\var{e} \apply \theta) \subseteq \vars(\var{e}) \cup \range(\theta).\]
In other words, for a variable to occur in $\var{e} \apply \theta $, it must already occur in $\var{e}$ or it may have been introduced by $\theta.$

In general, the subset relation in the property is not necessarily proper; for instance, if $\theta$ is the empty substitution $\emptysubst$, $\range(\theta)$ is the empty set and both sides of the property reduce to $\vars(\var{e})$.  But if $\theta$ is a proper idempotent substitution that does not miss the expression $\var{e}$, we do have the \emph{vars-range proper-subset property}
\[\vars(\var{e} \apply \theta) \subset \vars(\var{e}) \cup \range(\theta).\]
For, if $\theta$ does not miss $\var{e}$, there is a variable $\var{v}$ that occurs in $\var{e}$ and belongs to $\dom(\theta)$.  Because $\theta$ is idempotent, $\var{v}$ does not belong to $\range(\theta)$ and hence does not occur in $\var{e} \apply \theta$.  Thus $\var{v}$ belongs to the right side of the formula but not the left.
This formulation of the property turns out to be useful in the derivation of unification algorithms.
 
  \subsection{Unifiers}  A substitution $\theta$ is a unifier of two expressions $\e{1}$ and $\e{2}$ if applying it makes them identical, that is, if $\e{1} \apply \theta = \e{2} \apply \theta$. For example, the substitution  $\{\var{X} \mapsto a, \var{Y} \mapsto b\}$ is a  unifier of the expression $(\var{X} \cons b)$ and $(a \cons \var{Y})$ because applying it to either expression maps it into $(a \cons b)$.
 
 Unifiers are not unique. For example,  $\{\var{X} \mapsto a, \var{Y} \mapsto b, \var{Z} \mapsto c\}$ is also  unifier of the expression $(\var{X} \cons b)$ and $(a \cons \var{Y})$.   The third replacement $\var{Z} \mapsto c$ has no effect on either expression.  In fact, if $\theta$ is a unifier of two expressions, the result $\theta \compose \delta$ of composing $\theta$ with any substitution $\delta$ is also a unifier of the two expressions. Hence if two expressions are unifiable, they have an infinite set of unifiers. 
 
 The empty substitution $\emptysubst$ is a unifier of two expressions only if they are already identical.  The improper failure substitution $\fail$, on the other hand,  is a unifier of any two expressions; applying it always yields the black hole $\blk$.
 
 We say that two expressions are \emph{unifiable} if they have a proper unifier, i.e., a unifier other than $\fail$. For example, the two distinct constants $a$ and $b$ are ununifiable, because no proper substitution can make them identical. A constant and a non-atomic expression can never be unifiable, because the result of applying a proper substitution to a constant is the constant itself, an atom, while the result of applying the same substitution to a nonatomic expression is nonatomic. If one expression $\e{1}$ is a proper subexpression of another $\e{2}$, that is, if $\e{1} \occursin \e{2}$, then
 $(\e{1}\apply \theta) \occursin (\e{2}\apply \theta)$; hence the results cannot be equal and the two given expressions are ununifiable.

 For a substitution $\theta$ to unify two nonatomic expressions $\e{1}$ and $\e{2}$, it must unify both their left components and their right components;  that is,

    {$\begin{aligned}
  &\e{1} \apply \theta = \e{2} \apply \theta
  \uiff \\
  &\left[{\begin{aligned}
  &\lef(\e{1}) \apply \theta = \lef(\e{2}) \apply \theta \uand \\
  & \rig(\e{1}) \apply \theta = \rig(\e{2}) \apply \theta
  \end{aligned}} \right].\\[10pt]
\end{aligned}$}
 
 
 
 We have seen that, if two expressions are unifiable, they have an infinite set of different unifiers.  But we want our unification algorithm to yield a unifier that does no unnecessary work. 
 
 \subsubsection{More Generality.}  A substitution $\thet{1}$ is \emph{strongly more general} than substitution $\thet{2}$, written  $\thet{1}$ $ \moregen$ $\thet{2}$, if $\thet{1}\! \compose \thet{2} = \thet{2}$. In this case, we can also say that $\thet{2}$ is an \emph{extension} of $\thet{1}$.  For example, the substitution $\{\var{X} \mapsto \var{Y}\}$ is strongly more general than $\{\var{X} \mapsto A, \var{Y} \mapsto A\}$ because $\{\var{X} \mapsto \var{Y}\} \compose \{\var{X} \mapsto A, \var{Y} \mapsto A\} = \{\var{X} \mapsto A, \var{Y} \mapsto A\}$. 
 
 The empty substitution $\{\}$ is strongly more general than any substitution $\theta$, because $\{\} \compose \, \theta = \theta$. However, no other substitution $\theta$ is strongly more general than the empty substitution, because $\theta \compose $\{\}$= \theta \neq \{\}.$ On the other hand, the failure substitution $\fail$ is not strongly more general than any proper substitution $\theta$, because $\fail \compose \, \theta = \fail \neq \theta.$ But any substitution $\theta$ is strongly more general than the failure substitution, because $\theta \compose \fail = \fail.$

 The strongly more general relation has a \emph{composition property}, namely
 \[\thet{0} \moregen \thet{1} \uimplies \thet{0} \moregen \thet{1}\! \compose \thet{2},\]
for all substitutions $\thet{0}$, $\thet{1}$, and $\thet{2}.$  For if
\[\thet{0} \moregen \thet{1},\]
that is [by the definition of $\moregen$]
\[\thet{0} \compose \thet{1} = \thet{1},\]
then
\[\thet{0} \compose \thet{1}\! \compose \thet{2} = \thet{1}\! \compose \thet{2},\]
that is [by the definition of $\moregen$, again]
\[\thet{0} \moregen \thet{1}\! \compose \thet{2},\]
as we wanted to show.

 If $\theta$ is a unifier of two expressions, then clearly any extension of $\theta$ is also a unifier.  

 \citet{rob} used the term “most-general unifier" for the output of the unification algorithm, but he did not define what it meant for one substitution to be more-general than another.   \citep{man:wal} said that  $\thet{1}$ is more general than $\thet{2}$ if $(\exists \delta)[\thet{1} \compose \, \delta = \thet{2}]$ holds; we call this the weakly more-general relation $\thet{1} \weakmoregen \thet{2}$.  Clearly the strongly more-general relation implies this weakly more-general relation.  When $\thet{1}$ is idempotent, the weakly more-general relation also implies the  strongly more general relation.  To see this, assume that $\thet{1} \weakmoregen \thet{2}$; that is, for some substitution $\delta$,  $\thet{1} \compose \, \delta = \thet{2}$.  Then,  we have 
 \begin{align*}
   \thet{1}\! \compose \thet{2}
     & =  \thet{1} \compose \thet{1} \compose \, \delta  && \text{[by assumption]} \\
     & = \thet{1} \compose \, \delta  && \text{[by idempotence]} \\
     & = \thet{2} && \text{[by assumption, again].}
 \end{align*}
 \noindent Hence $\thet{1} \moregen \thet{2}$, as we wanted to show.

 On the other hand, if $\theta$ is the  permutation $\{\var{X} \mapsto \var{Y}, \allowbreak \var{Y} \mapsto \var{X}\}$, which is not idempotent, we have $\theta \compose \theta = \emptysubst$, and thus $\theta \weakmoregen \emptysubst$; that is,  $\theta$
is  weakly more general than 
$\emptysubst$.  But $\theta \compose \emptysubst = \theta \neq \emptysubst$, and hence it is not true that $\theta \moregen \emptysubst$; that is, $\theta$ is not strongly more general than the empty substitution.

Using the stronger relation allows us to simplify the specification and shorten the proof. In this paper, we will use only the strongly more general relation, sometimes forgetting the “strongly" modifier.


Clearly, a substitution $\theta$ is idempotent precisely when it is (strongly) more  general than itself, that is, $\idem(\theta)$ is equivalent to $ \theta \moregen \theta$, because then $\theta \compose \theta = \theta$. Thus, while the strongly more general relation is not reflexive, it is reflexive on idempotent substitutions. 

The more-general relation can also be shown to be transitive; that is,
\[(\thet{1} \moregen \thet{2} \uand 
\thet{2} \moregen \thet{3}) \uimplies \thet{1} \moregen \thet{3}.\]
For, suppose \[\thet{1} \moregen \thet{2} \uand 
\thet{2} \moregen \thet{3}.\]  
Then, by the definition of $\moregen$, we have \[\thet{1}\! \compose \thet{2} = \thet{2} \uand \thet{2} \compose \thet{3} = \thet{3}.\]  Hence \[\thet{1}\! \compose \thet{2} \compose \thet{3} =  \thet{2} \compose \thet{3}\] [by the supposition that [$\thet{1}\! \compose \thet{2} = \thet{2}$] and thus \[\thet{1} \compose \thet{3} = \thet{3},\] [by the supposition that $\thet{2} \compose \thet{3} = \thet{3}$]. In other words, \[\thet{1} \moregen \thet{3},\] as we wanted to show.

\subsubsection{Relativizing the Definitions.} 
It is remarked that, in a proof by induction, it is sometimes easier to prove a stronger, more general theorem, to have the benefit of a stronger induction hypothesis; this is an instance of what \citet{pol}  termed the \emph{inventor's paradox}, famously exploited by the Boyer-Moore [\citeyear{boy:moo}] theorem prover.  Had we initially specified that we merely wanted to find a unifier of two expressions, we would have been led to require that the unifier be most general.  Then, we would have been led to further require that the unifier be idempotent. We don't know how to automate the generalization of these specifications; we regard this as a \emph{eureka!} step, as in program transformation \citep{bur:dar}. Perhaps a failed inductive proof will give us a hint of how we would like to strengthen the theorem; that is, how would we strengthen the corresponding induction hypothesis to allow the proof to succeed.


We now generalize the specification further. For the current derivation, we have found it better to construct an algorithm that performs unification with respect to an idempotent \emph{environment substitution}.  That is, we search for a unifier that is an extension of a given idempotent substitution $\thet{0}$. This is a strengthening, because, when the environment $\theta$ is the empty substitution $\emptysubst$, it reduces to the original problem, since any substitution is an extension of the empty substitution.  Relative unification requires a more general specification, but a simpler proof gives us a more efficient resulting program.  Indeed, in the implementation of resolution and other rules,  \SNARK\ and other theorem provers perform unification with respect to an environment substitution.


\subsubsection{Most-General Idempotence Relation.}  To specify the relative unification algorithm, it is convenient for us to introduce the relation  ${\mgi} (\thet{0},  \e{1}, \e{2}, \theta)$  to stand for the condition that \emph{the substitution} $\theta$ \emph{is most-general idempotent for the expressions} $\e{1}$ and $\e{2}$ with respect to the environment substitution $\thet{0}$, that is
\begin{align*}
 {\mgi}(&\thet{0}, \e{1}, \e{2}, \theta) \uiff \\
&\begin{aligned}
 (\forall \theta') \left[{
 \begin {aligned} &\e{1} \apply \theta' = \e{2} \apply \theta' \, \uand \,  
  \,\thet{0} \moregen \theta' \,\uimplies\\
                    &\theta \moregen \theta'
   \end{aligned}}
   \right] \end{aligned}
   \end{align*}
The relation does not require $\theta$ to be a unifier of the expressions.

% \begin{align*} 
%  {\mgi}(&\thet{0}, \e{1}, \e{2}, \theta) \uiff \\
% \begin{aligned}
%  (\forall \theta') \left[{
%  \begin {aligned} & \e{1} \apply \theta' = \e{2} \apply \theta' \, \uand \,  \theta' \neq \fail  \, \uand
%   \,\thet{0} \moregen \theta'\\
%                     &\operatorname{then}\, \theta \moregen \theta'
%   \end{aligned}
%   \right] \end{aligned}

% \begin{alignat*}{1}
%  (\forall \theta') \left[{
%  \begin {aligned} & \e{1} \apply \theta' = \e{2} \apply \theta' \, \uand \,  \theta' \neq \fail  \, \uand
%   \,\thet{0} \moregen \theta'\\
%                     &\operatorname{then}\, \theta \moregen \theta'
%   \end{aligned}}
%   \right] \end{alignat*}.


Because the roles of $\e{1}$ and $\e{2}$ are interchangeable, the most-general idempotent relation has a \emph{symmetry property} 
\begin{align*}
 {\mgi}(\thet{0}, \e{1}, \e{2}, \theta) \,\, \uiff \,\, 
{\mgi}(\thet{0}, \e{2}, \e{1}, \theta).
   \end{align*}
The relation also has a kind of \emph{reflexivity property}; when $\thet{0}$ and $\theta$ are equal, the relation clearly holds, because then $\thet{0} \moregen \theta'$ appears in both the antecedent and the consequent of the implication.  Hence
\begin{align*}
[\thet{0} = \theta] \,\, \uimplies \,\,
 {\mgi}(\thet{0}, \e{1}, \e{2}, \theta).
   \end{align*}
   \noindent In other words, the environment $\thet{0}$ itself is always most-general idempotent for any expressions.

If the two expressions $\e{1}$ and $\e{2}$ are ununifiable, any substitution $\theta$ will satisfy the most-general idempotent relation.   When the substitution $\theta'$ is the improper substitution $\fail$, the consequent of the above definition  of $\mgi$ is true, because any substitution $\theta$ is strongly more general than the failure substitution.  But if $\theta'$ is proper, because the two expressions are ununifiable, the antecedent of the definition will be false, and the implication itself will be true.  In either case, if $\e{1}$ and $\e{2}$ are ununifiable, any substitution $\theta$ is most-general idempotent. We call this the \emph{ununifiable property of mgi}.

For instance, if the two expressions are unequal constants, any substitution will be most-general idempotent with respect to any environment. That is,
\begin{align*}
 &{\mgi}(\thet{0}, \e{1}, \e{2}, \theta) \,\, \uimpliedby \\ \,\,
&[\iscnst(\e{1}) \uand \iscnst(\e{2}) \uand \e{1} \neq \e{2} ].
   \end{align*}
Similarly, if one of the expressions is a constant and the other is nonatomic, any substitution will be most-general idempotent; that is, 
\begin{align*}
 &{\mgi}(\thet{0}, \e{1}, \e{2}, \theta) \,\, \uimpliedby \\ \,\,
&[\iscnst(\e{1}) \uand \unot(\isatm(\e{2}))].
   \end{align*}
And if one of the expressions is a proper subexpression of the other, any substitution will be most-general idempotent; that is, 
\begin{align*}
 &{\mgi}(\thet{0}, \e{1}, \e{2}, \theta) \,\, \uimpliedby \,\,
[\e{1} \occursin \e{2}].
   \end{align*}

% \subsection{Renaming} A  $\theta$ is a \emph{renaming} on a term $t$ if it replaces all the variables in the term by distinct variables; that is, if $\var{X}$ is a variable, $\var{X}\theta$ is a variable and if $\var{X}$ and $\var{Y}$ are distinct variables that occur in $t$, $\var{X}\theta$ and $\var{Y}\theta$ are distinct. Two renamings $\thet{1}$ and $\thet{2}$ \emph{rename apart} two expressions $\e{1}$ and $\e{2}$ if  $\e{1}\thet{1}$ and $\e{2}\thet{2}$ have no variables in common.


\begin{comment}
The condition that $\theta' \neq \fail$ can be dropped from the antecedent of the above definition of the relative most-general idempotent relation because, when it doesn't hold, the conclusion holds automatically; $\theta \moregen \theta'$
is always true if $\theta'$ is $\fail$. Therefore we can say that ${\mgi} (\thet{0}, \e{1}, \e{2}, \theta)$ holds, by the \emph{abbreviated definition of $\mgi$,} precisely when 
\begin{align*}
 (\forall \theta') \left[{
 \begin {aligned} &\e{1} \apply \theta' = \e{2} \apply \theta' \, \uand \,   
  \thet{0} \moregen \theta' \,\uimplies\\
                    &\theta \moregen \theta'
   \end{aligned}}
   \right]. \end{align*}
\end{comment}

   Conversely, while the improper failure substitution $\fail$ unifies any two expressions, it will not be most-general idempotent unless the two expressions are ununifiable with respect to that environment; we call this the \emph{failure property of mgi}.  For, if $\e{1}$ and $\e{2}$ are unified by a proper substitution $\theta'$ that is an extension of the environment $\thet{0}$, the antecedent is true but
it cannot be true that the consequent $\fail \moregen \theta'$ holds;  the failure substitution is not more general than any proper substitution. In other words, the implication
 {\begin {align*} &\e{1} \apply \theta' = \e{2} \apply \theta' \, \uand \,     \thet{0} \moregen \theta' \,\uimplies\\
                    &\fail \moregen \theta'
   \end{align*}}
must be false.
\paragraph{Replacement Property of Most-General Idempotence.}
 The \emph{$\mgi$ replacement property} expresses the relationship between replacement and the most-general idempotent relation:
\[
\begin{aligned}
    &\mgi(\thet{0}, \e{1}, \e{2}, \thet{0} \compose \{\e{1} \mapsto \e{2}\}) \uimpliedby \\
    &\isvar(\e{1})
\end{aligned}
\]
for all substitutions $\thet{0}$ and expressions $\e{1}$ and $\e{2}$.

To prove this, it suffices (by the definition of the relative most-general idempotence relation $\mgi$) to 
assume that, for some substitution $\theta$, variable $\e{1}$ and expression $\e{2}$, 
\[\e{1} \apply \theta = \e{2} \apply \theta\]
and
\[\thet{0} \moregen \theta,\]
that is [by the definition of the relation $\moregen$] 
\[\thet{0} \compose \theta = \theta.\]
We show that then
\[\thet{0} \compose \{\e{1} \mapsto \e{2}\} \moregen \theta,\]
that is [by definition of $\moregen$, again]
\[\thet{0} \compose \{\e{1} \mapsto \e{2}\} \compose \theta = \theta .\]
It suffices to show [because $\thet{0} \compose \theta = \theta$] that
\[\thet{0} \compose \{\e{1} \mapsto \e{2}\} \compose \theta = \thet{0} \compose \theta \]
or [by properties of equality] that
\[\{\e{1} \mapsto \e{2}\} \compose \theta = \theta. \]
It further suffices [by the definition of equality for substitutions] to show that, for any variable $v$,
\[v \apply \{\e{1} \mapsto \e{2}\} \compose \theta =  v \apply \theta. \]

    When $v$ is actually $\e{1}, $ this reduces [by the \emph{replacement identity} property and the \emph{composition property} of substitutions] to
\[\e{2} \apply \theta = \e{1} \apply \theta,\]
which we have assumed.

When $v$ is distinct from $\e{1}$, this reduces [by the \emph{replacement distinct} property] to
\[v \apply \theta = v \apply \theta, \] which is true.  This concludes the proof.

\paragraph{Instance Property of Most-General Idempotence.} The most-general idempotence relation has a property that is useful in the derivation of unification algorithms, namely, that
\begin{align*}
 {\mgi}(\thet{0}, \e{1}, \e{2}, \theta) \,\, \uiff \,\, 
  {\mgi}(\thet{0}, \e{1}\!\apply\thet{0}, \e{2}\!\apply\thet{0}, \theta),
 \end{align*}
for any expressions $\e{1}$, $\e{2}$, and substitutions $\thet{0}$ and $\theta$. The consequents of the implications on the left and the right side of the equivalence are the same, $\theta' \moregen \theta$. So it suffices to show that the antecedents are equivalent.  

The antecedent of the right side ${\mgi}(\thet{0}, \e{1}\!\apply\thet{0}, \e{2}\!\apply\thet{0}, \theta)$,
\[\e{1}  \apply \thet{0} \apply \theta' = \e{2} \apply\thet{0} \apply \theta' \, \uand \,   
  \thet{0} \moregen \theta', \]
  is equivalent to
 \[\e{1}  \apply \thet{0} \compose \theta' = \e{2}  \apply \thet{0} \apply \theta' \, \uand \,   
  \thet{0} \compose \theta' = \theta' \]
[by the \emph{composition property} and the definition of $\moregen$],  which is equivalent to 
\[\e{1} \apply \theta' = \e{2} \apply \theta' \, \uand \,   
  \thet{0} \compose \theta' = \theta'\]
[because $\thet{0} \compose \theta' = \theta'$],  which is equivalent to
\[\e{1} \apply \theta' = \e{2} \apply \theta' \, \uand \,   
  \thet{0} \moregen \theta'. \]
  But this is the antecedent of the left side ${\mgi}(\thet{0}, \e{1}, \e{2}, \theta).$
Hence, we have the desired result.

  \paragraph{Most-General Idempotence on Nonatomic Expressions.} We can construct most-general idempotent substitutions for nonatomic expressions from most-general idempotent substitutions for their components. There is a kind of transitivity in the relative most-general-idempotence relation.
  More precisely, for all expressions $\d{l}$, $\d{r}$, $\e{l}$, $\e{r}$ and all substitutions $\thet{1}$, $\thet{2}$, $\thet{3}$, we have the \emph{transitivity property of $\mgi$},
   \begin{alignat*}{1}
 &\left[\begin{aligned}
  &\mgi (\thet{0}, \d{l}, \e{l}, \thet{1})
  \, \uand \\
   &\mgi (\thet{1}, \d{r}, \e{r}, \thet{2}) 
   \end{aligned}\right] \, \uimplies\\
   &\mgi(\thet{0}, (\d{l} {\cons} \d{r}), (\e{l} {\cons} \e{r}), \thet{2}). 
  \end{alignat*} 
  

   \noindent To prove this, assume that ${\mgi}(\thet{0}, \d{l}, \e{l}, \thet{1})$ and ${\mgi}(\thet{1}, \d{r}, \e{r}, \thet{2}) $; it suffices to show that ${\mgi}(\thet{0}, (\d{l} {\cons} \d{r}), (\e{l} {\cons} \e{r}), \thet{2})$.  For this purpose, we assume  that $\theta'$ is a substitution such that $(\d{l} {\cons} \d{r}) \apply \theta' = (\e{l} {\cons} \e{r}) \apply \theta'$ and $\thet{0} \moregen \theta'$; we attempt to show that $\thet{2} \moregen \theta'$.
   
   Because  $(\d{l} {\cons} \d{r}) \apply \theta' = (\e{l} {\cons} \e{r}) \apply \theta'$, we have that  $\d{l} \apply \theta' = \e{l} \apply \theta'$ and  $\d{r} \apply \theta' = \e{r} \apply \theta'$.
   
   Because ${\mgi}(\thet{0}, \d{l}, \e{l}, \thet{1})$, $\d{l} \apply \theta' = \e{l} \apply \theta'$, and $\thet{0} \moregen \theta'$, we have [by the definition of $\mgi$], $\thet{1} \moregen \theta'$.
   
   Because ${\mgi} (\thet{1}, \d{r}, \e{r}, \thet{2})$, $\d{r} \apply \theta' = \e{r} \apply \theta'$, and $\thet{1} \moregen \theta'$, we have [again by the definition of $\mgi$] $\thet{2} \moregen \theta'$, which is what we wanted to show.
   
  Because any non-atomic expression $e$ can be decomposed into  $\lef(e)\cons \rig(e)$, we can phrase the above \emph{transitivity property of $\mgi$} as
    \[
    \begin{aligned}
    &\unot(\isatm(\e{1})) \uand \unot(\isatm(\e{2})) \uimplies\\
&\left[    \begin{aligned}
   &\left[\begin{aligned}
  &\mgi (\thet{0}, \lef(\e{1}), \lef(\e{2}), \thet{1})
  \, \uand \\
   &\mgi (\thet{1}, \rig(\e{1}), \rig(\e{2}), \thet{2}) 
   \end{aligned}\right] \uimplies \\
  &\mgi(\thet{0}, (\lef(\e{1}) {\cons} \rig(\e{1})), (\lef(\e{2}) {\cons} \rig(\e{2})), \thet{2})
   \end{aligned} \right].
   \end{aligned}
    \]

      \subsubsection{Most-General Idempotent Unifier.} 
Finally, we introduce the most-general idempotent unifier relation ${\mgiu} (\thet{0}, \e{1}, \e{2}, \theta)$ that will be used in the specification of the unification algorithm.  This relation holds when the substitution $\theta$ is a \emph{most-general idempotent unifier} of the expressions $\e{1}$ and $\e{2}$ with respect to the environment substitution $\thet{0}$, that is, 
\begin{align*} 
 {\mgiu}(&\thet{0}, \e{1}, \e{2}, \theta) \uiff \\
&\begin{aligned}
&\e{1} \apply \theta = \e{2} \apply \theta \, \uand 
&&\text{\qquad [$\theta$ is a unifier]} \\
 \,\, & \thet{0} \moregen \theta \, \uand
&&\text{\qquad [$\theta$ is an extension of $\thet{0}]$}\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \theta)
 &&\text{\qquad [$\theta$ is most-general idempotent]}
 \end{aligned}.\end{align*}
   
   
   \noindent In other words, $\theta$ is a unifier of the expressions $\e{1}$ and $\e{2}$, $\theta$ is an extension of the environment $\thet{0}$, and $\theta$ is most-general idempotent for the expressions $\e{1}$ and $\e{2}$ with respect to $\thet{0}$.

   For example, if $\thet{0}$ is the substitution  $\{\var{X} \mapsto \var{Y}\}$ and the two expressions $\e{1}$ and $\e{2}$ are $\var{Y}$ and $\var{Z}$, respectively, then the substitution $\theta = \{\var{X} \mapsto \var{Z}, \var{Y} \mapsto \var{Z}\}$ is a most-general idempotent unifier, i.e., it satisfies 
   $\mgiu(\thet{0}, \e{1}, \e{2}, \theta)$.  First, $\theta$ is a unifier, because
   
   \begin{align*}
   \e{1} \apply \theta  &= \var{Y} \apply  \{\var{X} \mapsto \var{Z}, \var{Y} \mapsto \var{Z}\} \\
                        &= \var{Z} \\
                        &= \var{Z} \apply  \{\var{X} \mapsto \var{Z}, \var{Y} \mapsto \var{Z}\} \\
                        &= \e{2} \apply \theta.
    \end{align*}                     

Also $\theta$  is an extension of $\thet{0}$, because
  \begin{align*}
  \thet{0} \compose \theta &= \{\var{X} \mapsto \var{Y}\} \compose \{\var{X} \mapsto \var{Z}, \var{Y} \mapsto \var{Z}\} \\
                           &= \{\var{X} \mapsto \var{Z}, \var{Y} \mapsto \var{Z} \} \\
                           &= \theta.
   \end{align*}

Finally, we can show that $\theta$ is most-general idempotent for this environment and expressions, that is,
$\mgi(\thet{0}, \e{1}, \e{2}, \theta)$.  For suppose, for some substitution $\theta'$, that
    $\e{1} \apply \theta' = \e{2} \apply \theta',$
that is,
\begin{align*}
    \var{Y} \apply \theta' = \var{Z} \apply \theta',  
\end{align*}
and that $\theta'$ is an extension of $\thet{0}$, that is,
\[\thet{0} \compose \theta' = \theta'.\]
Then, we want to show $\theta$ is strongly more general than $\theta'$, that is,
\begin{align*}
    \theta \compose \theta'  = \theta'.
\end{align*} 
To show this it suffices to show 
\begin{align*}
    \var{v} \apply {\theta \compose \theta' } = \var{v} \apply \theta,
\end{align*}
that is [by the \emph{composition property}],
\begin{align*}
    \var{v} \apply \theta \apply \theta'  = \var{v} \apply \theta,
\end{align*}
for any variable $\var{v}.$

When $\var{v}$ is $\var{X}$, we must show
\begin{align*}
    \var{X} \apply \theta \apply \theta'  = \var{X} \apply \theta' 
\end{align*}
or, equivalently, 
\begin{align*}
    \var{Z} \apply \theta'  = \var{X} \apply \theta' \quad \text{[because $\var{X} \apply \theta = \var{Z}$]}
\end{align*}
or, equivalently,
\begin{align*}
    \var{Z} \apply \thet{0} \apply \theta'  = \var{X} \apply \thet{0} \apply \theta' \quad \text{[because $\thet{0} \compose \theta' =  \theta'$]}
\end{align*}
or, equivalently,
\begin{align*}
    \var{Z}  \apply \theta'  = \var{Y} \apply \theta' \quad \text{[because $\var{Z} \apply \thet{0} =  \var{Z}$ and 
    $\var{X} \apply \thet{0} = \var{Y}$]},
\end{align*}
which is true by supposition.


When $\var{v}$ is $\var{Y}$, we must show
\begin{align*}
    \var{Y} \apply \theta \apply \theta'  = \var{Y} \apply \theta' 
\end{align*}
or, equivalently, 
\begin{align*}
    \var{Z} \apply \theta'  = \var{Y} \apply \theta' \quad \text{[because $\var{Y} \apply \theta = \var{Z}$]}.
 \end{align*}   
 But this is true by supposition.

 When $\var{v}$ is any variable other than $\var{X}$ or $\var{Y}$, we must show
 \begin{align*}
    \var{v} \apply \theta \apply \theta'  = \var{v} \apply \theta' 
\end{align*}
 or, equivalently,
  \begin{align*}
    \var{v} \apply \theta'  = \var{v} \apply \theta' \quad \text{[because $\theta$ misses $\var{v}$]}.
\end{align*}
But this is identically true.

It can similarly be shown that $\theta = \{\var{X} \mapsto \var{Y}, \var{Z} \mapsto \var{Y}\}$ is a most-general idempotent unifier, that is,  $\mgiu(\thet{0}, \e{1}, \e{2}, \theta)$.  Thus, most-general idempotent unifiers are not unique.

Although $\theta = \{\var{Y}  \mapsto \var{Z} \}$ is a unifier of $\var{Y}$ and $\var{Z}$, it is \emph{not} a most-general idempotent unifier with respect to the environment $\thet{0} = \{\var{X} \mapsto \var{Y}\}$ because it is not an extension of $\thet{0}$.  That is because
\[\thet{0} \compose \theta = \{\var{X} \mapsto \var{Y}\} \compose \{\var{Y}  \mapsto \var{Z} \} = \{\var{X} \mapsto \var{Z}, \var{Y}  \mapsto \var{Z}\} \neq \{\var{Y}  \mapsto \var{Z} \} = \theta. \]


 \paragraph{Properties of Most-General Idempotent Unifiers.}  We can  show the \emph{idempotence property of the relation mgiu}, namely, if $\theta$ is a most-general idempotent unifier of two expressions $\e{1}$ and $\e{2}$ with respect to an environment $\thet{0}$, then $\theta$ is indeed idempotent.  For suppose 
   \[\mgiu(\thet{0}, \e{1}, \e{2}, \theta).\]
Then, (by the definition of $\mgiu$)
      \[\e{1} \apply \theta = \e{2} \apply \theta, \]
      \[\thet{0} \moregen \theta, \]  
            and
      \[{\mgi}(\thet{0}, \e{1}, \e{2}, \theta).\]
Hence (by the definition of $\mgi$), for any substitution $\theta'$, 
\[
 \begin {aligned} &\e{1} \apply \theta' = \e{2} \apply \theta' \, \uand \,   
  \thet{0} \moregen \theta' \,\uimplies\\
                    &\theta \moregen \theta'.
   \end{aligned}
   \]
In particular, taking $\theta'$ to be $\theta$, we have
   \[\theta \moregen \theta;\]
that is, $\theta$ is idempotent, as we wanted to show.


   Because the relation $\mgi$ has a \emph{symmetry property} and the roles of $\e{1}$ and $\e{2}$ are otherwise interchangeable, we can establish the \emph{symmetry property} of the \emph{most-general idempotent unifier relation} $\mgiu$, namely
    \begin{align*} 
 {\mgiu}(&\thet{0}, \e{1}, \e{2}, \theta) \uiff 
 {\mgiu}(\thet{0}, \e{2}, \e{1}, \theta). 
 \end{align*}

We earlier established an \emph{instance property for the most-general idempotent relation} ${\mgi}$; by similar reasoning, we can establish an \emph{instance property of the most-general idempotent-unifier relation \emph{$\mgiu$}}, namely:
   \begin{align*}
 {\mgiu}(\thet{0}, \e{1}, \e{2}, \theta) \,\, \uiff \,\, 
  {\mgiu}(\thet{0}, \e{1}\!\apply\thet{0}, \e{2}\!\apply\thet{0}, \theta),
 \end{align*}
for any expressions $\e{1}$, $\e{2}$, and substitutions $\thet{0}$ and $\theta$. For
\[ {\mgiu}(\thet{0}, \e{1}\!\apply\thet{0}, \e{2}\!\apply\thet{0}, \theta)\]
\noindent is equivalent [by definition] to
\[\begin{aligned}
&\e{1}\!\apply\thet{0}\apply \theta = \e{2}\!\apply\thet{0} \apply \theta \, \uand 
 \\
 \,\, & \thet{0} \moregen \theta \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}\!\apply\thet{0}, \e{2}\!\apply\thet{0}, \theta),
\end{aligned}\]
\noindent which is equivalent [by the \emph{composition property}, the definition of $\moregen$, and the \emph{instance property} of $\mgi$] to
\[\begin{aligned}
&\e{1}\!\apply\thet{0}\compose \theta = \e{2} \!\apply\thet{0}\apply \theta \, \uand 
 \\
 \,\, & \thet{0} \compose \theta = \theta \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \theta),
\end{aligned}\]
\noindent which is equivalent [by properties of equality] to
\[\begin{aligned}
&\e{1}\!\apply \theta = \e{2} \apply \theta \, \uand 
 \\
 \,\, & \thet{0} \compose \theta = \theta \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \theta),
\end{aligned}\]
\noindent which is equivalent [by the definitions of $\moregen$ and $\mgiu$, again]  to
\[{\mgiu}(\thet{0}, \e{1}, \e{2}, \theta).\]



 \subsubsection{Range Bound Property.}\label{rprop}  
 This most-general idempotent-unifier relation with respect to an environment has a property that is important in our derivation of some unification algorithms, namely that, if the environment substitution is  idempotent and misses both expression arguments, the most-general idempotent unifier can introduce no new variables. More precisely, a variable in the range of the unifier must already be in the range of the environment or occur in one of the input expressions.  We call this the \emph{range bound property} of most-general idempotent unifiers.  Maintaining or reducing the set of variables in our arguments is important in applying the induction principle and in establishing termination of our derived unification algorithm, as we shall see. But this may be the most difficult result in this paper; the reader who is willing to accept the result is justified in skipping the proof.
   
   The \emph{range bound property} is not true for most-general unifiers that are not idempotent;  for example, as we have seen, with respect to the empty environment substitution  $\emptysubst$, the substitution $\{\var{X} \mapsto \var{Z}, \var{Y} \mapsto \var{Z}, \var{Z} \mapsto \var{Y}\}$ is a most-general but non-idempotent unifier of $\var{X}$ and $\var{Y}$.  In fact, it introduces the new variable $\var{Z}$.  The idempotent most-general unifier $\{\var{X} \mapsto \var{Y}\}$
  introduces only the variable $\var{Y}$, which occurs in an input expression.

   We can write the \emph{range bound property}  as
\begin{align*} 
 &\mgiu(\thet{0}, \e{1}, \e{2}, \theta) \uimplies \\
 &\,\range(\theta) \subseteq \range(\thet{0}) \cup \vars(\e{1}, \e{2}), \end{align*}
 where $\thet{0}$ is idempotent and misses $\e{1}$ and $\e{2}$.
To prove this, assume to the contrary that some variable $z$ belongs to  $\range(\theta)$ but does not belong to $\range(\thet{0})$ and does not occur in $\e{1}$ or $\e{2}$.  



Because $\theta$ is idempotent and $\var{z}$ is in 
$\range(\theta)$, $\var{z}$ is not in $\dom(\theta)$ and thus $\var{z} \apply \theta = \var{z}$. And because $\var{z}$ is in 
$\range(\theta),$ there is a variable $\var{y}$ in $\dom(\theta)$ such that $\var{z} \occurseq (\var{y} \apply \theta).$  We shall derive a contradiction.

We employ the \emph{derangement} construction (Section \ref{par:der}) to remove $\var{z}$ from the range of $\theta$. Let $\var{z'}$ be a new variable, one distinct from $\var{z}$ that does not occur in any of the expressions or substitutions; in particular, $\var{z'} \neq \var{z}$ and $\var{z'}$ is not in $\dom(\theta)$ or $\range(\theta)$. Let $\thet{z'}$ be a substitution that is the same as $\theta$ except that every occurrence of $\var{z}$ has been replaced by $\var{z'}$.  Formally we have defined $\thet{z'}$ so that
\begin{align*}
  & \var{u} \apply \thet{z'} = (\var{u} \apply \theta) \apply \{\var{z} \mapsto \var{z'}\}
 \end{align*}
 for every variable $u$ in $\dom(\theta)$, and
 \begin{align*}
  & \var{u} \apply \thet{z'} = \var{u}  
 \end{align*}
 for every variable $\var{u}$ not in $\dom(\theta)$. 
 This means [because $\var{z}$ is not in $\dom(\theta)$] that $\var{z} \apply \thet{z'} = \var{z}$; that is, $\var{z}$ is not in $\dom(\thet{z'}).$ 
 
We have established the \emph{derangement property}, that for any expression $e$ that contains no occurrences of $\var{z}$, we have
 \begin{align*}
  & e \apply \thet{z'} = e \apply \theta \compose \{\var{z} \mapsto \var{z'}\}.
 \end{align*}

\paragraph{Use of Most-General Idempotence.} We define another new substitution $\theta'$ by $\theta' = \thet{0} \compose \thet{z'}$.  By the \emph{composition property of domains}, $\var{z}$ does not belong to $\dom(\theta')$, since it belongs to neither $\dom(\thet{0})$ nor  $\dom(\thet{z'}).$ 
% Also,  \[\var{z'} \occurseq (\var{y} \apply \theta'),\] 
% that is, $\var{z'} \occurseq (\var{y} \apply \thet{0} \compose \thet{z'}).$  

We claim that then $\theta'$ is an extension of the environment substitution  $\thet{0}$ and is a unifier of  $\e{1}$ and $\e{2}$.
By the definition of most-general idempotent unifier, this will imply that $\theta'$ is an extension of $\theta.$  We show that this is impossible.

 We first show that $\theta'$ is an extension of $\thet{0}$. 
 We have 
\begin{align*}
 \thet{0} \compose \theta' &= \thet{0} \compose \thet{0} \compose \thet{z'}  &&  
  \text{[by definition of $\theta'$]} \\
    &= \thet{0} \compose \thet{z'} && 
    \text{[because $\thet{0}$ is idempotent]} \\
    &= \theta' &&
    \text{[by definition of $\theta'$, again]}.
 \end{align*} 
 

%It follows that $\var{z} \apply \theta' = \var{z}'$, because 
% $\var{z} \apply \theta' =$ [by the definition of $\theta'$]$(\var{z} \apply \theta) \apply \{\var{z} \mapsto \var{z}' \} = $ [because $\var{z}$ is not in the domain of $\theta$] $\var{z} \apply \{\var{z} \mapsto \var{z}'\} =\var{z}'$. .



 % \begin{align*}
 %   \var{z} \apply \theta'
 %      & = (\var{z} \apply \theta) \apply \{\var{z} \mapsto \var{z}' \} &&  \text{[by the definition of $\theta'$]} \\
 %       & = \var{z} \apply \{\var{z} \mapsto \var{z}'\} && \text{[because $\var{z}$ is not in the domain of $\theta$]} \\
 %       & = \var{z}'.
 %      \end{align*}

     % 
     
     % & = \var{z} \apply \{\var{z} \mapsto \var{z}'\} && \text{[because $\var{z}$ is not in the domain of $\theta$]} \\
     % & = \var{z}'
 

 % \begin{align*}
 %   \var{z} \apply \theta' 
 %     & = (\var{z} \apply \theta) \apply \{\var{z} \mapsto \var{z}' \}  && \text{[by the definition of $\theta']} \\
 %     & = \var{z} \apply \{\var{z} \mapsto \var{z}'\} && \text{[because $\var{z}$ is not in the domain of $\theta$]} \\
 %     & = \var{z}'\omit
 % \end{align*}

We now show that  $\theta'$  is a unifier of $\e{1}$ and $\e{2}$, that is, that 
\begin{align*}
    \e{1} \apply \theta' = \e{2} \apply \theta',
\end{align*}
or [by definition of $\theta'$]
\begin{align*}
     \e{1} \apply \thet{0} \compose \thet{z'} = 
     \e{2} \apply \thet{0} \compose \thet{z'},
\end{align*}
or (because $\thet{0}$ misses both $\e{1}$ and $\e{2}$)
\begin{align*}
     \e{1} \apply  \thet{z'} = 
     \e{2} \apply  \thet{z'},
\end{align*}
or (by the \emph{derangement property}, because $\var{z}$ does not occur in $\e{1}$ or $\e{2}$)
\begin{align*}
     \e{1} \apply  \theta \compose \{\var{z} \mapsto \var{z'}\} = 
     \e{2} \apply  \theta \compose \{\var{z} \mapsto \var{z'}\}.
\end{align*}
This holds because we have assumed that $\theta$ is a unifier of $\e{1}$ and $\e{2}$.



We have shown that $\theta'$ is a unifier and is an extension of the environment substitution  $\thet{0}$. By the definition of most-general idempotent unifier, this implies that $\theta'$ is an extension of $\theta.$ We next show that this is impossible, because it implies that $\var{z}$ both belongs and does not belong to the result of applying $\theta'$ to $\var{y}.$

\paragraph{Completion of the Proof of the Range Bound Property.} 
The gist of the proof is that $\theta$ introduces $\var{z}$; 
the new substitution $\theta'$ has been devised so that it leaves existing occurrences of $\var{z}$ alone but does not introduce $\var{z}$.  
Their composition $\theta \compose \theta'$ therefore introduces $\var{z}$ and hence cannot equal $\theta',$ which does not introduce $\var{z}$. The details follow.

We have chosen $\var{y}$ and $\var{z}$ so that $\var{z} \occurseq (\var{y} \apply \theta),$  and we established that $\var{z}$ does not belong to the domain of $\theta'$; therefore,
$\var{z} \occurseq (\var{y} \apply \theta \compose \theta').$  But since we have concluded that $\theta'$ is an extension of $\theta,$  that is, $\theta \compose \theta' = \theta'$, this means that
\[\var{z} \occurseq (\var{y} \apply \theta').\]



% Also we have assumed that $\var{z}$ is not in $\dom(\thet{0});$ therefore 
% $\var{z} \occurseq (\var{y} \apply \theta \compose \thet{0}).$  
% We have shown that $\var{z}$ is not in $\dom(\thet{z'});$ therefore 
% $\var{z} \occurseq (\var{y} \apply \theta \compose \thet{0} \compose \thet{z'}).$ 
% Hence [because by definition $\theta' = \thet{0} \compose \thet{z'}$] we have 
% $\var{z} \occurseq (\var{y} \apply \theta \compose \theta'),\;$ 
% and [because $\theta'$ is an extension of $\theta$, that is, $\theta \compose \theta' = \theta'$] we have 
% \[\var{z} \occurseq (\var{y} \apply \theta').\]

On the other hand, because all occurrences of $\var{z}$ have been replaced by $\var{z'}$ in $\var{y} \compose \thet{0} \compose \theta \compose \{\var{z} \mapsto \var{z'}\},$ we have $\unot(\var{z} \occurseq (\var{y} \compose \thet{0} \compose \theta \compose \{\var{z} \mapsto \var{z'}\})).$  But [because $\unot(\var{z} \occurseq (\var{y} \compose \thet{0}))$] the \emph{derangement property} implies that $\thet{z'}$ and $\theta \compose \{\var{z} \mapsto \var{z'}\})$ agree on $\var{y} \compose \thet{0}$, and hence
$\unot(\var{z} \occurseq (\var{y} \compose \thet{0} \compose \thet{z'})).$ But then [because we have defined $\theta'$ to be $\thet{0}\compose \thet{z'}$] we have 
\[\unot(\var{z} \occurseq (\var{y} \apply \theta')),\]
our desired contradiction.  This concludes the proof of the \emph{range bound property}.


 



    



 % \begin{align*}
 %   \var{z} \apply \theta'
 %      & = (\var{z} \apply \theta) \apply \{\var{z} \mapsto \var{z}' \} &&  \text{[by the definition of $\theta'$]} \\
 %       & = \var{z} \apply \{\var{z} \mapsto \var{z}'\} && \text{[because $\var{z}$ is not in the domain of $\theta$]} \\
 %       & = \var{z}'.
 %      \end{align*}

  

  

   We have completed our introduction to the theory of expressions and substitutions;  we  introduce other properties of the theory as they are needed.  We now turn to our framework for program synthesis.
   
  
   
   
   
   \section{A Brief Introduction to Deductive Program Synthesis}
   
   We begin by introducing the notion of the subject domain theory. We do not expect this section to serve as an introduction to logic, but we'll set down our terminology.
   

   \subsection{Subject Domain Theory}
   
   Program synthesis requires a good deal of knowledge about the domain of application, which is provided here by the subject domain theory.  This is expressed by a set of logical formulas in mathematical logic.
   
   \subsubsection{Formulas and Terms.} We begin with a vocabulary comprising an infinite set of constants, an infinite set of variables, an infinite set of $n$-ary function symbols, and an infinite set of $n$-ary relation symbols, for each $n$ such that $n \geq 0$, as well as some logical connectives and a conditional operator.  
   
   The \emph{expressions} comprise \emph{terms} and \emph{formulas}; intuitively, the value of a formula is a truth value, either true or false, and the value of a term is an object, such as a number.  We define terms and formulas together inductively.  Terms comprise the constants, the variables, the result of applying an $n$-ary function symbol to $n$ terms, and the conditional term  $\cond {\mathcal{P}} {\expsub{t}{1}} {\expsub{t}{2}}$, where $\mathcal{P}$ is a formula and  $\expsub{t}{1}$ and $\expsub{t}{2}$ are terms.   We call $\expsub{t}{1}$ and $\expsub{t}{2}$ the \emph{then-branch} and the \emph{else-branch}, respectively, of the conditional term. (We sometimes write this as 
   $(\uif \mathcal{P} \uthen t_1 \uelse t_2)$.
   
   We include the equality symbol $=$ as a binary function symbol in a single term or formula, but we also use it informally in English to relate two terms.
   
   Atomic formulas comprise $\emph{true}$, $\emph{false}$, and the result of applying an $n$-ary relation symbol to $n$ terms. Formulas comprise atomic formulas and the results of applying the logical connectives $\uand$,  $\uor$, $\unot$,  $\uimplies$, $\uimpliedby$, and  $\uiff$ to formulas. \emph{Ground} formulas are those that contain no variables. We freely switch between prefix and infix notation (e.g.,  ``$\uor(\mathcal{P},\, \mathcal{Q})$" and ``$\mathcal{P} \uor \mathcal{Q}$") as convenient.
   
   We also use the equivalence symbol $\uiff$ informally in English to relate two formulas. 
   Context will let us know if we are regarding $\uiff$ as part of a single formula or as an English abbreviation for “if and only if" to relate two formulas.
   We do not include explicit quantifiers, but, as in resolution theorem proving, we apply skolemization to remove quantifiers, so this will not cost us any expressive power. 
   
  
   
  \subsubsection{Truth.}  A \emph{theory} consists of a finite set of formulas, called the \emph{axioms} of the theory. We do not assume that the axioms are consistent or logically independent. We start by introducing the notion of \emph{truth} of a formula in a theory.
   
   \subsubsection{Interpretation.} A (Herbrand) \emph{interpretation} is a possibly infinite list of ground atomic formulas, which are taken to be \emph{true}; those ground atomic formulas not on the list are taken to be \emph{false}.  With respect to an interpretation, we can determine the truth value of a nonatomic ground formula, which contains logical connectives, by applying the usual truth tables; for instance, 
   $\uor (\mathcal{P}, \mathcal{Q})$ is true if $\mathcal{P}$ is true or $\mathcal{Q}$ is true, and false otherwise.  
   
   We then say that an arbitrary formula (not necessarily ground) is true under the interpretation if every instance of the formula is true, where an instance is obtained by replacing every occurrence of each variable in the formula by a corresponding term, that is, by applying a substitution. An arbitrary formula is false under an interpretation if some instance of the formula is false.   A formula is \emph{valid} if it is true under every interpretation. 
   
   \subsubsection{Equivalence and Equality.}
   Equivalence and equality are analogous; equivalence applies to formulas and equality to terms.
   
   \paragraph{Equivalence.}
   Two formulas $\expsub{\mathcal{P}}{1}$ and $\expsub{\mathcal{P}}{2}$ are \emph{equivalent} under an interpretation, written $\expsub{\mathcal{P}}{1} \uiff \expsub{\mathcal{P}}{2}$, if  $\expsub{\mathcal{P}}{1}$ and $\expsub{\mathcal{P}}{2}$ are either both true or both false under the interpretation.  
   For instance, the double negation sentence $\unot(\unot(\mathcal{P}))$ is equivalent to $\mathcal{P}.$
   The implication sentence $\expsub{\mathcal{P}}{1} \uimplies  \expsub{\mathcal{P}}{2}$  is equivalent to the sentence $ \uor(\unot(\expsub{\mathcal{P}}{1}), \expsub{\mathcal{P}}{2}).$ 
   The equivalence sentence $\expsub{\mathcal{P}}{1} \uiff \expsub{\mathcal{P}}{2}$ is equivalent to the sentence
   \begin{align*}
   \uand (\expsub{\mathcal{P}}{1} \uimplies  \expsub{\mathcal{P}}{2},\expsub{\mathcal{P}}{2} \uimplies  \expsub{\mathcal{P}}{1}),
   \end{align*}
   to the sentence
   \begin{align*}
   \uand (\uor(\unot(\expsub{\mathcal{P}}{1}),  \expsub{\mathcal{P}}{2}),\uor(\unot(\expsub{\mathcal{P}}{2}), \expsub{\mathcal{P}}{1})),
   \end{align*}
   and to the sentence
   \begin{align*}
   \uor (\uand(\expsub{\mathcal{P}}{1},  \expsub{\mathcal{P}}{2}), 
   \uand(\unot (\expsub{\mathcal{P}}{1}), \unot (\expsub{\mathcal{P}}{2}))).
  \end{align*} 
    Equivalence has a \emph{substitutivity property}; namely, for any formula $\mathcal{S}\langle\expsub{\mathcal{P}}{1}\rangle$, if $\expsub{\mathcal{P}}{1}$ and $\expsub{\mathcal{P}}{2}$ are equivalent, so are $\mathcal{S}\langle\expsub{\mathcal{P}}{1}\rangle$ and $\mathcal{S}\langle \expsub{\mathcal{P}}{2}\rangle.$ 
  \paragraph{Equality.}  
   Two terms $\expsub{t}{1}$ and $\expsub{t}{2}$ are \emph{equal} under an interpretation, written $\expsub{t}{1} = \expsub{t}{2}$, if they satisfy the \emph{substitutivity property}, that is, if, for any formula $\mathcal{F}\langle\var{x}\rangle$,  $\mathcal{F}\langle\expsub{t}{1}\rangle$ is true precisely when  $\mathcal{F}\langle\expsub{t}{2}\rangle$ is true under the interpretation. (Here,  $\mathcal{F}\langle t\rangle$ is the result of replacing zero or more occurrences of $\var{x}$ in  $\mathcal{F}\langle\var{x}\rangle$ with $t$.) It follows that equality has the usual properties, such as \emph{reflexivity} ($t = t$, for all terms $t$), \emph{symmetry} ($(\expsub{t}{1} = \expsub{t}{2}) \uimplies (\expsub{t}{2} = \expsub{t}{1})$, for all terms $\expsub{t}{1}$ and $\expsub{t}{2}$), and transitivity ($(\expsub{t}{1} = \expsub{t}{2}) \uand (\expsub{t}{2} = \expsub{t}{3}) \uimplies (\expsub{t}{1} = \expsub{t}{3})$, for all terms  $\expsub{t}{1}$, $\expsub{t}{2}$, and $\expsub{t}{3}$).
   
   \subsubsection{Conditional Terms.} Under a given interpretation, the conditional term \[\cond {\mathcal{P}} {\expsub{t}{1}} {\expsub{t}{2}}\] is equal to $\expsub{t}{1}$ if $\mathcal{P}$ is true under the interpretation, and equal to $\expsub{t}{2}$ otherwise. Thus the conditional term $\cond {\mathcal{P}} t t$ is equal to $t$. (We call this the \emph{same-branch property}.) This is not true if $\mathcal{P}$ is a program that doesn't terminate, but we only construct terminating programs.
   
   Our \SNARK\ implementation systematically applies equivalences and equalities to simplify formulas, and it paraphrases implication and equivalence sentences in terms of the other connectives.
   
 
    \subsubsection{Expressions versus S-Expressions.} In our section on the theory of expressions and substitutions, we dealt only with S-expressions, which contain occurrences of constants but no function or relation symbols, other than $\cons$ (\emph{cons}). In the balance of this paper we deal with conventional expressions.  We apply substitutions to these expressions and we assume that all operators $\emph{op}$, including both relation symbols and logical operators, and all function symbols $\uf$, satisfy the \emph{distributivity  property},  
    \[\emph{op}(\expsub{t}{1}, \expsub{t}{2}, \ldots, \expsub{t}{n})\apply \theta \uiff \, \emph{op}(\expsub{t}{1}\apply \theta, \expsub{t}{2}\apply \theta, \ldots, \expsub{t}{n}\apply \theta),\]
    \noindent and 
     \[\uf(\expsub{t}{1}, \expsub{t}{2}, \ldots, \expsub{t}{n})\apply \theta = \, \uf(\expsub{t}{1}\apply \theta, \expsub{t}{2}\apply \theta, \ldots, \expsub{t}{n}\apply \theta),\] for any terms $\expsub{t}{i}$ and substitution $\theta$. 

     But, as we remarked earlier,  conventional expressions can be represented as S-expressions, as in Lisp, so this is not a substantive extension.
    
    
 
 
   
   \subsubsection{Models and Validity.} A \emph{model} of a theory is an interpretation under which every axiom of the theory is true. A formula is \emph{valid in a theory} if it is true under every model of the theory. A theory is \emph{consistent} if it has a model.

   
 \subsection{Mathematical Induction}
 \begin{quote}
 A hundred bottles of beer on the wall, \\
 A hundred bottles of beer. \\
 If one of those bottles should happen to fall, \\
 Ninety-nine bottle of beer on the wall! \\
 \ldots .
 \\---Traditional American and Canadian Song
 \end{quote}
   
 As we have mentioned previously, recursive calls are introduced to the program being derived by application of the mathematical induction principle.  
 
 \subsubsection{Reification.} Although we are working in a first-order logic, it will be useful to quantify over relations and to have functions that apply to relations and produce new ones.  To allow this, we employ \emph{reification};
 in other words,  we allow variables and complex terms other than predicate symbols to stand for relations.
 \begin{comment}
 If $r$ is a term that  stands for a relation, recall that we regard 
$r(\var{x}, \var{y})$ as a notation for the symbolic expression 
$(r \cons (\var{x} \cons(\var{y} \cons \nil))$. If $r$ is a variable, we can quantify over it just like any other variable. 
\end{comment}
Because first-order logic does not allow anything other than a predicate symbol at the head of an atomic formula, we can chose to represent a formula ${r}(\x{1}, \x{2}, \ldots, \x{n})$, where ${r}$ is a (perhaps complex) term that stands for a relation, as 
\emph{wf}\!$(r, \x{1}, \x{2}, \ldots, \x{n})$, where   \emph{wf} is a predicate symbol. In discussing binary relations, and, especially, well-founded relations and orderings, we will use the conventional notation $x \expsub{\prec}{r}\, y$.

\subsubsection{Sequences.}  A \emph{sequence}  $\{\expsub{a}{0}, \expsub{a}{1}, \expsub{a}{2}, \ldots\} $ is a unary (one-argument) function on the natural numbers. We say that a sequence $a' = \{\expsub{a}{0}',\, \expsub{a}{1}',\, \expsub{a}{2}',\, \ldots\}  $ is a subsequence of a sequence $a =\{\expsub{a}{0}, \expsub{a}{1}, \expsub{a}{2}, \ldots\} $ if all the elements of $a'$ occur distinctly in $a$ in the same order, perhaps with intervening elements; we say that $a'$ is an \emph{initial} subsequence of $a$ if $\expsub{a}{0}' = \expsub{a}{0}.$  A sequence  $a = \{\expsub{a}{0}, \expsub{a}{1}, \expsub{a}{2}, \ldots\}$ will be said to \emph{converge} if eventually all its elements are equal; that is, if, for some natural number $j$, $\expsub{a}{j} = \expsub{a}{j+1} = \expsub{a}{j+2} =\ldots .$  If $j$  is the least such natural number, the sequence may be said to \emph{converge at $j$}.
 
 
 
 \subsubsection{Well-Founded Relations.} The form of induction we use is well-founded induction, that is, induction over a well-founded relation.  A relation  $\expsub{\prec}{w}$ is well-founded if it admits no infinite (strictly) decreasing sequences, i.e., no sequences $a =\{\expsub{a}{0}, \expsub{a}{1}, \expsub{a}{2}, \ldots\} $ such that $\expsub{a}{0} \, \expsub{\succ}{w} \, \expsub{a}{1} \, \expsub{\succ}{w} \, \expsub{a}{2} \, \expsub{\succ}{w} \,\ldots.$ (Here, $\expsub{\succ}{w}$ is the \emph{inverse} of $\expsub{\prec}{w}$, defined by $\var{x} \expsub{\succ}{w} \var{y} \uiff \var{y} \expsub{\prec}{w} \,\var{x}.$) For example, the less-than relation $<$ is well-founded over the natural numbers (because any infinite decreasing sequence would eventually hit 0), but $<$ is not well-founded over all the integers: if we include the negative integers, we can go down forever.  Another example of a well-founded relations is the proper subset relation over the finite sets.
 
 
  A well-founded relation $\prec$ is irreflexive; that is,  $\var{x} \expsub{\nprec}{\,w} \var{x}$, because if $x \expsub{\prec}{w} \,x$  for some $x$,   $\{x, x, x, \ldots \}$ would constitute an infinite decreasing sequence. It is also antisymetric; that is,  $\unot(\var{x} \expsub{\prec}{w} \,\var{y} \uand \var{y} \expsub{\prec}{w} \,\var{x})$ because if $x \expsub{\prec}{w} \,y$ and $y \expsub{\prec}{w} \,x$ for some $x$ and $y$,  $\{x, y, x,y, x, y \ldots \}$ would constitute an infinite decreasing sequence.  We do not assume that well-founded relations are transitive;  for instance, the predecessor relation $\texttt{prec}$, defined on the natural numbers by $\texttt{prec}(\var{x}, \var{y})$ if $\var{x} + 1 = \var{y}$, is well-founded but not transitive.
 
  
 
 According to the induction principle over a well-founded relation $\expsub{\prec}{w}$, if we are trying to prove a proposition $\mathcal{P}[a]$, we can assume inductively that the proposition $\mathcal{P}[\var{x}]$ holds for any entity $\var{x}$ such that $\var{x} \expsub{\prec}{w} \,a$, that is, such that \var{x} is less than $a$ with respect to $\expsub{\prec}{w}$.  In other words, we prove $\mathcal{P}[a]$ under the induction hypothesis $\var{x} \expsub{\prec}{w} \,a  \, \uimplies \mathcal{P}[\var{x}]$.
 
 Well-founded induction is also called \emph{Noetherian induction}.  Over the natural numbers, well-founded induction over $<$ is usually called \emph{complete induction}. Our reason for using well-founded induction is that it is domain independent and extremely general; the same induction principle applies to nonnegative integers, expressions, substitutions, and other sorts of entities.
 
 We can give an informal justification for the well-founded induction principle as follows.  Suppose that, contrary to the principle, we have a proposition $\mathcal{P}[\expsub{a}{0}]$ that is false under a given model but for which the induction hypothesis  $\var{x} \expsub{\prec}{w} \,\expsub{a}{0} \, \uimplies \mathcal{P}[\var{x}]$ is true.  If $\mathcal{P}[\var{x}]$ were true for every entity $\var{x}$ such that $\var{x} \expsub{\prec}{w} \,\expsub{a}{0}$, the induction hypothesis would imply that $\mathcal{P}[\expsub{a}{0}]$ were true too, but it isn't.  Hence there must be some entity $\expsub{a}{1}$ such that $\expsub{a}{1} \expsub{\prec}{w} \,\expsub{a}{0}$, that is, $\expsub{a}{0} \expsub{\succ}{w} \, \expsub{a}{1}$  but $\mathcal{P}[\expsub{a}{1}]$ is false.  Repeating the same reasoning on $\expsub{a}{1}$, we establish the existence of an entity  $\expsub{a}{2}$ such that  $\expsub{a}{1} \expsub{\succ}{w} \, \expsub{a}{2}$  but $\mathcal{P}[\expsub{a}{2}]$ is false. In this way, we can construct an infinite decreasing sequence $\{\expsub{a}{0}, \expsub{a}{1}, \expsub{a}{2}, \ldots \} $, that is, one such that  $\expsub{a}{0} \, \expsub{\succ}{w} \, \expsub{a}{1} \, \expsub{\succ}{w} \, \expsub{a}{2} \, \expsub{\succ}{w} \,\ldots ,$ contradicting the well-foundedness of $\expsub{\prec}{w}$.
 
 In a well understood theory, such as the theory of expressions, there will be an arsenal of well-founded relations. 

 \paragraph{Proper-Subexpression Relation.} The proper-occurrence relation $\occursin$ is well-founded in the theory of expressions, since we only consider finite expressions.  To see this, recall that a proper subexpression of a given expression must be strictly smaller that the expression; in other words, 
  \[\e{1} \occursin \e{2} \uimplies \size(\e{1})  < \size(\e{2}).\]
 \noindent Thus, if there were an infinite decreasing sequence of expressions with respect to the proper-subexpression relation, their sizes would form an infinite decreasing sequence of nonnegative integers, which is impossible.



 Constructing non-trivial programs, including the unification algorithm, requires combining known well-founded relations to construct new ones peculiarly appropriate to the program being constructed. We now discuss ways of doing this.
     \subsubsection{Induced Relation.} For any unary function symbol $g$, we define the well-founded relation $\expsub{\prec}{g(w)}$ \emph{induced by $g$ and $\expsub{\prec}{w}$} by the property
 \[\var{x} \expsub{\prec}{g(w)} \var{y} \uiff g(\var{x}) \, \expsub{\prec}{w} \, g(\var{y}).\]
 \noindent If $\expsub{\prec}{w}$ is well-founded, so is  $\expsub{\prec}{g(w)}.$  For, if $\expsub{\prec}{w}$ is well-founded but $\expsub{\prec}{g(w)}$ is not.   there is an infinite sequence $\{\expsub{a}{0}, \expsub{a}{1}, \expsub{a}{2}, \ldots \}$ such that  \[\expsub{a}{0} \, \expsub{\succ}{g(w)} \, \expsub{a}{1} \, \expsub{\succ}{g(w)} \, \expsub{a}{2} \, \expsub{\succ}{g(w)} \,\ldots .\]  But then, by the definition of the induced relation,  \[g(\expsub{a}{0}) \, \expsub{\succ}{w} \, g(\expsub{a}{1}) \, \expsub{\succ}{w} \, g(\expsub{a}{2}) \, \expsub{\succ}{w} \,\ldots;\] that is, there is an infinite decreasing sequence with respect to $\expsub{\prec}{w}$, contradicting the well-foundedness of $\expsub{\prec}{w}$.

 This is a case in which we use a complex term to stand for a relation.  In the implementation, we use reification to squeeze this into first-order logic. 

 \paragraph{Vars and Size Relations.} The \emph{vars} ordering $\expsub{\prec}{vars(\subset)}$  is defined as the relation induced by the function $\vars$ and the subset ordering $\subset.$  For two expressions $\e{1}$ and $\e{2}$, we define the ordering $\expsub{\prec}{vars(\subset)}$ by 
\[   \expsub{e}{1}    \expsub{\prec}{vars(\subset)} \expsub{e}{2} \uiff \vars(\expsub{e}{1}) \, \subset \, \vars(\expsub{e}{2}).\]
\noindent Because the subset ordering is well-founded on finite sets, the relation $\expsub{\prec}{vars(\subset)}$ is well-founded on expressions.  
We abbreviate this ordering as $\expsub{\prec}{vars}$.


Similarly, the \emph{size} ordering $\expsub{\prec}{size(<)}$  is defined for expressions $\e{1}$ and $\e{2}$ by
\[   \expsub{e}{1}    \expsub{\prec}{size(<)} \expsub{e}{2} \uiff \size(\expsub{e}{1}) \, < \, \size(\expsub{e}{2}).\]
Because the less-than ordering is well-founded on the nonnegative integers, the \emph{size} ordering is well-founded on expressions. We abbreviate this ordering  as $\expsub{\prec}{size}$. 

If $e$ is a nonatomic expression, we can establish that
$\lef(e) \expsub{\prec}{vars}\, e$ and \allowbreak $\rig(e) \expsub{\prec}{vars}\, e$ and that $\lef(e) \expsub{\prec}{size}\, e$ and \allowbreak $\rig(e) \expsub{\prec}{size}\, e$. This follows because $\lef(e)$ and $\rig(e)$ are proper subexpressions of $e$.

  
\subsubsection{Weakly Decreasing Sequences.}  

 
  For any relation $\expsub{\prec}{w}$, we define its \emph{reflexive closure} $\preccurlyeq$ by the property
 \[\var{x} \expsub {\preccurlyeq}{w} \var{y} \uiff 
 [\var{x} \expsub{\prec}{ w} \, \var{y} \uor  \var{x} = \var{y}].\] 

 \noindent For instance, the reflexive closure $\expsub{\preccurlyeq}{vars}$ of the vars relation $\expsub{\prec}{vars}$ is defined by
 \[ \expsub{e}{1} \expsub{\preccurlyeq}{vars}\, \expsub{e}{2} \uiff  
[\expsub{e}{1} \expsub{\prec}{ vars} \, \expsub{e}{2} \uor  \expsub{e}{1} = \expsub{e}{2}] \uiff
[\expsub{e}{1} \subset \expsub{e}{2} \uor  \expsub{e}{1} = \expsub{e}{2}] \uiff
 \expsub{e}{1} \subseteq \expsub{e}{2}. \]

A sequence $a = \{\expsub{a}{0}, \expsub{a}{1}, \expsub{a}{2}, \ldots\}$ is \emph{weakly decreasing}
 with respect to a relation $\expsub{\prec}{w}$ if 
 $\expsub{a}{0} \, \expsub{\succcurlyeq}{\expsub{w}{2}} \, \expsub{a}{1} \, \expsub {\succcurlyeq}{\expsub{w}{2}} \, \expsub{a}{2} \, \expsub {\succcurlyeq}{\expsub{w}{2}} \, \expsub{a}{3} \ldots. $  
 
 As a first example of well-founded induction, we can prove the following \emph{weakly-decreasing sequence property} of well-founded relations: 
 a sequence $a = \{\expsub{a}{0}, \expsub{a}{1}, \expsub{a}{2}, \ldots\}$ that is weakly decreasing with respect to a well-founded relation $\expsub{\prec}{w}$ either converges or contains as an initial subsequence a (strictly) decreasing subsequence $a' = \{\expsub{a}{0}',  \expsub{a}{1}',\, \expsub{a}{2}',\, \ldots\}  $ with respect to $\expsub{\prec}{w}$, where $\expsub{a}{0}'$, is equal to $\expsub{a}{0}$.  The proof is an example of well-founded induction over the relation $\expsub{\prec}{w}$.  
 
 We prove this property under the induction hypothesis that the property holds for all entities $\var{x}$ such that $\var{x} \expsub{\prec}{w} \, \expsub{a}{0}$. 
 In the case that all the elements of the sequence $a$ are equal, the sequence converges by definition.  Otherwise, there must be some element of the sequence, $\expsub{a}{j}$, such that $\expsub{a}{0} = \expsub{a}{1} = \ldots = \expsub{a}{j-1} \expsub{\succ}{w} \, \expsub{a}{j}$.  Because 
 $ \expsub{a}{j}\expsub{\prec}{w} \, \expsub{a}{0}$,
 our induction hypothesis tells us that either the subsequence  $\{\expsub{a}{j}, \,  \expsub{a}{j+1}, \,  \expsub{a}{j+2}, \ldots\}$  converges, in which case $a$ also converges,  or the subsequence  has an initial strictly decreasing subsequence $\{\expsub{a}{j}, \,  \expsub{a'}{j+1}, \, \expsub{a'}{j+2}, \ldots\}$, in which case $\{\expsub{a}{0}, \, \expsub{a}{j}, \, \expsub{a'}{j+1}, \,  \expsub{a'}{j+2}, \ldots\}$  is an initial strictly decreasing subsequence of $a$, as we wanted to show.

\subsubsection{Well-Founded Relations on Tuples.} For the synthesis of recursive programs with more than one argument, we form them into a tuple that we treat as a single entity.  For this situation, it is necessary to discuss well-founded relations on tuples, which can be constructed from well-founded relations on single arguments.  We begin discussing well-founded relations on pairs (2-tuples), with the understanding that this can be extended to triples or general $n$-tuples, i.e.,  tuples of $n$ elements.

 
 
 % Pairs are the same as conses ($\cons$), but with a different notation.  For two elements $\var{x}$ and $\var{y}$, we write $\langle \var{x}, \var{y}\rangle$ for a pair, a tuple of two elements. Two pairs are equal precisely when their respective elements are equal; that is,
 % \[
 % \begin{split}
 % &\langle \expsub{\var{x}}{1}, \, \expsub{\var{x}}{2}\rangle =
 % \langle \expsub{\var{y}}{1}, \,\expsub{\var{y}}{2}\rangle \uiff \\
 % &\expsub{\var{x}}{1} = \expsub{\var{y}}{1} \, \uand \,
 % \expsub{\var{x}}{2} = \expsub{\var{y}}{2}. 
 % \end{split}
 % \]

 
 If we have a well-founded relation, we can extend it to a well-founded relation on pairs simply by ignoring one of the components.  For instance, if $\expsub{\prec}{w}$ is a relation, then the relation $\expsub{\prec}{\ufirst(w)}$ on pairs induced by the function $\ufirst$ satisfies the condition
  \begin{alignat*}{2}
  \begin{split}
 &\langle \varsub{x}{1}, \,  \varsub{x}{2}\rangle \, \expsub{\prec}{\ufirst(w)} 
    \langle \varsub{y}{1}, \,  \varsub{y}{2}\rangle  \uiff \\
  &\ufirst(\langle \varsub{x}{1}, \,  \varsub{x}{2}\rangle) \, \expsub{\prec}{w} 
    \ufirst(\langle \varsub{y}{1}, \,  \varsub{y}{2}\rangle) \uiff \\
  &\varsub{x}{1}\expsub{\prec}{w} 
   \varsub{y}{1}
  \end{split}
\end{alignat*} 
We have shown that if a relation is well-founded, the relation induced on it by a function is also well-founded.  Thus, if $\expsub{\prec}{w}$ is well-founded, so is $\expsub{\prec}{\ufirst(w)}$. Intuitively speaking, any infinite sequence of pairs that is decreasing if we ignore the first elements will correspond to an infinite decreasing sequence of individual elements; thus if the sequence of individual elements cannot exist, neither can the sequence of pairs.

Similarly, if we have a well-founded relation on pairs, we can induce a corresponding well-founded relation on triples, and so on.


In the theory of expressions, the \emph{vars} relation, satisfying the property
 \[ \langle  \expsub{d}{1}, \expsub{d}{2} \rangle   
  \expsub{\prec}{vars} 
      \langle  \expsub{e}{1}, \expsub{e}{2} \rangle
      \uiff \vars(\langle  \expsub{d}{1}, \expsub{d}{2} \rangle ) \, \subset \, \vars(\langle  \expsub{e}{1}, \expsub{e}{2} \rangle),\] 
      and the \emph{size} relation, satisfying the property
      \[ \langle  \expsub{d}{1}, \expsub{d}{2} \rangle   
  \expsub{\prec}{size} 
      \langle  \expsub{e}{1}, \expsub{e}{2} \rangle
      \uiff \size(\langle  \expsub{d}{1}, \expsub{d}{2} \rangle ) < \size(\langle  \expsub{e}{1}, \expsub{e}{2} \rangle),\] 
      are well-founded on tuples of expressions. These are the relations induced on pairs of expressions by the functions $\vars$ and $\size$ and the well-founded relations $\subset$ and $<$, respectively.

      Because we know that, if the expression $e$ is nonatomic, we have $\lef(e) \occursin e$ and $\rig(e) \occursin e,$ we can establish that
      \[\langle  \lef(\e{1}), \lef(\e{2}) \rangle \expsub{\prec}{vars} 
      \langle  \e{1}, \e{2} \rangle
      \] 
      and     
      \[\langle  \rig(\e{1}), \rig(\e{2}) \rangle \expsub{\prec}{vars} 
      \langle  \e{1}, \e{2} \rangle. \]
  
 


\subsubsection{Lexicographic Combination of Well-Founded Relations.}
\begin{quote}
Little man can beat a big man every time if he's in the right and keeps a-coming.
\\---Texas Rangers' creed.
\end{quote}

 For any two binary relations $\expsub{\prec}{\expsub{w}{1}}$ and  $\expsub{\prec}{\expsub{w}{2}}$, we define their \emph{lexicographic combination} $\expsub{\prec}{\lex(\expsub{w}{1}, \expsub{w}{2})}$ on pairs by the property
 \begin{alignat*}{2}
  \begin{split}
  &\langle \varsub{x}{1}, \,  \varsub{x}{2}\rangle \, \expsub{\prec}{\lex(\expsub{w}{1}, \expsub{w}{2})} \langle \varsub{y}{1}, \,  \varsub{y}{2}\rangle
  \uiff \\
  &\left(\begin{aligned}
  &\varsub{x}{1} \expsub{\prec}{\expsub{w}{1}} \, \varsub{y}{1} \, \uor \, \\
  &\varsub{x}{1} = \varsub{y}{1} \uand
  \varsub{x}{2} \expsub{\prec}{\expsub{w}{2}} \, \varsub{y}{2}  
  \end{aligned}\right).
  \end{split}
\end{alignat*} 

%   $\begin{aligned}[t] &= a \\ &=b\end{aligned}$ 

 
%   \begin{alignat*}{2}
%  & 
%  \left[\begin{aligned}
%   &\mgi (\thet{0}, \d{l}, \e{l}, \thet{1})
%   \, \uand \\
%   &\mgi (\thet{1}, \d{r}, \e{r}, \thet{2}) 
%   \end{aligned}\right]\\
%   &\operatorname{then} 
%   \mgi(\thet{0}, (\d{l} {\cons} \d{r}), (\e{l} {\cons} \e{r}), \thet{2}). 
%   \end{alignat*} 
  
%  \[ \left(
%     &{\begin{aligned}
%   &&&\varsub{x}{1} \expsub{\prec}{\expsub{w}{1}} \, \varsub{y}{1} \, \uor \, \\
%   &&&\varsub{x}{1} = \varsub{y}{1} \uand \varsub{x}{2} \expsub{\prec}{\expsub{w}{2}} \, \varsub{y}{2} \, \uor \, \\
%   &&&\varsub{x}{1} = \varsub{y}{1} \uand \varsub{x}{2} = \varsub{y}{2} \uand
%   \varsub{x}{3} \expsub{\prec}{\expsub{w}{3}} \, \varsub{y}{3}
%   %\end{aligned}
%   \right)
%   \]
 
%  \begin{alignat*}{2}
%  % \begin{aligned}[t]
%     &\langle \varsub{x}{1}, \,  \varsub{y}{1},\,  \varsub{z}{1}\rangle \, \expsub{\prec}{\lex(\expsub{w}{1}, \expsub{w}{2}, \expsub{w}{3})} \langle \varsub{x}{2}, \,  \varsub{y}{2} , \,  \varsub{z}{2}\rangle
%   \uiff \\
% %&{\begin{alignat*}{1}
%   &\left(
%     &{\begin{aligned}
%   &&&\varsub{x}{1} \expsub{\prec}{\expsub{w}{1}} \, \varsub{y}{1} \, \uor \, \\
%   &&&\varsub{x}{1} = \varsub{y}{1} \uand \varsub{x}{2} \expsub{\prec}{\expsub{w}{2}} \, \varsub{y}{2} \, \uor \, \\
%   &&&\varsub{x}{1} = \varsub{y}{1} \uand \varsub{x}{2} = \varsub{y}{2} \uand
%   \varsub{x}{3} \expsub{\prec}{\expsub{w}{3}} \, \varsub{y}{3}
%   %\end{aligned}
%   \right)
% %  \end{alignat*}.}
%  %   \end{aligned}
%   \end{alignat*}

  

 
  Sometimes we find it more convenient to use the logically equivalent \emph{reflexive lexicographic property}
\begin{alignat*}{2}
   \begin{split}
  &\langle \varsub{x}{1}, \,  \varsub{x}{2}\rangle \, \expsub{\prec}{\lex(\expsub{w}{1}, \expsub{w}{2})} 
   \langle \varsub{y}{1}, \,  \varsub{y}{2}\rangle
  \uiff \\
 &\left(\begin{aligned}
  &\varsub{x}{1} \expsub{\prec}{\expsub{w}{1}} \, \varsub{y}{1} \, \uor \, \\
  &\varsub{x}{1} \expsub{\preccurlyeq}{\expsub{w}{1}} \, \expsub{\var{y}}{1}\uand
  \varsub{x}{2} \expsub{\prec}{\expsub{w}{2}} \, \varsub{y}{2}
  \end{aligned}\right).
\end{split}
\end{alignat*}
  
  \noindent It is easy to see that the definition implies the reflexive lexicographic property, because $\varsub{x}{1} = \varsub{y}{1}$ implies $\varsub{x}{1} \expsub{\preccurlyeq}{\expsub{w}{1}} \, \expsub{\var{y}}{1}$. 
  In the other direction, if the right side of the reflexive lexicographic property holds and the first disjunct $\varsub{x}{1} \expsub{\prec}{\expsub{w}{1}} \, \varsub{y}{1}$ is true, then  the right side of the definition holds.
  But suppose the right side of the reflexive lexicographic property holds but the first disjunct $\varsub{x}{1} \expsub{\prec}{\expsub{w}{1}} \, \expsub{\var{y}}{1}$ is false;  then the second disjunct \[[\varsub{x}{1} \expsub{\preccurlyeq}{\expsub{w}{1}} \, \expsub{\var{y}}{1} \uand
  \varsub{x}{2} \expsub{\prec}{\expsub{w}{2}} \, \expsub{\var{y}}{2}]\bigr]\] is true and hence [because $\varsub{x}{1} \expsub{\prec}{\expsub{w}{1}} \, \expsub{\var{y}}{1}$ is false]
  \[ [\varsub{x}{1} = \expsub{\var{y}}{1} \uand \varsub{x}{2} \expsub{\prec}{\expsub{w}{2}} \, \expsub{\var{y}}{2}]. \]
Hence the right side of the definition holds.

 We can extend this definition to apply to three or more binary relations. For instance, for three relations the definition is
  \begin{alignat*}{2}
  \begin{split}
  &\langle \varsub{x}{1}, \,  \varsub{x}{2}, \,  \varsub{x}{3}\rangle \, \expsub{\prec}{\lex(\expsub{w}{1}, \expsub{w}{2}, \expsub{w}{3})} \langle \varsub{y}{1}, \,  \varsub{y}{2}, \,  \varsub{y}{3}\rangle
  \uiff \\
  &\left(\begin{aligned}
  &\varsub{x}{1} \expsub{\prec}{\expsub{w}{1}} \, \varsub{y}{1} \, \uor \, \\
  &\varsub{x}{1} = \varsub{y}{1} \uand
  \varsub{x}{2} \expsub{\prec}{\expsub{w}{2}} \, \varsub{y}{2}\, \uor \, \\
  &\varsub{x}{1} = \varsub{y}{1} \uand \varsub{x}{2} = \varsub{y}{2} \uand
  \varsub{x}{3} \expsub{\prec}{\expsub{w}{3}} \, \varsub{y}{3}
  \end{aligned}\right).
  \end{split}
\end{alignat*} 

  
  
 If $\expsub{\prec}{\expsub{w}{1}}$ and $\expsub{\prec}{\expsub{w}{2}}$ are both well-founded relations, so is their lexicographic combination $\expsub{\prec}{\lex(\expsub{w}{1}, \expsub{w}{2})}$.  For suppose, to the contrary, there is an infinite decreasing sequence of pairs $\{\langle\expsub{a}{0}, \expsub{b}{0}\rangle, \langle\expsub{a}{1}, \expsub{b}{1}\rangle, \langle\expsub{a}{2}, \expsub{b}{2}\rangle, \ldots \}$, that is, one such that
  \[\langle\expsub{a}{0}, \expsub{b}{0}\rangle \, \expsub{\succ}{\lex(\expsub{w}{1}, \expsub{w}{2})} \, \langle\expsub{a}{1}, \expsub{b}{1}\rangle \, \allowbreak \expsub{\succ}{\lex(\expsub{w}{1}, \expsub{w}{2})} \,\allowbreak \langle\expsub{a}{2}, \expsub{b}{2}\rangle \, \expsub{\succ}{\lex(\expsub{w}{1}, \expsub{w}{2})} \,\ldots .\]   By the definition of the lexicographic combination, we know that, for each natural number $i$, we have either
   \begin{align*}
       & \expsub{a}{i} \expsub{\succ}{\expsub{w}{1}} \, \expsub{a}{i+1} \uor  && [\textit{the $\expsub{\prec}{\expsub{w}{1}}$ case for $i$}]\\ 
       & \expsub{a}{i} = \expsub{a}{i+1}  \uand
 \expsub{a}{i} \expsub{\succ}{\expsub{w}{2}} \,\expsub{a}{i+1})  && [\textit{the $\expsub{\prec}{\expsub{w}{2}}$ case for $i$}].
   \end{align*}
   \noindent In either case, we have $\expsub{a}{i} \expsub{\succcurlyeq}{\expsub{w}{1}} \, \expsub{a}{i+1}$ for each natural number $i$.  But since $\expsub{\prec}{\expsub{w}{1}}$ is well-founded, we know (from the \emph{weakly-decreasing sequence property}) that the sequence cannot weakly decrease indefinitely and hence must converge at some natural number $j$; thus for each $k$ such that $k \geq j,$ we have $\expsub{a}{k}  =  \expsub{a}{k+1}.$   But then (by the irreflexivity of well-founded relations), for each $k$ such that $k \geq j,$ the  $\expsub{\prec}{\expsub{w}{1}}$ case for $k$ cannot hold, and therefore the $\expsub{\prec}{\expsub{w}{2}}$ case for $k$ must hold.
   Hence, for each $k$ such that $k \geq j,$ we have $\expsub{a}{k} \expsub{\succ}{\expsub{w}{2}} \,\expsub{a}{k+1},$ but this contradicts the well-foundedness of $\expsub{\prec}{\expsub{w}{2}}$.  Therefore no decreasing sequence of pairs can exist under the lexicographic combination, so the lexicographic combination must be well-founded.
   
   \subsubsection{Lexicographic  Combination of Induced Relations.}  In the derivation of the unification algorithm, we find it convenient to use a \emph{lexicographic combination of induced relations.}   While the construction is quite general, we describe it in a special case that resembles its use in the unification derivation.  We define the lexicographic combination $\expsub{\prec}{\lex(\vars,\size)}$ of the \emph{vars} relation $\expsub{\prec}{vars}$ and the \emph{size} relation  $\expsub{\prec}{\size}$ by the property
   \begin{alignat*}{2}
  \begin{split}
  &\e{1} \, \expsub{\prec}{\lex(\vars,\size)}\, \e{2}
  \uiff \\
  &\left(\begin{aligned}
  &\vars(\e{1}) \subset \, \vars(\e{2})\, \uor \, \\
  &\vars(\e{1}) = \, \vars(\e{2}) \uand
 \size(\e{1}) < \, size(\e{2})\,
  \end{aligned}\right).
  \end{split}
  \end{alignat*}
  In other words, with respect to the lexicographic combination, 
$\e{1}$ is less than $\e{2}$ if the variable set of $\e{1}$ is a proper subset of variable set of $\e{2}$, or if the variable set of $\e{1}$ equals the variable set of $\e{2}$ and the size of $\e{1}$ is  less than the size of $\e{2}$.

This is well-founded, because it is the relation induced by a function on simpler well-founded relation.  The function is the function $\varssize$,  defined by 
\[vars\!\!-\!\!size(e) = \langle vars(e), size(e) \rangle,\]
which maps any expression into the pair of its variable set and its size. 
The simpler well-founded relation is the lexicographic relation $\expsub{\prec}{\lex(\subset, <)}$, defined by 
\begin{alignat*}{2}
  \begin{split}
  &\langle s_{1}, n_{1}\rangle \,  \expsub{\prec}{\lex(\subset, <)}\, \langle s_{2},n_{2} \rangle
  \uiff \\
  &\left(\begin{aligned}
  &s_{1} \subset \, s_{2}\, \uor \, \\
  &s_{1} = \, s_{2} \uand
 n_{1} < \, n_{2}\,
  \end{aligned}\right),
  \end{split}
  \end{alignat*} 
 which is the lexicographic combination of the proper-subset relation $\subset$ on the finite sets and the less-than relation $<$ on the nonnegative integers. 

 The relation $\expsub{\prec}{\lex(\vars,\size)}$ is the relation  $\expsub{\prec}{\varssize(\lex(\subset, <))}$ induced by function 
$\varssize$ on the above relation $\expsub{\prec}{\lex(\subset, <)}$, because
\[\e{1}  \expsub{\prec}{\varssize(\lex(\subset, <))} \e{2} \]
is equivalent [by the definition of induced relation] to
\[\varssize(\e{1}) \expsub{\prec}{\lex(\subset, <)} \varssize(\e{2}),\]
which is equivalent [by the definition of $\varssize$] to
\[\langle\vars(\e{1}), \size(\e{1})\rangle \, \expsub{\prec}{\lex(\subset, <)} \langle \vars(\e{2}), \size(\e{2})\rangle,\]
which is equivalent [by the definition of $\lex(\subset, <)$] to
\begin{alignat*}{2}
  \begin{split}
  &\left(\begin{aligned}
  &\vars(\e{1}) \subset \, \vars(\e{2})\, \uor \, \\
  &\vars(\e{1}) = \, \vars(\e{2}) \uand
 \size(\e{1}) < \, \size(\e{2})\,
  \end{aligned}\right),
  \end{split}
  \end{alignat*}
 which is equivalent [by the definition of $\expsub{\prec}{\lex(\vars,\size)}$] to
\[\e{1} \, \expsub{\prec}{\lex(\vars,\size)}\, \e{2}.\]
 









\begin{comment}
 $\expsub{\prec}{\lex(\subset, <)}$, is defined by
\begin{alignat*}{2}
  \begin{split}
  &\langle s_{1}, n_{1}\rangle \,  \expsub{\prec}{\lex(\subset, <)}\, \langle s_{2},n_{2} \rangle
  \uiff \\
  &\left(\begin{aligned}
  &\vars(\e{1}) \subset \, \vars(\e{2})\, \uor \, \\
  &\vars(\e{1}) = \, \vars(\e{2}) \uand
 \size(\e{1}) < \, \size(\e{2})\,
  \end{aligned}\right).
  \end{split}
  \end{alignat*}
 which is the lexicographic combination of the proper-subset relation $\subset$ on the finite sets and the less-than relation $<$ on the nonnegative integers.
 \end{comment}

Because the component relations $<$ and $\subset$ are well founded on finite sets and nonnegative integers, their lexicographic combination is well-founded on the pairs, and so is the relation induced by the function $\varssize$ onto the lexicographic relation.


Sometimes we find it more convenient to use the equivalent \emph{reflexive lexicographic property} of the lexicographic combination of relations,

\begin{alignat*}{2}
  \begin{split}
  &\e{1} \, \expsub{\prec}{\lex(\vars,\size)}\, \e{2}
  \uiff \\
  &\left(\begin{aligned}
  &\vars(\e{1}) \subset \, \vars(\e{2})\, \uor \, \\
  &\vars(\e{1}) \subseteq \, \vars(\e{2}) \uand
 \size(\e{1}) < \, size(\e{2})\,
  \end{aligned}\right).
  \end{split}
  \end{alignat*}


 \begin{alignat*}{2}
  \begin{split}
  &\e{1} \, \expsub{\prec}{\lex(\size, \vars)}\, \e{2}
  \uiff \\
  &\left(\begin{aligned}
  &\e{1} \expsub{\prec}{size}\, \e{2}\, \uor \, \\
  &\e{1} \expsub{\preccurlyeq}{size}\, \e{2}\ \uand
 \e{1} \expsub{\prec}{vars}\, \e{2}\,
  \end{aligned}\right).
  \end{split}
\end{alignat*} 
\begin{comment}
\noindent It is easy to see that the definition implies the reflexive lexicographic property, because $\expsub{g}{1}(\var{x}) = \expsub{g}{1}(\var{y})$ implies $\expsub{g}{1}(\var{x})\, \expsub{\preccurlyeq}{\expsub{w}{1}} \, \expsub{g}{1}(\var{y})$. 
  In the other direction, if the right side of the reflexive lexicographic property holds and the first disjunct $\expsub{g}{1}(\var{x}) \expsub{\prec}{\expsub{w}{1}} \, \expsub{g}{1}(\var{y})$ is true, then  the right side of the definition holds.
  But suppose the right side of the reflexive lexicographic property holds but the first disjunct $\expsub{g}{1}(\var{x}) \expsub{\prec}{\expsub{w}{1}} \, \expsub{g}{1}(\var{y})$ is false;  then the second disjunct \[[\expsub{g}{1}(\var{x}) \expsub{\preccurlyeq}{\expsub{w}{1}} \, \expsub{g}{1}(\var{y}) \uand
  \varsub{x}{2} \expsub{\prec}{\expsub{w}{2}} \, \expsub{g}{2}(\var{y})]\] is true and hence [because $\expsub{g}{1}(\var{x}) \expsub{\prec}{\expsub{w}{1}} \, \expsub{g}{1}(\var{y})$ is false]
  \[ [\expsub{g}{1}(\var{x}) = \expsub{g}{1}(\var{y}) \uand \varsub{x}{2} \expsub{\prec}{\expsub{w}{2}} \, \expsub{g}{2}(\var{y})]. \]
  But that is the right side of the definition.
\end{comment}
\begin{comment}
    

We can formulate an equivalent reflexive version of the above definition:

\vspace{-10pt}
 \begin{alignat*}{2}
  \begin{split}
  &\var{x} \, \expsub{\prec}{\lex(\expsub{g}{1}(\expsub{w}{1}),\, \expsub{g}{2}(\expsub{w}{2}))}\, \var{y}
  \uiff \\
  &\left\{\begin{aligned}
  &\expsub{g}{1}(x) \expsub{\prec}{\expsub{w}{1}} \, \expsub{g}{1}(y) \, \uor \, \\
  & \expsub{g}{1}(x) \expsub{\preceq}{\expsub{w}{1}} \, \expsub{g}{1}(y) \,  \uand
  \expsub{g}{2}(x) \expsub{\prec}{\expsub{w}{2}} \, \expsub{g}{2}(y) 
  \end{aligned}\right\}.
  \end{split}
\end{alignat*} 
\end{comment}

\begin{comment}
For example, take $\expsub{g}{1}$ and $\expsub{g}{2}$ to be the $\vars$ and $\size$ functions that map expressions into sets of variables and nonnegative integers, respectively.  Take $\expsub{\prec}{\expsub{w}{1}}$ and $\expsub{\prec}{\expsub{w}{2}}$ to be the proper subset relation $\subset$ and the less-than relation $<$ on sets of variables and nonnegative integers, respectively.  Then, because $\subset$ and $<$ are well-founded, so is the relation $\expsub{\prec}{w^*}$ defined by

\vspace{-16pt}
\begin{center}
\[
\begin{aligned}
& \var{e} \, \expsub{\prec}{w^*} \, \var{e'} \uiff \\
&\left\{
\begin{aligned}
&\vars(\var{e}) \subset \vars(\var{e'}) \uor \\
&\left[
\begin{aligned}
 &\vars(\var{e}) \subseteq \vars(\var{e'}) \uand \\
 &\size(\var{e}) < \size(\var{e'})
\end{aligned}
\right]
\end{aligned}
 \right\} .
\end{aligned}\]
\end{center}





We can extend this definition to apply to three or more binary relations. For instance, for three relations the definition is

\begin{alignat*}{2}
  \begin{split}
  &x \, \expsub{\prec}
  {\lex(\expsub{g}{1}(\expsub{w}{1}),\,\expsub{g}{2}(\expsub{w}{2}),\,\expsub{g}{3}(\expsub{w}{3}))}\, y
  \uiff \\
  &\left(\begin{aligned}
  &\expsub{g}{1}(x) \expsub{\prec}{\expsub{w}{1}} \, \expsub{g}{1}(y) \, \uor \, \\
  &\expsub{g}{1}(x) = \expsub{g}{1}(y) \uand
  \expsub{g}{2}(x) \expsub{\prec}{\expsub{w}{2}} \, \expsub{g}{2}(y) 
  \uor \\
  &\expsub{g}{1}(x) = \expsub{g}{1}(y) \uand
  \expsub{g}{2}(x) = \expsub{g}{2}(y) \uand
  \expsub{g}{3}(x) \expsub{\prec}{\expsub{w}{3}} \, \expsub{g}{3}(y) 
  \end{aligned}\right).
  \end{split}
\end{alignat*} 
\end{comment}
We actually  use the \emph{reflexive version} of the definition of $\expsub{\prec}{\lex(\vars,\size)}$, namely
  \begin{alignat*}{2}
  \begin{split}
  &\e{1} \, \expsub{\prec}{\lex(\vars,\size)}\, \e{2}
  \uiff \\
  &\left(\begin{aligned}
  &\vars(\e{1}) \subset \, \vars(\e{2})\, \uor \, \\
  &\vars(\e{1}) \subseteq \, \vars(\e{2}) \uand
 \size(\e{1}) < \, size(\e{2})\,
  \end{aligned}\right).
  \end{split}
  \end{alignat*}
 The derivation of this version is the same as the one for the nonreflexive version, except we use the reflexive version of the definition of $\expsub{\prec}{\lex(\subset, <)}$.


  
   
   \subsection{Specifications and Programs} 
   For this paper, we deal with a particular form of declarative specification and applicative program.
  
   
   \subsubsection{Specifications.}  We restrict our attention to the synthesis of applicative (side-effect-free) programs from declarative specifications.  We begin with a specification of the form 
  \begin{equation*} \uf(a) \Lleftarrow \operatorname{find} \var{Z} \operatorname{such} \operatorname{that} \mathscr{Q}[a, \, \var{Z}],
  \end{equation*}
  where $a$ is the input parameter and $\var{Z}$ is the output.  In other words, for a given input entity $a$, we want to find output entity $\var{Z}$ that satisfies the input-output condition $\mathscr{Q}[a, \, \var{Z}]$; that entity will be the output produced by the program $\uf(a)$ we are synthesizing.   The input-output condition $\mathscr{Q}[a, \, \var{Z}]$ is a formula that contains no variable other than $\var{Z}$. (Naturally, because we allow tuples of entities, all this extends to allow multiple inputs and outputs, too, or none at all.)
 \subsubsection{Primitive Symbols.}  We assume that logical connectives, the conditionaL operator, and certain of the constant, function, and relation symbols of the theory have been declared to be \emph{primitive}; intuitively, this means that assume we know how to compute them, and we allow them to appear in the program we are constructing.  A term or formula is said to be \emph{primitive} if every constant, function, or relation symbol or logical connective it contains is primitive.  A primitive term may contain variables. (If there are multiple output variables, each may have its own list of primitive symbols, but we will not need this nicety here.)  A primitive term can turn out to be equal to a non-primitive term, even though we know how to compute one but not the other.

 Most skolem functions are not primitive; they yield an entity we know exists but may not know how to find.   There may also  be other symbols that we include in the specification or in an axiom that we do not expect to appear in a final program.  For instance, if we are constructing a program to test if a natural number is prime, we might include the symbol $\emph{prime}$ in the specification but expect it to be deconstructed and not to appear explicitly in the final program. Thus, a computable term may be nonprimitive.

  
  \subsubsection{Programs.} Our programs are of the form 
  \begin{equation*}
      \uf(a) =  t,
  \end{equation*}
  
  \noindent where $t$ is a primitive term, called the \emph{body} of the program. Such a program is said to satisfy the above specification if, for every model of the theory, the corresponding instance $\mathscr{Q}[a, \, t]$ of the input-output condition is true.


We require that the output entries be primitive to ensure that the program is something we know how to compute. 
We do not require the body $t$ of the program to be ground (variable-free); if the body contains a variable, that variable can be replaced by any primitive ground term. By not instantiating the variable, we leave the program open to a wider variety of subsequent refinements and optimizations.

   
      \subsection{Deductive Tableaus}

            Resolution theorem provers such as \SNARK\ are refutation procedures, in which our conjectured theorem, and all its subgoals, are negated and put into a clausal form, in which $\uand$, $\uor$, and $\unot$ are the only logical connectives.  While this transformation allows efficient implementation, it also makes proofs difficult for people to follow. In our presentation, we introduce a notation, the \emph{deductive tableau}, which retains a distinction between assertions and goals, and allows the implication ($\uimplies$), reverse implication ($\uimpliedby$), and equivalence ($\uiff$) in formulas. The tableau also provides a representation for the incremental construction of a program as the proof proceeds.
      
        \subsubsection{The Structure.}   
            A derivation from a specification   \[ \uf(a) \Lleftarrow \operatorname{find} \var{Z} \operatorname{such} \operatorname{that} \mathscr{Q}[a, \, \var{Z}] \]
   is carried out with a tableau structure, a set of \emph{assertions} and \emph{goals}, which are formulas, each with an optional associated \emph{output entry}, a term.   
   \begin{center}
 %\begin{tabular}{|m{0.25\textwidth}| m{0.25\textwidth}||m{0.25\textwidth}|}
 \begin{tabular}{T}
 \hline
 \begin{center} Assertions \end{center} &  \begin{center} Goals \end{center} & \begin{center} $\,\uf(a)\,$\end{center}  \\ \hhline{|=|=|=|}
 \begin{center}$\expsub{\mathcal{A}}{i}$ \end{center} &  & \begin{center}$\expsub{t}{i}$\end{center} \\  \hline
         & \begin{center}$\expsub{\mathcal{G}}{j}$\end{center} & \begin{center}$\expsub{t}{j}$\end{center} \\
 
 \hline
\end{tabular}
\end{center}
 We introduce some apparatus to provide the meaning of a tableau with respect to the given specification.


\subsubsection{Allowable Outputs.} For any interpretation, a  term is an \emph{allowable output} of the tableau if it is primitive and is an instance  $\expsub{t}{i}\apply \theta$ of an output entry  $\expsub{t}{i}$ corresponding to either 

\begin{itemize}
\item[$\bullet$] a goal $\expsub{\mathcal{G}}{i}$ of the tableau such that the corresponding instance $\expsub{\mathcal{G}}{i}\apply \theta$ is true under the model, or
\item[$\bullet$] an assertion $\expsub{\mathcal{A}}{i}$ of the tableau such that the corresponding instance $\expsub{\mathcal{A}}{i}\apply \theta$ is false under the model.

\end{itemize}
If a goal row has no output entry, any term is allowable under an interpretation for which the goal is true.  If an assertion has no output entry, any term is allowable under an interpretation for which the assertion is false.

A transformation on tableaus preserves allowable output if, for a given interpretation, the allowable outputs before the transformation equal the allowable outputs afterwards.

\subsubsection{Correctness Condition of a Tableau.} In a given theory, with respect to a given specification, a tableau is said to satisfy the correctness condition if, for a given model $\mathcal{M}$ for the theory, any term that is allowed under $\mathcal{M}$ satisfies the input-output condition. A tableau is correct for a theory and specification if it satisfies the correctness condition for any model of the theory.

A transformation on tableaus preserves correctness with respect to a theory and specification if, for a given model, a term has the correctness condition before the transformation precisely when it has the correctness condition afterwards.  A transformation that preserves output entries for a model will also preserve the correctness condition. Consequently, if one tableau is correct in the theory with respect to the specification, so is the other.






%  If two tableaus satisfy the correctness condition for a given specification, they allow the same outputs with respect to any model. If we add new rows to a correct tableau without introducing new allowable outputs, the new tableau will also be correct.  If we replace some rows of a correct tableau with others that have the same allowable outputs, the new tableau will also be correct.






\subsubsection{Duality.}  There is a duality between assertions and goals; in fact, any row
 \begin{center}
\begin{tabular}{T}
\hline
 \begin{center}$\mathcal{A}$\end{center} & \begin{center}$\qquad$\end{center} & \begin{center}$t$\end{center}\\
 
 \hline
\end{tabular}
\end{center}
 
\noindent can be replaced by the row
 


   \begin{center}
\begin{tabular} {T}
\hline
    \begin{center}$\qquad$\end{center} & \begin{center}$ \unot(\mathcal{A})$\end{center} & \begin{center}$t$\end{center} \\
 
 \hline
\end{tabular}
\end{center}

\noindent while preserving the allowable outputs.  For, if there is a term that is an instance $t\apply \theta$ of the output entry, the corresponding instance of the goal, $ (\unot(\mathcal{A}))\apply \theta$, that is  $ \unot (\mathcal{A}\apply \theta)$, is true precisely when the corresponding instance of the assertion, $\mathcal{A}\apply \theta$, is false.


Because of duality, we could have phrased a derivation using only assertions, or only goals.  Indeed, the {\SNARK}  implementation of the deductive tableau uses only assertions; goals are negated, translated into clausal form, and put into the assertion column, but the distinction between assertions and goals can make a derivation easier to follow. Typically, forward reasoning is conducted in the assertion column and backward reasoning in the goal column.


\subsubsection{Splitting Rules.} We can split assertions that are conjunctions and goals that are disjunctions or implications into their components without changing the outputs allowed.  For instance, according to the \emph{implication splitting property}, a goal row 


 \begin{center}
\begin{tabular}{T}
\hline
 \begin{center}$\qquad$\end{center}  &  \begin{center}$\mathcal{A}\uimplies\mathcal{G}$\end{center} & \begin{center}$t$\end{center} \\
  \hline
\end{tabular}
\end{center}

\noindent can be replaced by the two rows


 \begin{center}
\begin{tabular}{T}
\hline
 \begin{center}$\mathcal{A}$\end{center} &   \qquad & \begin{center} $t$ \end{center} \\
  \hline
     &  \begin{center}$ \mathcal{G}$ \end{center} & \begin{center}$t$\end{center} \\
  \hline
\end{tabular}
\end{center}

\noindent without altering allowable output. For if, under a given model, $t \apply \theta$ is an instance of the output entry for which the corresponding instance of the original goal, $(\mathcal{A}\uimplies\mathcal{G})\apply \theta $, that is  $\mathcal{A}\apply \theta \uimplies\mathcal{G}\apply \theta, $ is true, then (by the truth table for $\uimplies$) either the corresponding instance of the assertion, $\mathcal{A}\apply \theta $, is false or the corresponding instance of the goal, $\mathcal{G}\apply \theta $, is true, and vice versa.  

There is also an analogous
\emph{and-splitting rule} that decomposes an assertion that contains a conjunction into two (or more) assertions, and an \emph{or-splitting rule} that decomposes a goal that contains a disjunction into two (or more) goals, without altering the output entries.  In our {\SNARK} implementation, and in resolution theorem provers in general, splitting is performed automatically in the transformation to clausal form. 

While in implementations, implication ($\uimplies$) and equivalence ($\uiff$) are paraphrased in terms of conjunction ($\uand$), disjunction ($\uor$), and negation ($\unot$) for efficiency,  our presentation  often leaves them intact to make the proof easier to understand.

\subsubsection{Instance Property.} If a tableau contains the assertion row

 \begin{center}
\begin{tabular}{T}
\hline
 \begin{center}$\mathcal{A}$\end{center} & $\qquad$ & \begin{center}$t$\end{center} \\
  \hline
\end{tabular}
\end{center}

\noindent we can add any instance of that row,

 \begin{center}
\begin{tabular}{T}
\hline
 \begin{center}$\mathcal{A}\apply \theta$\end{center} & $\qquad$ & \begin{center}$t\apply\theta$\end{center} \\
  \hline
\end{tabular}
\end{center}
\noindent without changing the allowable outputs. This is not itself a rule of our system---it would allow the introduction of many irrelevant rows---but it is used to justify rules.

To prove this, suppose (under a given interpretation) $(t\apply\theta)\apply \theta'$ is an instance of the new row for which the corresponding instance of the assertion $(\mathcal{A}\apply \theta) \apply \theta'$ is false.
In other word, by the composition property, $t\apply(\theta \compose \theta')$  is an instance of the new row for which the corresponding instance of the assertion $\mathcal{A}\apply (\theta \compose \theta')$ is false. Then, $t\apply(\theta \compose \theta')$ is an instance of the output entry for which the corresponding instance of the given assertion is false.

% For, suppose (under a given model) some instance $(\mathcal{A}\apply\theta)\apply \theta'$ of the new assertion is false.  That is (by the composition property)  the instance $\mathcal{A} \apply (\theta \compose \theta')$ of the original assertion is false under the model.  But since the given assertion row satisfies the correctness condition, the corresponding instance of the given output entry, $(t \apply (\theta \compose \theta')$ satisfies the input-output condition $\mathscr{Q}[a, \, t \apply (\theta \compose \theta')]$.  But then, by the  composition property again, the instance  
% $(t \apply \theta) \apply \theta'$ of the new output entry satisfies the input-output condition $\mathscr{Q}[a, \, (t\apply \theta) \apply \theta']$ for the new row, as we wanted to show.

Variables in goals behave as if they were existentially quantified, while in assertions they appear to be universally quantified; we use upper-case symbols for variables, to distinguish them. During a proof, in assertions or goals, our rules will be able to replace variables with other terms.


When the substitution is a permutation $\pi$, the row and its instance are interchangeable; if either is present, we can add the other without affecting the allowable outputs.  We have remarked that a permutations substitution has an inverse substitution $\pi^{-1}$.  If the tableau contains the instance row


 \begin{center}
\begin{tabular}{T}
\hline
  \begin{center}$\mathcal{A}\apply \pi$\end{center} & \qquad &  \begin{center}$t\apply\pi$\end{center} \\
  \hline
\end{tabular},
\end{center}
we can also add an instance of that instance, i.e., 
 \begin{center}
\begin{tabular}{T}
\hline
  \begin{center}$(\mathcal{A}\apply \pi) \apply \pi^{-1} $\end{center} &   $\qquad$ &  \begin{center}$(t\apply\pi) \apply \pi^{-1}$\end{center} \\
  \hline
\end{tabular},
\end{center}
which (by the composition property) is
 \begin{center}
\begin{tabular}{T}
\hline
  \begin{center}$\mathcal{A}\apply (\pi \compose \pi^{-1}) $\end{center} &   $\qquad$ &  \begin{center}$(t\apply (\pi \compose \pi^{-1}))$\end{center} \\
  \hline
\end{tabular},
\end{center}
which (because $\pi^{-1}$ is an inverse) is just the original row
 \begin{center}
\begin{tabular}{T}
\hline
  \begin{center}$\mathcal{A} $\end{center} &  \qquad &  \begin{center}$t$\end{center} \\
  \hline
\end{tabular}.
\end{center}

By duality, the instance properties hold for goals as well as assertions.  Thus, if a tableau contains a goal row, an instance of that row can be added without changing the allowable outputs, and the row may be replaced by a row to which a permutation substitution has been applied to its goal and its output entry.

In presenting a derivation, we freely rename the variables in a row to improve clarity.

\subsubsection{Orphaned Output Entries and Valid Assertions.} If the output entry of a goal row 
   \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ &  \begin{center}$ \mathcal{G}$\end{center} &  \begin{center}$\var{V}$\end{center} \\
 \hline
\end{tabular}
\end{center}
consists of a  new variable $\var{V}$, one that does not occur elsewhere in that row, then, according to the \emph{orphaned output-entry property}, we can drop the output entry and replace the row with
   \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ &  \begin{center}$ \mathcal{G}$\end{center} & $\qquad$\\
 \hline
\end{tabular}.
\end{center}
For, if $\mathcal{G}\apply \theta$ is true under an interpretation, the new row will allow any primitive term $t.$ However, we know $\mathcal{G}\apply 
 (\{\var{V} \mapsto t\} \addto \theta) $ is also true, since $\var{V}$ does not occur in $\mathcal{G}.$ Since $\var{V}\apply (\{\var{V} \mapsto t\} \addto \theta)$ is {t}, the replaced row also allows any primitive term.

 If a tableau row has multiple output entries, we can drop any of them if it is a variable that does not occur elsewhere in the row (including another output column.)

A formula that is valid in the theory can never be false in any model for the theory; hence that formula can be added to a tableau without changing the correctness of the tableau with respect to the theory and given specification. It never allows any new output entries in any model. 

Therefore, for a given theory,  we include in our tableau any formula that is a definition or axiom or has been previously proved in that theory. For instance, we have established in the theory of substitutions that a substitution is idempotent precisely when it is more-general-idempotent than itself.  Thus, we can include in a tableau for the theory the assertion



\noindent  
 \begin{center}
\begin{tabular}{T}
 \hline
\begin{center}
{\begin{align*}
&\idem(\Theta) \uiff   \\   
&\Theta \moregen \Theta
\end{align*}}
\end{center}
      &  & \\
\hline
\end{tabular}.
\end{center}
\noindent  We have made the substitution $\Theta$ a variable so the assertion will behave as if the substitution is universally quantified. $\Theta$ is the upper-case $\theta$.

For the derivation of the unification algorithm, we have proved the validity of all the added assertions that were not axiomatic, either by hand or by a separate deductive-tableau proof.  Adding a nonvalid assertion compromises the correctness of the final program.

  
\subsection{The Derivation Process}
\subsubsection{Initial Tableau.} For a given theory and a specification 
  \begin{equation*} \uf(a) \Lleftarrow \operatorname{find}\var{Z} \operatorname{such} \operatorname{that} \mathscr{Q}[a, \,\var{Z}],
  \end{equation*}
our initial tableau is


      \begin{center}
\begin{tabular}{T}
 \hline
  \begin{center}Assertions\end{center} &  \begin{center}Goals\end{center} &  \begin{center}$\uf(a)$\end{center} \\ \hhline{|=|=|=|}
 &   \begin{center}$\mathscr{Q}[a, \, \var{Z}] $\end{center} &  \begin{center}$\var{Z}$\end{center} \\ 
 
 \hline
\end{tabular}.
\end{center}
\noindent This is a tableau with a single row, a goal, with a single variable, the output entry. The tableau is correct with respect to the specification, for if $\theta$ is a substitution for which the instance of the goal $\mathscr{Q}[a, \, \var{Z}] \apply \theta$,  is true under a model of the theory, the corresponding instance of the output entry is $\var{Z} \apply \theta$ itself. But this expression is [by distributivity, because $\var{Z}$ is the only variable in the input-output condition] $\mathscr{Q}[a, \, \var{Z} \apply \theta]$.  Thus the initial tableau is correct with respect to the specification. The fact that we have used an upper-case symbol $\var{Z}$ in the goal indicates that it is a variable, and has tacit existential quantification; our rules can instantiate it freely in the course of the search for a proof.


  We actually allow multiple inputs and outputs.  When the input-output condition $\mathscr{Q}$ has no outputs, the tableau can be used as a simple theorem prover, to show the validity of $\mathcal{Q[a]}$ in the theory.
   

\subsubsection{Final Tableau} A deductive-tableau program derivation framework applies \emph{rules} to the tableau, which add or remove rows while maintaining correctness.  The process continues until we develop a \emph{final} row, which consists (in the \emph{assertion case}) of an assertion $\false$,   


 \begin{center}
\begin{tabular}{T}
\hline
 \begin{center}$\false$\end{center} & $\qquad$ & \begin{center}$t$\end{center} \\
 
 \hline
\end{tabular}
\end{center}

\noindent or (in the \emph{goal case}) a goal $\true$, i.e.

   \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & \begin{center}$\true$\end{center} & \begin{center}$t$\end{center} \\
 
 \hline
\end{tabular}.
\end{center}

We maintain correctness throughout;  hence (in the assertion case), if any instance of the assertion is false under a model, the corresponding instance of the output entry will satisfy the input-output condition,. For any substitution $\theta$, the instance of the assertion,  $\false \apply \theta$, that is, $\false$,  is  false under any model; hence the corresponding instance of the input-output condition   $\mathscr{Q}[a, \, t \apply \theta ]$, is satisfied.  (The goal case is similar.) 
From this derivation, we can extract the program
 \begin{equation*} \uf(a) =  t.
 \end{equation*}
 The program may still contain variables, but the correctness condition guarantees that any instance of the program will satisfy the specification. 
 
There may be many derivations from the same initial tableau, leading to different final tableaus and final programs, each satisfying the specification. 

 \subsection{Case Analysis and Conditional Program Formation} In a deductive approach, a conditional program structure is introduced as a result of a case analysis in the proof. 
 We describe the resolution rule and the equivalence and equality replacement rules, all of which perform case analysis and can introduce conditionals.
 
  \subsubsection{Resolution Rule.} 
 \begin{quote}
 Once you eliminate the impossible, whatever remains, no matter how improbable, must be the truth.
 \\---Arthur Conan Doyle, \emph{The Case-Book of Sherlock Holmes}, 1927
 \end{quote}

 Paradoxically, deriving the unification algorithm requires the resolution and equivalence and equality replacement rules, but these rules depend on the unification algorithm.
 
 We will first describe the resolution rule as it applies to two goals, but, by duality, it will also be applied to two assertions and to an assertion and a goal. We shall assume that the rows have no variables in common;  they are standardized apart if necessary.  By the instance property, this maintains the correctness of the tableau.



 Suppose we have developed two goal rows, of the form

   \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & \begin{center}$\uand\!(\expsub{\mathcal{P}}{1},\expsub{\mathcal{R}}{1})$\end{center} & \begin{center}$\expsub{t}{1}$\end{center} \\
  \hline
\end{tabular}
\end{center}
\noindent and
  \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ &  \begin{center}$ \uand\!(\!\unot(\expsub{\mathcal{P}}{2}),\expsub{\mathcal{R}}{2})$\end{center} &  \begin{center}$\expsub{t}{2}$\end{center} \\
  \hline
\end{tabular}
 \end{center}

 
\noindent where the two rows are standardized apart, and $\expsub{\mathcal{P}}{1}$ and $\expsub{\mathcal{P}}{2}$ are unifiable, with the most-general unifier $\theta$; let $ \mathcal{P} = \expsub{\mathcal{P}}{1} \apply \theta = \expsub{\mathcal{P}}{2} \apply \theta$.  Then, we can infer the new goal row


  \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & $\uand(\expsub{\mathcal{R}}{1} \apply \theta, \ \expsub{\mathcal{R}}{2} \apply \theta)$ &  $\cond {\mathcal{P}} {\expsub{t}{1} \apply \theta} {\expsub{t}{2} \apply \theta}$ \\
  \hline
\end{tabular}
\end{center}

\noindent The rule has introduced a conditional term into the output entry;  the test is the unified formulas, and the then-branch and else-branch are instances under $\theta$ of the corresponding output entries  $\expsub{t}{1}$, and $\expsub{t}{2}$, respectively, of the given goal rows.

If the first goal is simply $\expsub{\mathcal{P}}{1}$, we treat is as if it were $\uand(\expsub{\mathcal{P}}{1},\true)$. We then automatically perform propositional-logic simplifications, such as $\uand(\mathcal{P}, \true) \rightarrow \mathcal{P}$, to the inferred row whenever possible.  If the first goal is actually 
$\uand(\expsub{\mathcal{P}}{1},\expsub{\mathcal{R}}{1},\allowbreak \expsub{\mathcal{R}}{2}, \ldots)$, with more than two conjuncts, we treat it as if it were $\uand(\expsub{\mathcal{P}}{1}, \uand(\expsub{\mathcal{R}}{1},\allowbreak \expsub{\mathcal{R}}{2}, \ldots))$.

We show that, for a given interpretation, any term allowed by the new row is also allowed by the given tableau. For, suppose some instance  
\begin{align*}
&\uand(
\expsub{\mathcal{R}}{1}\apply \theta,
\expsub{\mathcal{R}}{2}\apply \theta) \apply \theta' \  \, &&\uiff 
   \text{[by distributivity]} \\
&\uand(
(\expsub{\mathcal{R}}{1}\apply \theta)\apply \theta',
(\expsub{\mathcal{R}}{2}\apply \theta)\apply \theta') 
 %& 
% \uand(
% \expsub{(\mathcal{R}}{1} \apply \theta) \apply \theta',
% \ \expsub{\mathcal{R}}{2} \apply \theta)\apply \theta' }
\end{align*}
of the new goal  is true; hence (by the truth table for $\uand$) both $(\expsub{\mathcal{R}}{1}\apply \theta)\apply \theta'$ and $(\expsub{\mathcal{R}}{2}\apply \theta)\apply \theta'$ are true. We show that the corresponding instance  
of the new output entry,
 \begin{align*}
   &\cond 
   {\mathcal{P}} 
   {\expsub{t}{1} \apply \theta} 
   {\expsub{t}{2} \apply \theta} \apply \theta'\
      &&=  \text{[by distributivity]} \\
     &\cond 
     {\mathcal{P}\apply \theta'} 
     {(\expsub{t}{1} \apply \theta) \apply \theta'} 
     {(\expsub{t}{2} \apply \theta) \apply \theta'} \ 
       &&=  \text{[by the composition property]} \\
     &\cond 
     {\mathcal{P}\apply \theta'} 
     {\expsub{t}{1} \apply (\theta \compose \theta')} 
     {\expsub{t}{2} \apply (\theta \compose \theta')} \ 
 \end{align*}
 is already allowed by one of the two given rows.
 

The proof distinguishes between two cases.  In the first case, in which the instance of the test, 
$\mathcal{P}\apply \theta'$, that is
[because $\mathcal{P} = 
\expsub{\mathcal{P}}{1} \apply \theta)$],
$({\expsub{\mathcal{P}}{1} \apply \theta})\apply \theta'$, is true, we have
\begin{align*}
&\uand(({\expsub{\mathcal{P}}{1} \apply \theta})\apply \theta',
(\expsub{\mathcal{R}}{1}\apply \theta)\apply \theta'
)  \, &&\uiff 
  \text{[by distributivity]} \\
&\uand(({\expsub{\mathcal{P}}{1} \apply \theta}),
(\expsub{\mathcal{R}}{1}\apply \theta))\apply \theta' \, &&\uiff 
   \text{[by distributivity, again]} \\
  &\uand(({\expsub{\mathcal{P}}{1}},
\expsub{\mathcal{R}}{1})\apply \theta) \apply \theta' \, &&\uiff  
 \text{[by the composition property]} \\
&\uand({\expsub{\mathcal{P}}{1}},
\expsub{\mathcal{R}}{1})\apply (\theta \compose \theta')
   \end{align*}
is true.  But this is an instance of the first row.  We have assumed the row allows the corresponding instance of its output entry, $\expsub{t}{1} \apply (\theta \compose \theta').$ But in this case, because the test
$\mathcal{P}\apply \theta'$ is true, the conditional answer \[\cond 
     {\mathcal{P}\apply \theta'} 
     {\expsub{t}{1} \apply (\theta \compose \theta')} 
     {\expsub{t}{2} \apply (\theta \compose \theta')}\] is equal to its then-branch $\expsub{t}{1} \apply (\theta \compose \theta')$;  that is, the conditional is allowed by the first row.
    

In the second case, in which the instance of the test, 
$\mathcal{P}\apply \theta'$, that is
[because $\mathcal{P} = 
\expsub{\mathcal{P}}{2} \apply \theta)$],
$({\expsub{\mathcal{P}}{2} \apply \theta})\apply \theta'$, is false, we have [by the truth table for $\unot$] $\unot(({\expsub{\mathcal{P}}{2} \apply \theta})\apply \theta')$ is true, and hence
\begin{align*}
&\uand(\unot(({\expsub{\mathcal{P}}{2} \apply \theta})\apply \theta'),
(\expsub{\mathcal{R}}{2}\apply \theta)\apply \theta'
)  \,  &&\uiff 
  \text{[by distributivity]} \\
&\uand(\unot({\expsub{\mathcal{P}}{2} \apply \theta}),
(\expsub{\mathcal{R}}{2}\apply \theta))\apply \theta' \,  &&\uiff 
  \text{[by distributivity, again]} \\
  &\uand((\unot{\expsub{\mathcal{P}}{2}},
\expsub{\mathcal{R}}{2})\apply \theta) \apply \theta' \, &&\uiff  
 \text{[by the composition property]} \\
&\uand(\unot{\expsub{\mathcal{P}}{2}},
\expsub{\mathcal{R}}{2})\apply (\theta \compose \theta')
   \end{align*}
is true.  But this is an instance of the second row.  We have assumed the row allows the corresponding instance of its output entry, $\expsub{t}{2} \apply (\theta \compose \theta').$ However,  in this case, because the test
$\mathcal{P}\apply \theta'$ is false, the conditional answer $\cond 
     {\mathcal{P}\apply \theta'} 
     {\expsub{t}{1} \apply (\theta \compose \theta')} 
     {\expsub{t}{2} \apply (\theta \compose \theta')}$ is equal to its else-branch $\expsub{t}{2} \apply (\theta \compose \theta')$;  that is, the conditional is allowed by the second row.


This concludes the proof of correctness of the resolution rule and its introduction of conditional terms.  

\subsubsection{Missing Output Entries and the Resolution Rule.}  When one of the two goal rows has no output entry, we do not form a conditional.  For instance, suppose we have two goal rows, 


   \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & \begin{center}$\uand(\expsub{\mathcal{P}}{1},\expsub{\mathcal{R}}{1})$ \end{center}& \begin{center}$\expsub{t}{1}$\end{center} \\
  \hline
\end{tabular}
\end{center}
\noindent and
  \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & \begin{center}$ \uand(\unot (\expsub{\mathcal{P}}{2}),\expsub{\mathcal{R}}{2})$ \end{center}&  $\qquad$ \\
  \hline
\end{tabular}
\end{center}
\noindent where the same conditions apply but the second row has no output entry.  But we have mentioned that a row with no output entry can be replaced by a row with a new output variable $\var{V}$:

  \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & \begin{center}$ \uand(\unot (\expsub{\mathcal{P}}{2}),\expsub{\mathcal{R}}{2})$\end{center} & \begin{center} $\var{V} $\end{center} \\
  \hline
\end{tabular}
\end{center}

 


\noindent Applying the resolution rule, we obtain
$\cond {\mathcal{P}} {\expsub{t}{1} \apply \theta} {\var{V} \apply \theta}$ 

 \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & \begin{center}$\uand(\expsub{\mathcal{R}}{1} \apply \theta, \ \expsub{\mathcal{R}}{2} \apply \theta)$\end{center} &  \begin{center}$\cond {\mathcal{P}} {\expsub{t}{1} \apply \theta} {\var{V} \apply \theta}$\end{center}\\
  \hline
\end{tabular}
\end{center}



\noindent By the instance property, we can add a row in which new variable $\var{V}$ is replaced by $\expsub{t}{1}$ (or any term), obtaining


 \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & \begin{center}$\uand(\expsub{\mathcal{R}}{1} \apply \theta, \ \expsub{\mathcal{R}}{2} \apply \theta)$ \end{center} & \begin{center} $\cond {\mathcal{P}} {\expsub{t}{1} \apply \theta} {\expsub{t}{1} \apply \theta}$\end{center} \\
  \hline
\end{tabular}
\end{center}



%  \begin{center}
% \begin{tabular} {T}
% \hline
%     $\qquad$ & $\uand(\expsub{\mathcal{R}}{1} \apply \theta, \ \expsub{\mathcal{R}}{2} \apply \theta)$ &  $\cond {\mathcal{P}} {\expsub{t}{1} \apply \theta} {\expsub{t}{1} \apply \theta}$ \\
%   \hline
% \end{tabular},
% \end{center}

\noindent or, equivalently (by the \emph{same-branch property} of the conditional), 
   \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & \begin{center}$\uand(\expsub{\mathcal{R}}{1} \apply \theta, \ \expsub{\mathcal{R}}{2} \apply \theta) $ \end{center} & \begin{center}$\expsub{t}{1}\apply \theta$\end{center} \\
  \hline
\end{tabular}.
\end{center}

\noindent Failing to introduce a conditional when the test $\mathcal{P}$ is non-primitive may enable the rule to yield a primitive output entry.

If neither row contains an output entry, the resulting row also has no output entry. To  prove this, replace each row with one containing new variables $\var{U}$ and $\var{V}$ as output entries; the resolution rule will allow us to derive a new row with output entry $\cond {\mathcal{P}} {\var{U} \apply \theta} {\var{V} \apply \theta}$, that is [because $\var{U}$ and $\var{V}$ are new variables, not in the domain of $\theta$], $\cond {\mathcal{P}} {\var{U} } {\var{V}}$. Then, take an instance of the row with $\var{V}$ in the output entry replaced by $\var{U}$, yielding  $\cond {\mathcal{P}} {\var{U} } {\var{U}}.$ By the \emph{same-branch property}, this output entry is equal to the variable $\var{U}$. But a row with a new variable as its output entry can be replaced by a row with no output entry at all.


 
\subsubsection{Dual Forms of the Resolution Rule.}  We call the above the \emph{goal-goal version} of the rule.  By duality, we can apply the resolution rule to two assertion rows (the \emph{assertion-assertion version}), or to an assertion and a goal (the \emph{assertion-goal version}).  For two assertions, the assertion-assertion version is as follows. Suppose we have developed two assertion rows, of the form



   \begin{center}
\begin{tabular}{T}
\hline
   \begin{center} $\uor(\!\unot(\expsub{\mathcal{P}}{1}),\expsub{\mathcal{R}}{1})$\end{center} & 
   $\qquad$ 
   & \begin{center}$\expsub{t}{1}$\end{center}\\
  \hline
\end{tabular}
\end{center}


\noindent and
  \begin{center}
\begin{tabular} {T}
\hline
  \begin{center}  $ \uor(\expsub{\mathcal{P}}{2},\expsub{\mathcal{R}}{2})$ \end{center} 
    &  $\qquad$ 
    &\begin{center} $\expsub{t}{2}$ \end{center}\\
  \hline
\end{tabular}
\end{center}
 
\noindent where, as in the \emph{goal-goal version}, the two rows are standardized apart, and $\expsub{\mathcal{P}}{1}$ and $\expsub{\mathcal{P}}{2}$ are unifiable, with the most-general unifier $\theta$, and $ \mathcal{P} = \expsub{\mathcal{P}}{1} \apply \theta = \expsub{\mathcal{P}}{2} \apply \theta$.  Then, we can infer the new assertion row

 
 


\begin{center}
\begin{tabular}{T}
%{| Y | Y || Y |}
\hline
  \begin{center} $\uor(\expsub{\mathcal{R}}{1} \apply \theta, \ \expsub{\mathcal{R}}{2} \apply \theta) $ \end{center}& &
   \begin{center} $\cond {\mathcal{P}} {\expsub{t}{1} \apply \theta} {\var{V} \apply \theta}$ \end{center}
  \\
  \hline
\end{tabular}.
\end{center}

\noindent To see this, we can (by duality) pass both assertions to the goal column by negating them, apply the \emph{goal-goal version} of the rule, then (by duality, again) push the resulting goal to the assertion column by negating it, and then simplify (by propositional-logic equivalences) the resulting assertion.

As in the \emph{goal-goal version} of the rule, if the first row has no output entry, no conditional is formed; the output entry for the new row is simply ${\expsub{t}{1} \apply \theta}$.  If the second row has no output entry, the new row has output entry  ${\expsub{t}{2} \apply \theta}.$  If neither given row has an output entry, neither does the new row.



\begin{comment}
    \begin{center}
\begin{tabular} {T}
\hline
    \begin{center}$\uor(\unot(\expsub{\mathcal{P}}{1}),\expsub{\mathcal{R}}{1})$\end{center} & $\qquad$ & \begin{center}$\expsub{t}{1}$\end{center} \\
    \begin{center}$\uor(\unot(\expsub{\mathcal{P}}{1}),\expsub{\mathcal{R}}{1})$ \end{center}& $\qquad$ & \begin{center}$\expsub{t}{1}$\end{center} \\
  \hline
\end{tabular}
\end{center}
\noindent and
  \begin{center}
\begin{tabular} {T}
\hline
    \begin{center}$ \uor(\expsub{\mathcal{P}}{2},\expsub{\mathcal{R}}{2})$\end{center}  &  $\qquad$  & \begin{center}$\expsub{t}{2}$\end{center} \\
  \hline
\end{tabular}
\end{center}
\noindent where the two rows are standardized apart, and $\expsub{\mathcal{P}}{1}$ and $\expsub{\mathcal{P}}{2}$ are unifiable, with the most-general unifier $\theta$; let  $ \mathcal{P} = \expsub{\mathcal{P}}{1} \apply \theta = \expsub{\mathcal{P}}{2} \apply \theta$.  Then, we can infer the new goal row
\end{comment}
 


Similarly, in the \emph{assertion-goal version} of the rule, we assume we are given the assertion row
   
   \begin{center}
\begin{tabular} {T}
\hline
    \begin{center}$\uor(\expsub{\mathcal{P}}{1},\expsub{\mathcal{R}}{1})$ \end{center}& $\qquad$ & \begin{center}$\expsub{t}{1}$\end{center} \\
  \hline
\end{tabular}
\end{center}
\noindent and the goal row
  \begin{center}
\begin{tabular} {T}
\hline
   $\qquad$ & \begin{center}$ \uand (\expsub{\mathcal{P}}{2},\expsub{\mathcal{R}}{2})$ \end{center}   & \begin{center}$\expsub{t}{2}$\end{center} \\
  \hline
\end{tabular}
\end{center}
 
\noindent where, as in the other versions, the two rows are standardized apart, and $\expsub{\mathcal{P}}{1}$ and $\expsub{\mathcal{P}}{2}$ are unifiable, with the most-general unifier $\theta$, and $ \mathcal{P} = \expsub{\mathcal{P}}{1} \apply \theta = \expsub{\mathcal{P}}{2} \apply \theta$.  Then, we can infer the new goal row
  \begin{center}
\begin{tabular} {T}
\hline
   $\qquad$ & 
   \begin{center}
   $\uand(\!
 \begin{aligned}[t]
 &\!\!\unot(\expsub{\mathcal{R}}{1}) \apply \theta,  \\
 &\expsub{\mathcal{R}}{2} \apply \theta)
 \end{aligned}$ 
 \end{center}
 &   \begin{center}$\cond {\mathcal{P}} {\expsub{t}{2} \apply \theta} {\expsub{t}{1} \apply \theta}$\end{center}\\
  \hline
\end{tabular}
\end{center}
\noindent The justification is similar to those for the other versions.


   
% \noindent\begin{tabularx}{.85\textwidth} { 
%   | >{\relax\raggedright\arraybackslash}X 
%   | >{\raggedright\arraybackslash}X 
%   || >{\raggedright\arraybackslash}X | }
% \hline
% & $\uand(\unot(\expsub{\mathcal{R}}{1} \apply \theta), \ \expsub{\mathcal{R}}{2} \apply \theta)$    &  $\cond {\mathcal{P}} {\expsub{t}{1} \apply \theta} {\expsub{t}{2} \apply \theta}$\\
% \hline
% \end{tabularx}

\subsubsection{Equivalence and Equality Replacement Rules.}  Simple equivalences can be treated as rewrite rules:  replace any instance of the left side with the corresponding instance of the right side.  More generally, we state the \emph{equivalence replacement} rule here.  As with the resolution rule, there are \emph{assertion-assertion}, \emph{goal-goal} and \emph{assertion-goal versions}, but we show only the \emph{assertion-goal} form.

We assume we are given the assertion row
   \begin{center}
\begin{tabular} {T}
\hline
    \begin{center}$\uor(\expsub{\mathcal{P}}{1}\uiff \mathcal{Q},\expsub{\mathcal{R}}{1})$ \end{center}& $\qquad$ & \begin{center}$\expsub{t}{1}$\end{center} \\
  \hline
\end{tabular}
\end{center}
\noindent and the goal row
  \begin{center}
\begin{tabular} {T}
\hline
   $\qquad$ &  \begin{center}$ \uand (\mathcal{S}\langle\expsub{\mathcal{P}}{2}\rangle,\expsub{\mathcal{R}}{2})$\end{center}   & \begin{center} $\expsub{t}{2}$\end{center} \\
  \hline
\end{tabular}
\end{center}

 
\noindent where, as in the other rules, the two rows are standardized apart, and $\expsub{\mathcal{P}}{1}$ and $\expsub{\mathcal{P}}{2}$ are unifiable, with the most-general unifier $\theta$, and $\mathcal{P} = \expsub{\mathcal{P}}{1} \apply \theta = \expsub{\mathcal{P}}{2} \apply \theta$.  Here, $\mathcal{S}\langle\expsub{\mathcal{P}}{2}\rangle$ is a formula that contains at least one occurrence of $\expsub{\mathcal{P}}{2}.$
Then, the \emph{equivalence replacement} rule allows us to infer the new goal row

\begin{center} 
\begin{tabular}{T}
\hline
$\qquad$  & 
  \begin{center}

$\begin{aligned}
\uand(&\unot({\expsub{\mathcal{R}}{1} \apply \theta}),\\
&\mathcal{S}\langle\mathcal{Q}\rangle\apply \theta, \\ 
&\expsub{\mathcal{R}}{2} \apply \theta)
\end{aligned}$
\end{center}
& 
\begin{center} $\begin{aligned}\uif\,(&{\mathcal{P} \uiff \mathcal{Q}\apply \theta}, \\
&{\expsub{t}{2} \apply \theta}, \\
&{\expsub{t}{1} \apply \theta})\end{aligned}$\end{center}
\\
\hline
\end{tabular}.
\end{center}


\noindent Here, $\mathcal{S}\langle\mathcal{Q}\rangle$ is the result of replacing one or more occurrences of $\expsub{\mathcal{P}}{2}$ in $\mathcal{S}\langle\expsub{\mathcal{P}}{2}\rangle$ with $\mathcal{Q}$. We omit the justification, which depends on the \emph{substitutivity property} of equivalence.

We have shown the \emph{left-to-right version} of the rule, in which an instance of the left side of the equivalence is replaced by the corresponding instance of the right side;  there is also an analogous \emph{right-to-left version}.

In our {\SNARK} implementation, equivalences are replaced by other connectives by  translating to clause form, so the equivalence rules do not appear in proofs.  However, in exposition the rules make some proofs easier to understand. 

The \emph{equality replacement} rule is analogous to the \emph{equivalence replacement} rule. It corresponds to the paramodulation rule in resolution theorem proving.

We assume we are given the assertion row
   \begin{center}
\begin{tabular} {T}
\hline
\begin{center}
    $\uor(\expsub{s}{1}= t,\expsub{\mathcal{R}}{1})$ 
  \end{center}  
    & $\qquad$ &\begin{center} $\expsub{t}{1}$\end{center}  
    \\
  \hline
\end{tabular}
\end{center}
\noindent and the goal row
  \begin{center}
\begin{tabular} {T}
\hline
   $\qquad$ &  
   \begin{center}
 $\uand (\mathcal{P}\langle\expsub{s}{2}\rangle,\expsub{\mathcal{R}}{2})$
\end{center}
     &\begin{center} $\expsub{t}{2}$\end{center} \\
  \hline
\end{tabular}
\end{center}

\noindent where, as in the other rules, the two rows are standardized apart, and $\expsub{s}{1}$ and $\expsub{s}{2}$ are unifiable, with the most-general unifier $\theta$, and $s = \expsub{s}{1} \apply \theta = \expsub{s}{2} \apply \theta$.  Here, $\mathcal{P}\langle\expsub{s}{2}\rangle$ is a formula that contains at least one occurrence of $\expsub{s}{2}.$

Then, the \emph{equality replacement} rule allows us to infer the new goal row
  \begin{center}
\begin{tabular} {T}
\hline
   $\qquad$ & 
   \begin{center}
     $\begin{aligned}
\uand(&\!\unot({\expsub{\mathcal{R}}{1} \apply \theta}),\\
&\mathcal{P}\langle t\rangle\apply \theta, \\  
&\expsub{\mathcal{R}}{2} \apply \theta)
\end{aligned}$
\end{center} & 
\begin{center}
$
\begin{aligned}
\uif(&{s = t\apply \theta}, \\
&{\expsub{t}{2} \apply \theta}, \\
&{\expsub{t}{1} \apply \theta})
\end{aligned}
$
\end{center}\\
  \hline
\end{tabular}
\end{center}

 





% \noindent
%  % \begin{center}
%  \begin{tabular} {|m{0.125\textwidth}|m{0.30\textwidth}||m{0.35\textwidth}|}
%  \hline
%   $\qquad$ & 
%  {\begin{align*}\begin{aligned}
% \uand(&\mathcal{P}\langle t\rangle\apply \theta,   \unot({\expsub{\mathcal{R}}{1} \apply \theta}),\\
% &\expsub{\mathcal{R}}{2} \apply \theta)
% \end{aligned}\end{align*}} &  {\begin{align*}\cond {s = t\apply \theta} 
% {\expsub{t}{2} \apply \theta} 
% {\expsub{t}{1} \apply \theta}\end{align*}} \\
%   \hline
% \end{tabular}
%  %\end{center}

\noindent Here, $\mathcal{P}\langle t\rangle$ is the result of replacing one or more occurrences of $\expsub{s}{2}$ in $\mathcal{P}\langle\expsub{s}{2}\rangle$ with $t$. We omit the justification, which depends on the \emph{substitutivity property} of equality. 

We have shown the \emph{left-to-right version} of the rule, in which an nstance of the left side of the equality is replaced by the corresponding instance of the right side;  there is also an analogous \emph{right-to-left version}. In the {\SNARK} implementation, the version to be applied depends on a symbol ordering strategy.



This rule corresponds to the \emph{paramodulation} rule in ordinary resolution theorem proving.





\subsection{Mathematical Induction and Recursive Program Formation}   We now see how the well-founded induction principle is integrated into the deductive tableauIn the deductive tableau framework, we begin with the initial tableau 


    
   \begin{center}
\begin{tabular}{T}
 \hline
 \begin{center} Assertions\end{center} &
 \begin{center} Goals\end{center}
 &\begin{center} $\uf(a)$ \end{center}\\ 
 \hhline{|=|=|=|} 
 &\begin{center} $ \mathscr{Q}[a,  \var{Z}] $ \end{center}& \begin{center}$\var{Z}$ \end{center}\\ 
 
 \hline
\end{tabular}
\end{center}
\noindent In other words, for a given input entity $a$, we are constructing a program $\uf$ that will yield an output $\var{Z}$ that satisfies the input-output condition $ \mathscr{Q}[a, \var{Z}] $. For a well-founded relation $\expsub{\prec}{w}$, we can conduct the proof under the induction hypothesis that recursive calls to the program $\uf(\var{x})$ we are constructing will satisfy the input-output condition $ \mathscr{Q}[\var{x}, \, \uf(\var{x})]$ for any input $\var{x}$ such that $\var{x}\expsub{\prec}{w} \, a.$  We add this induction hypothesis to the initial tableau as an assertion: 


      \begin{center}
\begin{tabular}{T}
 \hline
 \begin{center} Assertions \end{center} 
 & \begin{center} Goals \end{center}
 &\begin{center} $\uf(a)$ \end{center}\\ \hhline{|=|=|=|}
 & \begin{center} $ \mathscr{Q}[a,  \var{Z}] $ \end{center}
 & \begin{center} $\var{Z}$ \end{center} \\ 
 \hline 
 \begin{center} $ \var{X} \expsub{\prec}{w}\,a   \, \uimplies \mathscr{Q}[\var{X},\, \uf(\var{X})]$ \end{center} &  &  \\ 
 \hline
\end{tabular}
\end{center}
In other words, instead of proving the desired conclusion itself, we prove the inductive step, which says that the induction hypothesis implies the desired conclusion. 

Using the induction hypothesis in a proof can introduce a recursive call into the program being derived.  However,  including the induction hypothesis in the tableau does not force us to derive a recursive program. If we don't use the induction hypothesis in the derivation proof, the program we derive won't use recursion.
 

Use of the well-founded induction principle provides a termination argument for the derived program.  If the program $\uf(a)$ invokes a recursive call $\uf(\var{X})$, we require that $ \var{X} \expsub{\prec}{ w} \, a $, that is,  $ a \expsub{\succ}{w} \, \var{X}$. If there were a nonterminating computation in which $\uf(\expsub{a}{0})$ invokes $\uf(\expsub{a}{1})$, which invokes $\uf(\expsub{a}{2})$, and so forth, the sequence of arguments $\expsub{a}{0}, \expsub{a}{1}, \expsub{a}{2}, \ldots  $ would constitute an infinite decreasing sequence, because $\expsub{a}{0} \expsub{\succ}{w}\, \expsub{a}{1} \expsub{\succ}{w} \, \expsub{a}{2}, \ldots ,$ contradicting the well-foundedness of $\expsub{\prec}{w}$.


The choice of the well-founded relation is not straightforward.  Generally, we cannot anticipate what relation to use until the proof is underway. \citet{man:wal} developed a complete proof in which the well-founded relation was unspecified; only then, when one could one see what properties the relation had to satisfy, was it possible to construct the appropriate relation.  

For an automatic system, we can expect the formulator of an subject domain theory to provide properties of the most basic well-founded relations in that theory; e.g., for the theory of expressions and substitutions, we would be given  properties of the the $\vars$  relation $\expsub{\prec}{vars(\subset)}$  and the $\size$ relation $\expsub{\prec}{size(<)}$.  But any particular algorithm may require some combination of the basic relations for its derivation and termination proof. We can reasonably hope  an automatic system would discover this combination, but we have not yet introduced the necessary apparatus; we regard this as a challenging topic for future research.   

For instance, the associative-commutative unification algorithms,  which allow us to take into account the associativity and commutativity of function symbols in the unified expressions \citep{sti:acu,  liv-siek:acu} were published (and used) years before the well-founded relation was discovered that allowed their termination to be established   \citep{fag:acu}.

For the derivation discussed in this paper, we provide a successful well-founded relation as an un-automated “eureka" step. 

\section{The Derivation of the Unification Algorithm}

We illustrate the use of the deductive tableau framework with examples selected from the derivation of the unification algorithm.

% \section{Derivation of the Unification Algorithm}

% We are finally ready to present the derivation of the unification algorithm.  The automatic {\SNARK} derivation is a refutation in clausal form, and thus is difficult for people to follow.  Instead we begin by showing a more comprehensible version of the same derivation.
 
\subsection{The Specification and First Steps}\label{sec:spec-first}
  
For our specification for the unification algorithm, we will assume that the environment substitution is idempotent; this allows a simpler algorithm and termination proof. Thus,  the input-output condition for the unification algorithm will be
   \begin{align*}
       &\idem(\thet{0}) \uimplies \, \\
       &\,{\mgiu}(\thet{0}, \e{1}, \e{2}, \Theta)
   \end{align*}
   
   \noindent where the inputs are $\thet{0}$, $\e{1}$, and $\e{2}$, and the output is $\Theta$. 

 

   Our primitive instructions include the failure indicator $\fail$, the empty substitution $\emptysubst$, the expression decomposers $\lef$ and $\rig$, the substitution application $\apply$, the composition operator $\compose$, the  replacement operator $\mapsto$ and the predicate symbols $=$, $\issubst$, $\isatm$, $\iscnst$, $\isvar$, $\occursin$, and $\misses$.  The logical connectives, the conditional operator $(\uif\_\uthen \_\uelse\_)$ and recursive calls are primitive as usual.


We are given as inputs an idempotent environment substitution $\thet{0}$ and two expressions $\e{1}$ and $\e{2},$ and want to find an output $\Theta$ that is an extension of $\thet{0}$ and is a most-general idempotent unifier of $\e{1}$ and $\e{2}.$  Our specification is thus


\begin{alignat*}{2}
  \begin{split}
   \unify(&\thet{0}, \e{1}, \e{2}) \Lleftarrow  \\ 
&\operatorname{find} \, \Theta \,
     \operatorname{such}\operatorname{that} \\
&\begin{aligned}
  &&&&& \idem(\thet{0}) \uimplies  \\
  &&&&& \mgiu(\thet{0}, \e{1}, \e{2}, \Theta) 
   \end{aligned}
  \end{split}.
\end{alignat*}

   
\vspace*{.2cm}
\noindent Our initial tableau is then

\begin{center}  
\begin{tabular}{T}
 \hline
\begin{center}  Assertions \end{center}&
\begin{center}  Goals  \end{center}  &
\begin{center}  $\unify(\thet{0}, \e{1}, \e{2})$  \end{center}\\
 \hline\hline
  & \begin{center}$\begin{aligned}[t] &\idem(\thet{0}) \uimplies \\  &\,{\mgiu}(\thet{0}, \e{1}, \e{2} , \Theta) \\ \end{aligned}$ \end{center} & \begin{center}$\Theta$ \end{center} \\

\hline
\end{tabular}.
\end{center}
  


\noindent In other words, for given input entities $\thet{0}$, $\e{1}$, and $\e{2},$ we are constructing a program  $\,\unify(\thet{0}, \e{1}, \e{2})$ that will yield an output $\Theta$ that satisfies the input-output condition  $\idem(\thet{0}) \uimplies {\mgiu}(\thet{0}, \e{1}, \e{2} , \Theta)$.  Here $\Theta$ is a variable; it behaves as if it were existentially quantified, and it can be instantiated with other terms during the proof process.


 By the \emph{implication-splitting} rule, we can replace this goal with the separate assertion and goal
\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
 \vspace{-.3cm}\begin{center}$\idem(\thet{0})$\end{center} &  & \vspace{-.3cm}\begin{center}$\Theta$ \end{center} \\
\hline
  & \vspace{-.3cm}\begin{center}$ {\mgiu}(\thet{0}, \e{1}, \e{2} , \Theta)$  \end{center}  & \vspace{-.3cm}\begin{center}$\Theta$\end{center} \\
\hline
\end{tabularx}.
\end{center}
Because the output entry $\Theta$ is a variable that does not occur in the above assertion, it may be dropped (by the \emph{orphaned output-entry property}), leaving

\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
 \vspace{-.3cm}\begin{center}$\boxed{\idem(\thet{0})}$\end{center} &  & \\
\hline
\end{tabularx}.
\end{center}
We shall subsequently refer to the above assertion (without the output entry) and goal as the  \emph{initial assertion} and the  \emph{initial goal}, respectively. (The box around the subexpression is an extra-logical annotation; it means that the boxed expression will be unified in the subsequent inference step.)

We have remarked that a substitution is idempotent precisely when it is an extension of itself; thus our tableau contains the valid assertion

\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
 \begin{center}
    \vspace{-.25cm}
$\begin{aligned}\boxed{\idem(\Theta)} \uiff  \Theta \moregen \Theta \end{aligned}$
\end{center}
  & 
  &  \\ \hline
\end{tabularx}.
\end{center}
 The symbol $\Theta$ in this assertion is a variable, which makes it behave as if it were universally, rather than existentially, quantified, because it is in an assertion rather than a goal. The two assertions are already standardized apart, since they have no variables in common. We can apply the \emph{assertion-assertion version} of the \emph{equivalence replacement} rule to this assertion and the previous assertion,  taking $\expsub{\mathcal{P}}{1}$ and  $\expsub{\mathcal{P}}{2}$ to be the boxed subexpressions  $\idem(\Theta)$ and $\idem(\thet{0})$, respectively, and taking the most-general unifier to be $\{\Theta \mapsto \thet{0}\}$. We obtain the new assertion

\begin{center}
\begin{tabularx}{1.0\textwidth}{V}
% { 
%   | >{\raggedright\arraybackslash}X 
%   | >{\raggedright\arraybackslash}X 
%   | >{\raggedright\arraybackslash}X | }
 \hline 
 \begin{center}
 \vspace{-.25cm}
$\begin{aligned} \thet{0} \moregen \thet{0} \end{aligned}$
\end{center}
  & 
  &  \\ \hline
\end{tabularx}.
\end{center}
\noindent We shall later use this phrasing of our \emph{idempotence assumption}, that the environment is idempotent. 
 
  We defined the most-general idempotent-unifier relation by an equivalence, which we can incorporate as a valid assertion in our tableau.
    \begin{center}
  \begin{tabular} {|m{0.45\textwidth}|m{0.18\textwidth}||m{0.18\textwidth}|}
\hline
 \begin{center} 
${\begin{aligned} 
&\boxed{\mgiu(\Thet{0}, \E{1}, \E{2}, \Theta)} \uiff \\
&\begin{aligned}
&\E{1} \apply \Theta = \E{2} \apply \Theta \, \uand 
 \\
 \,\, & \Thet{0} \moregen \Theta \, \uand
\\
  \,\, & {\mgi}(\Thet{0}, \E{1}, \E{2}, \Theta)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center}& &  \\  \hline
%\end{tabularx}
\end{tabular}
\end{center}

\noindent   We use this definition to expand the initial goal: 
\begin{center}
\begin{tabular}{T}
% {1.0\textwidth} { 
%   | >{\raggedright\arraybackslash}X 
%   | >{\raggedright\arraybackslash}X 
%   || >{\raggedright\arraybackslash}X | }
\hline
  & \begin{center}$ \boxed{{\mgiu}(\thet{0}, \e{1}, \e{2} , \Theta)}$  \end{center}  & \begin{center}$\Theta$\end{center} \\
\hline
\end{tabular}.
\end{center}
We apply the \emph{assertion-goal version} of the \emph{equivalence replacement} rule to this assertion and the initial goal (standardizing the two rows apart by renaming the variable $\Theta$ in the goal to $\Thet{1}$, taking  $\expsub{\mathcal{P}}{1}$ and  $\expsub{\mathcal{P}}{2}$ to be the boxed subexpressions ${\mgiu}(\Thet{0}, \E{1}, \E{2}, \Theta)$ and $ {\mgiu}(\thet{0}, \e{1}, \e{2} , \Thet{1})$, respectively, and taking the most-general unifier to be $\{\Thet{0} \mapsto \thet{0}, \E{1} \mapsto \e{1}, \E{2} \mapsto \e{2}, \Thet{1} \mapsto \Theta\}$. We expand our goal to obtain


    \begin{center}
  \begin{tabular}%{|m{0.20\textwidth}|m{0.40\textwidth}||m{0.20\textwidth}|}
  {T}
\hline
 & \begin{center}
${\begin{aligned} 
&\begin{aligned}
&\boxed{\e{1} \apply \Theta = \e{2} \apply \Theta} \, \uand 
 \\
 \,\, & \thet{0} \moregen \Theta \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \Theta)
\end{aligned}\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\Theta$\end{center} \\  \hline
%\end{tabularx}
\end{tabular}
\end{center}


We shall refer to this as the \emph{expanded initial goal}. Here, $\Theta$ is still a variable; the other variables in the assertion have been instantiated with constants, the program's input parameters.

\subsection{The Equal-Expression Case}\label{sec:eq-exps}

We have (as a property of equality) the valid assertion
\begin{center}
  \begin{tabular}%{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
  %{|m{0.27\textwidth}|m{0.26\textwidth}||m{0.26\textwidth}|}
  {|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
\hspace{-.5cm}
{\begin{align*}
&  \E{1} = \E{2}  \, \uimplies \\
& \boxed{\E{1}\apply\Theta = \E{2}\apply\Theta}
\end{align*}}
\end{center}
 & &
\\
\hline
\end{tabular}
\end{center}




We standardize the two rows apart by renaming the variable $\Theta$ in the goal to $\Thet{1}$. We apply the \emph{assertion-goal version} of the resolution rule to the above assertion and the \emph{expanded initial goal}, taking  $\expsub{\mathcal{P}}{1}$ and  $\expsub{\mathcal{P}}{2}$ to be the boxed subexpressions $\E{1}\apply\Theta = \E{2}\apply\Theta$. For the unified subexpressions, we take  $\expsub{\mathcal{P}}{1}$ to be the boxed subexpression $\E{1}\apply\Theta = \E{2}\apply\Theta$ in the assertion and  $\expsub{\mathcal{P}}{2}$ to be the boxed subexpression (after renaming) in the goal $\e{1} \apply \Thet{1} = \e{2} \apply \Thet{1}$. The most-general unifier is $\{\varsub{E}{1} \mapsto \expsub{e}{1}, \varsub{E}{2} \mapsto \expsub{e}{2}, \Thet{1} \mapsto \Theta\}$.  The resulting goal is
\begin{center}
\begin{tabular}{T}
 \hline 
  & 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
&\e{1} = \e{2}  \, \uand 
 \\
 \,\, & \thet{0} \moregen \Theta \, \uand
\\
  \,\, & \boxed{{\mgi}(\thet{0}, \e{1},  \e{2}, \Theta)}
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\Theta$ \end{center} \\
\hline
\end{tabular}.
\end{center}
We established that the most-general idempotent relation $\mgi$ has a sort of \emph{reflexivity property}, expressed in the valid assertion
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
\[\hspace{-.5cm}
\begin{aligned}
& \Thet{1} = \Thet{2} \,\, \uimplies \\
& \boxed{\mgi(\Thet{1}, \E{1}, \E{2}, \Thet{2})}  
\end{aligned}
\]
\end{center}
 & &
\\
\hline
\end{tabular}
\end{center}
In other words, the environment $\Thet{1}$ itself is most-general idempotent for any two expressions.  This assertion and the most recent goal are already standardized apart---they have no variables in common.  By \emph{assertion-goal resolution}, unifying the boxed subexpressions with the most-general unifier 
$\{\varsub{E}{1} \mapsto \expsub{e}{1}, \varsub{E}{2} \mapsto \expsub{e}{2}, \Thet{1} \mapsto \thet{0}, \Thet{2} \mapsto \Theta\}$,
we obtain the goal
\begin{center}
\begin{tabular}{T}
 \hline 
  & 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
&\e{1} = \e{2}  \, \uand 
 \\
 \,\, & \boxed{\thet{0} \moregen \Theta} 
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\Theta$ \end{center} \\
\hline
\end{tabular}.
\end{center}
By \emph{assertion-goal resolution} between the paraphrased \emph{idempotence assumption},
\begin{center}
\begin{tabular}{T}
% { 
%   | >{\raggedright\arraybackslash}X 
%   | >{\raggedright\arraybackslash}X 
%   | >{\raggedright\arraybackslash}X | }
 \hline 
 \begin{center}
 \vspace{-.25cm}
$\begin{aligned} \boxed{\thet{0} \moregen \thet{0}}\end{aligned}$
\end{center}
  & 
  &  \\ \hline
\end{tabular}
\end{center}
and the above goal, with the most-general unifier $\{\Theta \mapsto \thet{0}\}$, we reduce the goal to
\begin{center}
\begin{tabular}{T}
 \hline 
  & 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
\e{1} = \e{2}
\end{aligned}\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\thet{0}$ \end{center} \\
\hline
\end{tabular}.
\end{center}
According to this row, when the environment  $\e{1} = \e{2},$ that is, the two expression arguments are equal,  the environment substitution  $\thet{0}$ itself will satisfy the input-output condition for the desired program.  By duality, we could regard its negation as an assertion.
\begin{center}
\begin{tabular}{T}
 \hline 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
\unot (\e{1} = \e{2})
\end{aligned}\end{aligned}}$\hspace{2cm} 
\end{center} 
  & 
 & \begin{center}$\thet{0}$ \end{center} \\
\hline
\end{tabular}.
\end{center}
That is, henceforth we can assume that the two expression arguments are \emph{not} equal. Otherwise, the environment substitution $\thet{0}$ would be a satisfactory output.

\subsection{Failure Environment}

We earlier introduced a special constant $\blk$, the \emph{black hole}, and we assumed that the failure substitution $\fail$ maps any expression into the black hole; that is, $\var{E} \apply \fail = \blk$, for any expression $\var{E}$.  Hence our tableau includes the valid assertion
 \begin{center}
  \begin{tabular}{T}
\hline
 \begin{center} 
${\begin{aligned}
\boxed{\varsub{E}{1} \apply \fail = \varsub{E}{2} \apply \fail}
 \end{aligned}}$\hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
We apply the \emph{assertion-goal version} of the resolution rule to this assertion and the \emph{expanded initial goal},
\begin{center}
\begin{tabular}{T}
 \hline 
  & 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
&\boxed{\e{1} \apply \Theta = \e{2} \apply \Theta} \, \uand 
 \\
 \,\, & \thet{0} \moregen \Theta \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \Theta)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\Theta$ \end{center} \\
\hline
\end{tabular}.
\end{center}
The rows are already standardized apart---they have no variables in common. For the unified subexpressions, we take  $\expsub{\mathcal{P}}{1}$ to be the entire (boxed) assertion $\varsub{E}{1} \apply \fail = \varsub{E}{2} \apply \fail$, and $\expsub{\mathcal{P}}{2}$ to be the boxed subexpression of the goal, $\e{1} \apply \Theta = \e{2} \apply \Theta.$ The most-general unifier is $\{\varsub{E}{1} \mapsto \expsub{e}{1}, \varsub{E}{2} \mapsto \expsub{e}{2}, \Theta \mapsto \fail\}$.  The resulting goal is
\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
  & 
  \begin{center}\vspace{-.5cm} 
${\begin{aligned} 
&\begin{aligned}
 \,\, & \boxed{\thet{0} \moregen \fail} \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \fail)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center} & \vspace{-.3cm}\begin{center}$\fail$ \end{center} \\
\hline
\end{tabularx}.
\end{center}

\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
  & 
  \begin{center}\vspace{-.5cm} 
${\begin{aligned} 
&\begin{aligned}
 \,\, & \boxed{\thet{0} \moregen \fail} \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \fail)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center} & \vspace{-.3cm}\begin{center}$\fail$ \end{center} \\
\hline
\end{tabularx}.
\end{center}
Here we have introduced the failure indicator $\fail$ into the output entry.  Henceforth, we will be a bit more brisk in describing how each rule is applied.

We established that any substitution $\Theta$ is more-general idempotent than the failure substitution $\fail$, because $\Theta \compose \fail = \fail$; therefore our tableau contains the assertion 



\begin{center}
\begin{tabular} {T}
 \hline 
 \begin{center}
$\boxed{\Theta \moregen \fail} $ 
\end{center} & & \\
\hline
\end{tabular}.
\end{center}
\noindent By the \emph{assertion-goal version} of the resolution rule (taking $\Theta$ to be $\thet{0}$), we obtain the new goal

\begin{center}
\begin{tabular}{T}
 \hline 
  & 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
  \,\, & \boxed{{\mgi}(\thet{0}, \e{1}, \e{2}, \fail)}
\end{aligned}\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\fail$ \end{center} \\
\hline
\end{tabular}.
\end{center}
Because we will have need to refer back to this goal later, we name it, the \emph{most-general idempotent failure goal}.


We have also established (by the \emph{reflexivity property} of the $\mgi$ relation) that the environment substitution is most-general idempotent with respect to itself, for any expressions; therefore, our tableau contains the assertion

 

\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
\[\hspace{-.5cm}
\begin{aligned}
& \Thet{1} = \Thet{2} \,\, \uimplies \\
& \boxed{\mgi(\Thet{1}, \E{1}, \E{2}, \Thet{2})}  
\end{aligned}
\]
\end{center}
 & &
\\
\hline
\end{tabular}
\end{center}
\noindent Again, by applying the \emph{assertion-goal version} of the resolution goal, omitting the details but taking $\Thet{0}$ to be $\thet{0}$, $E_{1}$ and $E_{2}$ to be $e_{1}$ and $e_{2}$, respectively, and $\Theta$ to be $\fail$, we obtain the new goal


\begin{center}
\begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
      %{T}
 \hline 
  & 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
 \boxed{\thet{0} = \fail} \end{aligned}\end{aligned}}$\hspace{2cm} 
\end{center} & \begin{center}$\fail$ \end{center} \\
\hline
\end{tabular}.
\end{center}

We have introduced the relation $\isprop$ to characterize the proper substitutions; consequently, we include the assertion 
\begin{center}
 \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
 \hline 
 \begin{center}
 {\begin{align*}
 \begin{aligned}
 &\boxed{\Theta = \bot} \uiff \\ &\unot(\isprop(\Theta))
 \end{aligned}
\end{align*}}
\end{center} 
& & \\
\hline
\end{tabular}.
\end{center}

\noindent By applying the \emph{assertion-goal version} of the \emph{equivalence replacement} rule to the most recent assertion and goal, taking $\Theta$ to be $\thet{0}$,
% the most-general unifier to be $\{\Theta \mapsto \thet{0}\}$,
we obtain the new goal


\begin{center}
\begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|} 
 \hline 
  & 
  \begin{center}
$\begin{aligned} \hspace{-5pt}
&\begin{aligned}
\unot(\isprop(\thet{0}))
  \end{aligned}\end{aligned}$ 
\end{center} & \begin{center}$\fail$ \end{center} \\
\hline
\end{tabular}.
\end{center}

According to this row, when the environment  $\thet{0}$ is not a proper substitution, the failure substitution $\fail$ itself will satisfy the input-output condition for the desired program.  By duality, we could regard its negation as an assertion


\begin{center}
\begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|} 
 \hline 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
\isprop(\thet{0})
  \end{aligned}\end{aligned}}$\hspace{2cm} 
\end{center} 
  & 
 & \begin{center}$\fail$ \end{center} \\
\hline
\end{tabular}.
\end{center}
That is, henceforth we can assume that the environment is a proper substitution. Otherwise, the failure substitution $\fail$ would be a satisfactory output.


\subsection{The Constant Cases.} Because applying the resolution rule does not remove the given assertion or goal, our tableau still contains the \emph{most-general idempotent failure goal},


\begin{center}
\begin{tabular}{T}
 \hline 
  & 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \fail)
\end{aligned}\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\fail$ \end{center} \\
\hline
\end{tabular}.
\end{center}

\noindent We have seen that any substitution is most-general idempotent for two expressions that are ununifiable;  in particular, if the two expressions are distinct constants, any substitution will satisfy the condition.   Thus,  our tableau contains the assertion
\begin{center}
\begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
 \hline 
 \vspace{-1cm}
 \hspace{-3cm}
 \begin{center}
 \hspace{-3cm}
 {\begin{align*}  \hspace{-.7cm}
{\begin{aligned} 
 &\,{\mgi}(\Thet{0}, \E{1}, \E{2}, \Theta) \,\, \uimpliedby \,\, \\
 &\iscnst(\E{1}) \uand \iscnst(\E{2}) \\
 &\unot (\E{1} = \E{2})
 \end{aligned}}
\end{align*}}
\end{center} 
& & \\
\hline
\end{tabular}.
\end{center}
\noindent By the \emph{assertion-goal version} of the resolution rule, we can derive the new goal 
  \begin{center}
\begin{tabular}{T}
%{|m{0.25\textwidth}|m{0.30\textwidth}||m{0.25\textwidth}|}
  \hline 
  
 & \begin{center}
{\begin{align*} \hspace{-.7cm}
 \begin{aligned}
&\iscnst(\e{1}) \uand \\ &\iscnst(\e{2}) \uand \\ &\unot(\e{1} = \e{2})
 \end{aligned}
\end{align*}}
\end{center}
 &  \begin{center}$\fail$ \end{center} \\
\hline
\end{tabular}.
\end{center}


\noindent In other words, when $\e{1}$ and $\e{2}$ are distinct constants, the failure indicator satisfies the input-output relation for the unification algorithm.



\subsection{Introduction of the Occurs Check}
\label{sec:occurs-check}
A unification algorithm must fail if one of its argument expressions is a proper subexpression of the other; unless infinite expressions are allowed, there is no proper substitution that unifies them.   (This is not so for the unification algorithms employed in the programming language Prolog, in which it is possible to include infinite terms in the unifier.) We now see how the occurs check is introduced into our algorithm.

We have established that, in any environment, if one expression is a subexpression of another, any substitution will be most-general idempotent.  Thus, we can use the assertion 

\begin{center}
\begin{tabular}
{|m{0.30\textwidth}|m{0.25\textwidth}||m{0.25\textwidth}|}
 \hline 
 \begin{center}
 ${\begin{aligned}
 &\boxed{{\mgi}(\Thet{0}, \E{1}, \E{2}, \Theta)} \,\, \uimpliedby \, \\
&\E{1} \occursin \E{2}.
   \end{aligned}}$
   \end{center}
  & 
  &  \\
\hline
\end{tabular}.
\end{center}
We also developed the \emph{most-general idempotent failure goal},
\begin{center}
\begin{tabular}{T}
 \hline 
  & 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
  \,\, & \boxed{{\mgi}(\thet{0}, \e{1}, \e{2}, \fail)}
\end{aligned}\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\fail$ \end{center} \\
\hline
\end{tabular}.
\end{center}
In other words, if the failure indicator $\fail$ is most-general idempotent for two expressions, it satisfies the conditions for the unification algorithm.

By the \emph{assertion-goal version} of the resolution rule, taking 
$\{\Thet{0} \mapsto \thet{0}, \E{1} \mapsto \e{1}, \E{2} \mapsto \e{2}, \Theta \mapsto \fail\}$, we obtain the new goal
\begin{center}
\begin{tabular}{T}
 \hline 
  & 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
  \,\, & {\e{1} \occursin \e{2}}
\end{aligned}\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\fail$ \end{center} \\
\hline
\end{tabular}.
\end{center}
(We have skipped over the paraphrase of the implication  \[\begin{aligned}
 {\mgi}(\Thet{0}, \E{1}, \E{2}, \Theta)  \uimpliedby \,
(\E{1} \occursin \E{2})
   \end{aligned}\]
   as the disjunction \[\begin{aligned}
 {\mgi}(\Thet{0}, \E{1}, \E{2}, \Theta)  \uor 
\unot(\E{1} \occursin \E{2})
   \end{aligned}\]
prior to application of the resolution rule.)

In other words, when one of the two argument expressions is a proper subexpression of the other, the failure indicator $\fail$ satisfies the input-output relation for the unification algorithm. Use of this row in subsequent proof steps accounts for the introduction of the occurs check into the derived algorithm.



\subsection{Introduction of a Conditional}

We have seen some early stages of the derivation.  Now, to give a simple example of the formation of a conditional construct, we skip ahead and show the final stage.  

We have described the formation of the portion of the program that handles the case in which the environment is not a proper substitution. In the final stage, we have also developed a goal that corresponds to the case in which the environment is indeed a proper substitution:

\begin{center}
\begin{tabular}{|m{0.22\textwidth}|m{0.36\textwidth}||m{0.22\textwidth}|}
 \hline 
  & 
  \begin{center}
  \begin{align*}
\boxed{\isprop(\thet{0})}
  \end{align*}
\end{center} & \begin{center}
\begin{align*}\mathcal{T} 
\end{align*}
\end{center} \\
\hline
\end{tabular}.
\end{center}

\noindent
Here, $\mathcal{T}$ stands for the portion of the program that handles the case in which $\theta$ is proper.  So as not to spoil the surprise, we do not yet show this program segment.

In the earlier stages, we obtained the goal row 

\begin{center}
\begin{tabular}{|m{0.22\textwidth}|m{0.36\textwidth}||m{0.22\textwidth}|}
 \hline 
  &  \begin{center}
\begin{align*}
\unot(\boxed{\isprop(\thet{0})})
\end{align*}
\end{center} 
    & \begin{center}
    \begin{align*}
    \fail 
    \end{align*}\end{center} \\
\hline
\end{tabular}.
\end{center}
Applying the \emph{goal-goal version} of the resolution rule, taking the most-general unifier to be the empty substitution $\{\}$ (since the boxed subformulas are already identical), we develop the final program

\noindent
\begin{center}
\begin{tabular} {|m{0.20\textwidth}|m{0.20\textwidth}||m{0.40\textwidth}|}
\hline
     & 
     \begin{center}
\begin{align*}
\emph{true}
\end{align*}
\end{center} 
& 
\hspace{-2cm} \[\begin{aligned}
\cond{\isprop(\thet{0})}{\mathcal{T}}{\fail}
 \end{aligned}\] \hspace{2cm}
\\
  \hline
\end{tabular}.
\end{center}

\noindent 
When $\isprop(\thet{0})$ is true, $\mathcal{T}$ is a suitable output. 
When $\isprop(\thet{0})$ is false, $\fail$ is a suitable output. So, in either case, the conditional $\cond{\isprop(\thet{0})}{\mathcal{T}}{\fail}$ is a suitable output.
\subsection{Introduction of the Replacement}\label{sec:replacement}
This section shows how the environment substitution is composed with a replacement substitution to yield a new unifier.  This occurs under a special circumstance, in which the first expression argument is a variable that is missed by the environment and that does not occur in the second expression argument, and the second expression argument is also missed by the environment.  

We do this in several stages:  we manipulate the case assumptions, we develop the unifier, we show that the unifier is an extension of the environment, and we establish that the unifier is most-general idempotent.


\subsubsection{Managing the Case Assumptions.}
We have assumed as a case assumption for the remainder of the derivation that 
the environment $\thet{0}$ is a proper substitution, i.e.,
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
$\boxed{\isprop(\thet{0})}$
\end{center}& & \begin{center} $\fail$ \end{center} \\  \hline
\end{tabular}.
\end{center}
Otherwise, the failure indicator $\fail$ meets the conditions of the specification.

In Section \ref{sec:occurs-check}, on the introduction of the occurs check, we introduced the case assumption that the first argument expression
 $\e{1}$ is not a proper subexpression of the second, $\e{2}$; that is,
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
$\boxed{\unot(\e{1} \occursin \e{2})}$
\end{center}& & \begin{center} $\fail$ \end{center} \\  \hline
\end{tabular}.
\end{center}
Otherwise, the argument expressions are not unifiable and, again, the failure indicator $\fail$ meets the conditions of the specification.

In Section \ref{sec:eq-exps}, we introduced another case assumption, that $\e{1}$ and $\e{2}$ are not the same, i.e.,
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
$\boxed{\unot(\e{1} = \e{2})}$
\end{center}& & \begin{center} $\thet{0}$ \end{center} \\  \hline
\end{tabular}.
\end{center}
Otherwise, the argument expressions are already equal, and the environment substitution $\thet{0}$ meets the conditions of the specification.

Recall the \emph{reflexive closure property} of the $\occursin$ relation,
\[E_1 \occurseq E_2 \uiff (E_1 \occursin E_2 \uor \E{1} = \E{2}). \]

In particular, the left-to-right implication 
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
&E_1 \occurseq E_2 \uimplies  \\
&\boxed{E_1 \occursin E_2} \uor \E{1} = \E{2} 
\end{aligned}
$
\end{center}& &  \\  \hline
\end{tabular}.
\end{center} 
can be included in our tableau as a valid assertion. (In our \SNARK\ implementation, the assertion would be translated into clausal form, as  
\[
\begin{aligned}[b]
&\unot(E_1 \occurseq E_2) \uor  \\
&\boxed{E_1 \occursin E_2} \uor \E{1} = \E{2}. 
\end{aligned})
\]
By the resolution rule applied to this assertion and the first of the above case assumptions, taking $E_1$ and $E_2$ to be $e_1$ and $e_2$, respectively, we obtain
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
\[
\begin{aligned}
&e_1 \occurseq e_2 \uimplies 
e_{1} = e_2
\end{aligned}
\]
\end{center}& & 
\begin{center} $\fail$ \end{center}
\\  \hline
\end{tabular}.
\end{center} 
Here no conditional has been introduced into the output entry, because one of the two resolved assertions has no output entry.

By a second application of the resolution rule, to the new assertion and the second of the two case assumptions (no substitutions are necessary, because the boxed subformulas are identical), we obtain 

\begin{center}
\begin{tabular}{|m{0.20\textwidth}|m{0.20\textwidth}||m{0.40\textwidth}|}
 \hline 
\begin{center}
$\boxed{\unot(\e{1} \occurseq \e{2})}$
\end{center}
  & 
& 
\begin{center}
$
\cond{e_1 = e_2}{\thet{0}}{\fail}
$ 
 \end{center}
\\
\hline
\end{tabular}
\end{center}
Here we have introduced a conditional term into the output entry, because both assertions have output entries.  

Thus, we can assume henceforth that $e_1$ is not a subexpression of $e_2$;  otherwise, the conditional term satisfies the conditions of the specification.


We also assume that $\e{1}$ is a variable, i.e.,
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
$\boxed{\isvar(\e{1})}$
\end{center}& & \begin{center} $\expsub{\mathcal{T}}{1}$ \end{center} \\  \hline
\end{tabular},
\end{center}
and that the environment substitution $\thet{0}$ misses $\e{1}$ and $\e{2}$, i.e.,
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
 $\boxed{\misses(\thet{0},\e{1})}$
\end{center} 
& & \begin{center} $\expsub{\mathcal{T}}{2}$ \end{center} \\  \hline
\end{tabular}
\end{center}
and 
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
 $\boxed{\misses(\thet{0},\e{2})}$
\end{center} 
& & \begin{center} $\expsub{\mathcal{T}}{3}$ \end{center} \\  \hline
\end{tabular}.
\end{center}
These rows have output entries ($\expsub{\mathcal{T}}{1}$, $\expsub{\mathcal{T}}{2}$ and $\expsub{\mathcal{T}}{3}$) that correspond to program segments that satisfy the conditions of the specification when the corresponding assertions are false.  These entries will be derived in other sections of the derivation.  \SNARK\ will introduce conditional expressions when each of these assumptions is used, but we ignore them for the moment. 

We also can assert the definition of the $\misses$ relation, 

\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
\[ \boxed{\misses(\Theta, \var{E})} \uiff \var{E} \apply \Theta = \var{E} \]\hspace{1cm} 
 \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
Applying the \emph{equivalence replacement rule} to this and  two case assertions, that the environment misses the two expression arguments (taking $\Theta$ to be  $\thet{0}$ and $\var{E}$ to be $\e{1}$ and $\e{2}$ respectively), we paraphrase the two case assertions as
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
{$\e{1} \apply \thet{0} = \e{1} $}\hspace{1cm} 
 \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}
\end{center}
and
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
{$\e{2} \apply \thet{0} = \e{2} $}\hspace{1cm} 
 \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
This concludes our handling of the case assumptions; we now look at how the unifier is found.
\subsubsection{Finding the Unifier.} Earlier we developed the \emph{expanded initial goal}
\begin{center}
\begin{tabular}{|m{0.20\textwidth}|m{0.40\textwidth}||m{0.20\textwidth}|}
 \hline 
  & 
  \begin{center}
${\begin{aligned} 
&\begin{aligned}
&\boxed{\e{1} \apply \Theta} = \boxed{\e{2} \apply \Theta} \, \uand 
 \\
 \,\, & \thet{0} \moregen \Theta \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \Theta)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\Theta$ \end{center} \\
\hline
\end{tabular}.
\end{center}
We first apply the \emph{equality replacement rule} twice in succession to the \emph{composition property}
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
%\begin{tabularx} {\linewidth}{| Y | c || c |}
\hline
\begin{center}
{$\begin{aligned}
\boxed{\var{E} \apply (\Thet{1}\! \compose \Thet{2})} = (\var{E} \apply \Thet{1}) \apply \Thet{2}
\end{aligned}$} \hspace{1cm} 
\end{center}& &  \\  \hline
%\end{tabularx}
\end{tabular}
\end{center}
and this goal, taking  $\var{E}$ to be $\e{1}$ and $e_2$, respectively, and $\Theta$ to be $\Thet{1}\! \compose \Thet{2}$, to obtain
\begin{center}
\begin{tabular}{|m{0.20\textwidth}|m{0.40\textwidth}||m{0.20\textwidth}|}
 \hline 
  &\begin{center} 
$
\begin{aligned}
&\begin{aligned}&\boxed{(\e{1} \apply \Thet{1})} \apply \Thet{2} = \\ 
                &\quad \boxed{(\e{2} \apply \Thet{1})} \apply \Thet{2} \uand \end{aligned}   \\
 \,\, & \thet{0} \moregen \Thet{1}\! \compose \Thet{2} \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \Thet{1}\! \compose \Thet{2})
\end{aligned}.$
\end{center}
& 
\begin{center}$\Thet{1}\! \compose \Thet{2}$ \end{center}\\
\hline
\end{tabular}
\end{center}                                                                                                     The composition of two substitutions, yet to be determined, has been introduced into the output entry. By two applications of the \emph{equality replacement rule}  to this goal and our rephrasing of the statements that $\thet{0}$ misses $\e{1}$ and $\e{2}$, that is
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
{$\boxed{\e{1} \apply \thet{0}}= \e{1} $}\hspace{1cm} 
 \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}
\end{center}
and
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
{$\boxed{\e{2} \apply \thet{0}}= \e{2} $}\hspace{1cm} 
 \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
respectively, taking $\Thet{1}$ to be $\thet{0}$, we obtain

\begin{center}
\begin{tabular}{|m{0.20\textwidth}|m{0.40\textwidth}||m{0.20\textwidth}|}
 \hline 
  &\begin{center} 
$
\begin{aligned}
&\begin{aligned}&\boxed{\e{1} \apply \Thet{2}} = \e{2} \apply \Thet{2} \uand \end{aligned}   \\
 \,\, & \thet{0} \moregen (\thet{0}\! \compose \Thet{2}) \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, (\thet{0}\! \compose \Thet{2}))
\end{aligned}.$
\end{center}
& 
\begin{center}$\thet{0}\! \compose \Thet{2}$ \end{center}\\
\hline
\end{tabular}.
\end{center}
 Here, the first of the two substitutions in the composition, $\Thet{0}$, has been found to be $\thet{0}$.

We  defined the replacement substitution $\{\E{1} \mapsto \E{2}\}$ to satisfy the \emph{replacement identity} property 
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
\hspace{-.5cm}
{\begin{aligned}
&\boxed{\E{1} \apply \{\E{1} \mapsto \E{2} \}} = \E{2} \quad \uimpliedby \\ &\boxed{\isvar(\E{1}) }
\end{aligned}}
\end{aligned}
$
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
By the \emph{equality replacement rule}, taking $\E{1}$ to be $\e{1}$ and $\Theta_2$ to be $\{e_1 \mapsto E_2\}$, followed by resolution with the case assumption
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
$
\boxed{\isvar(\e{1})} 
$
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
we obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.50\textwidth}||m{0.20\textwidth}|}
 \hline 
  &\begin{center} 
$
\begin{aligned}
&\begin{aligned}&\boxed{\E{2} = \e{2} \apply \{\e{1} \mapsto  \E{2}\}} \uand \end{aligned}   \\
 \,\, & \thet{0} \moregen (\thet{0} \compose \{\e{1} \mapsto  \E{2}\} \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, (\thet{0} \compose \{\e{1} \mapsto  \E{2}\}))
\end{aligned}.$
\end{center}
& 
\begin{center}$\thet{0} \compose \{\e{1} \mapsto  \E{2}\}$ \end{center}\\
\hline
\end{tabular}
\end{center}
Here, a replacement has been introduced into the output entry.  
The replaced variable is the first input expression $\e{1}$; the introduced expression $\E{2}$ has yet to be determined.

Earlier, we established a \emph{replacement non-occur property}
\begin{center}
  \begin{tabular}{|m{0.50\textwidth}|m{0.10\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
&\boxed{\var{D} \apply \{\E{1} \mapsto \E{2} \} = \var{D}} \quad \uimpliedby \\
&\left[\begin{aligned}  
&\!\isvar(\E{1}) \uand \\
&\!\unot(\E{1} \occurseq \var{D})
\end{aligned}\right]
\end{aligned}
$
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
which means that a replacement has no effect on an expression if the replaced variable does not occur in the expression.  We apply the \emph{resolution rule}---\SNARK\ can reverse the arguments of the equality symbol---taking $\var{D}$ to be $\e{2}$, $\E{1}$ to be $\e{1}$, and $E_2$ to be $e_2$, and again resolving with the above case assumptions $\isvar(\e{1})$ and $\unot(\e{1} \occurseq \e{2})$,  to obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.50\textwidth}||m{0.20\textwidth}|}
 \hline 
  &\begin{center} 
$
\begin{aligned}
&     \boxed{\thet{0} \moregen (\thet{0} \compose \{\e{1} \mapsto  \e{2}\})} \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, (\thet{0} \compose \{\e{1} \mapsto  \e{2}\})) \\
  \end{aligned}$
\end{center}
& 
\begin{center}$\thet{0} \compose \{\e{1} \mapsto  \e{2}\}$ \end{center}\\
\hline
\end{tabular}
\end{center}
Here, the introduced expression $E_2$ in the output entry has been found to be the second input expression, 
$e_2$.

\subsubsection{Establishing the More-Generality Property.}  The \emph{composition property} of the relation $\moregen$ told us that
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
{$
 {\begin{aligned}  
 &\Thet{0} \moregen \Thet{1} \, \uimplies \\
 &\boxed{\Thet{0} \moregen \Thet{1}\! \compose \Thet{2}}
 \end{aligned}}
$}
\end{center}& &  \\  \hline
\end{tabular}
\end{center}
By applying the resolution rule, taking $\Thet{0}$ and $\Thet{1}$ to be $\thet{0}$, and $\Thet{2}$ to be $\{\e{1} \mapsto  \e{2}\},$ we obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.50\textwidth}||m{0.20\textwidth}|}
 \hline 
  &\begin{center} 
$\begin{aligned}
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, (\thet{0} \compose \{\e{1} \mapsto  \e{2}\})) \uand \\
  &\boxed{\thet{0} \moregen \thet{0}}
  \end{aligned}$
\end{center}
& 
\begin{center}$\thet{0} \compose \{\e{1} \mapsto  \e{2}\}$ \end{center}\\
\hline
\end{tabular}.
\end{center}
The boxed subsentence says that $\thet{0}$ is idempotent---exactly our initial assumption;  it is whisked away by the resolution rule, leaving us with the goal
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.50\textwidth}||m{0.20\textwidth}|}
 \hline 
  &\begin{center} 
$\begin{aligned}
  \,\, & \boxed{{\mgi}(\thet{0}, \e{1}, \e{2}, (\thet{0} \compose \{\e{1} \mapsto  \e{2}\}))} 
  \end{aligned}$
\end{center}
& 
\begin{center}$\thet{0} \compose \{\e{1} \mapsto  \e{2}\}$ \end{center}\\
\hline
\end{tabular}.
\end{center}

\subsubsection{Establishing Most-Generality and Idempotence.} We have shown the \emph{mgi replacement property}, that the replacement substitution is  most-general and idempotent; that is,

\begin{center}
  \begin{tabular}{|m{0.50\textwidth}|m{0.10\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}$
\begin{aligned}
    &\boxed{\mgi(\Thet{0}, \E{1}, \E{2}, (\Thet{0} \compose \{\E{1} \mapsto \E{2}\})} \, \uimpliedby \\
    &\isvar(\E{1})
\end{aligned}
$\end{center}
& &  \\  \hline
\end{tabular}
\end{center}
Applying the resolution rule to this assertion and the most recent goal, 
taking $\Thet{0}$ to be $\thet{0}$ and $\E{1}$ and $\E{2}$ to be $\e{1}$ and $\e{2}$, respectively, followed by resolution with the case assumption $\isvar(\e{1})$, we obtain the final goal
\begin{center}
\begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
 \hline 
  &\begin{center} 
$\begin{aligned}
  true
  \end{aligned}$
\end{center}
& 
\begin{center}$\thet{0} \compose \{\e{1} \mapsto  \e{2}\}$ \end{center}\\
\hline
\end{tabular}
\end{center}
In the context of the full derivation, the goal would have other conjuncts and  output entry would be one node in a larger conditional expression.   

\subsection{Introduction of the Recursive Calls}

We have said that recursive calls are introduced by application of the well-founded induction principle. The induction hypothesis is added to the initial tableau as an assertion at the beginning of the derivation.  For the derivation of the unification algorithm, we began with the initial tableau


    

\begin{center}  
\begin{tabular}{|m{0.20\textwidth}|m{0.40\textwidth}||m{0.20\textwidth}|}
 \hline
 \begin{center} Assertions\end{center} & \begin{center} Goals \end{center}& \begin{center} $\unify(\thet{0}, \e{1}, \e{2})$ \end{center} \\
 \hline\hline  
  & % \vspace{-15pt}
  \begin{center}
      $\begin{aligned}[t] &
  \idem(\thet{0}) \uimplies \\  &\,{\mgiu}(\thet{0}, \e{1}, \e{2}, \Theta) \\ \end{aligned}$  
  \end{center}
  & \vspace{5pt}{\begin{center}$\Theta$\end{center}} \\

\hline
\end{tabular}.
\end{center}



   We form the three inputs into a triple (3-tuple), which we treat as a single entity.
   Our implementation uses an ordinary function symbol \emph{tuple} for singletons, pairs, triples, and so forth, and $\emph{tuple}(\expsub{\var{x}}{1}, \expsub{\var{x}}{2}, \expsub{\var{x}}{3})$  stands for $\langle\expsub{\var{x}}{1}, \expsub{\var{x}}{2}, \expsub{\var{x}}{3}\rangle.$ 
  
  We conduct the proof under the induction hypothesis that recursive calls $\unify(\Thet{0}', \E{1}',\E{2}')$ to the program $\unify$ we are in the process of constructing will satisfy the input-output condition  \begin{align*}\begin{aligned}[t] &\idem(\Thet{0}') \uimplies \\ &\,{\mgiu}(\Thet{0}', \E{1}', \E{2}' , \unify(\Thet{0}', \E{1}', E{2}'))\end{aligned}\end{align*}
for any input triple $\langle \Thet{0}', \E{1}', \E{2}' \rangle$ such that $\langle\Thet{0}', \E{1}', \E{2}'\rangle \, \expsub{\prec}{U} \, \langle\thet{0}, \e{1}, \e{2}\rangle.$ (The symbols $\Thet{0}'$, $\E{1}'$, and $\E{2}'$ are variables.)  Here, $\expsub{\prec}{U}$ is the well-founded relation, previously unspecified, for the unification algorithm.   We add this induction hypothesis to the initial tableau as an assertion:

    



\noindent 


  \begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
%\begin{tabularx} {\linewidth}{| Y | c || c |}
\hline
\begin{center}
{$\begin{aligned}
&\langle\Thet{0}', \E{1}', \E{2}'\rangle \, \expsub{\prec}{U} \, \langle\thet{0}, \e{1}, \e{2}\rangle \uimplies \\
&\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right]\end{aligned}$} \hspace{1cm} 
\end{center}& &  \\  \hline
%\end{tabularx}
\end{tabular}.
\end{center}

\subsubsection{Introduction of the Well-Founded Relation.}\label{par:wfrelunif} In a \emph{Deus ex Machina} step, we chose the well-founded relation $\expsub{\prec}{\var{U}}$, called the \emph{unification \textup{(}\!well-founded\textup{)} relation}, to be a lexicographic combination of two relations, the \emph{range-vars} relation
$\expsub{\prec}{range-vars}$, defined on substitutions and expressions by


  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
%\begin{tabularx} {\linewidth}{| Y | c || c |}
\hline
\begin{center}
{$\begin{aligned}
    &\langle \Thet{0}', \E{1}', \E{2}' \rangle 
\,\expsub{\prec}{range-vars}
    \langle \Thet{0}, \E{1}, \E{2} \rangle \uiff \\
    &\left[\begin{aligned}
     &\range(\Thet{0}') \cup \vars(\langle \E{1}', \E{2}'\rangle) \subset \\
     &\range(\Thet{0}) \cup \vars(\langle \E{1}, \E{2}\rangle)
     \end{aligned}\right]
\end{aligned}$} \hspace{1cm} 
\end{center}& &  \\  \hline
%\end{tabularx}
\end{tabular},
\end{center}
and the \emph{size-first} relation $\expsub{\prec}{size\, 1}$, defined by
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
%\begin{tabularx} {\linewidth}{| Y | c || c |}
\hline
\begin{center}
{$\begin{aligned}
    &\langle \Thet{0}', \E{1}', \E{2}' \rangle 
\,\expsub{\prec}{\size\, 1}
    \langle \Thet{0}, \E{1}, \E{2} \rangle \uiff \\
    &\size(\E{1}') < \size(\E{1})
\end{aligned}$} \hspace{1cm} 
\end{center}& &  \\  \hline
%\end{tabularx}
\end{tabular}.
\end{center}
We take the \emph{unification well-founded relation} $\expsub{\prec}{U}$ to be the lexicographic combination 
$\expsub{\prec}{\lex(range-vars, \size \, 1)}$ of these relations.  It satisfies the
\emph{reflexive lexicographic property},  
 \begin{center}
    $
  \begin{aligned}
    & \begin{aligned}
 &\langle \Thet{0}', \E{1}', \E{2}' \rangle 
 \, \expsub{\prec}{\var{U}} \,
 \langle \Thet{0}, \E{1}, \E{2} \rangle \\
 \end{aligned}  \uiff \\
    &\left[\begin{aligned}
 &\left\{\begin{aligned}
&\range(\Thet{0}')\cup\vars(\langle  \E{1}', \E{2}' \rangle) \subset \\
  &\range(\Thet{0})\cup\vars(\langle \E{1}, \E{2} \rangle) 
  \end{aligned}\right\} \uor \\ 
&\left[\begin{aligned}
 &\left\{\begin{aligned}
 &\range(\Thet{0}')\cup\vars(\langle  \E{1}', \E{2}' \rangle) \subseteq \\
  &\range(\Thet{0})\cup\vars(\langle \E{1}, \E{2} \rangle) 
  \end{aligned}\right\} \uand  \\
  &\size(\E{1}') < \size(\E{1})
  \end{aligned} \right] 
  \end{aligned} \right]
  \end{aligned}
    $.
 \end{center}
By propositional reasoning, using the implication
\[
(
((\mathcal{P} \uor \mathcal{Q}) \uimplies \mathcal{R})
\uimplies
(
(\mathcal{P} \uimplies \mathcal{R})
\uand\,
(\mathcal{Q} \uimplies \mathcal{R})
)
),
\]
taking $\mathcal{P}$ to be \[\left\{\begin{aligned}
&\range(\Thet{0}')\cup\vars(\langle  \E{1}', \E{2}' \rangle) \subset \\
  &\range(\Thet{0})\cup\vars(\langle \E{1}, \E{2} \rangle) 
  \end{aligned}\right\},  \]
  $\mathcal{Q}$ to be
  \[\left[\begin{aligned}
 &\left\{\begin{aligned}
 &\range(\Thet{0}')\cup\vars(\langle  \E{1}', \E{2}' \rangle) \subseteq \\
  &\range(\Thet{0})\cup\vars(\langle \E{1}, \E{2} \rangle) 
  \end{aligned}\right\} \uand  \\
  &\size(\E{1}') < \size(\E{1})
  \end{aligned} \right], \]
and  $\mathcal{R}$ to be
\[\begin{aligned}
 &\langle \Thet{0}', \E{1}', \E{2}' \rangle 
 \, \expsub{\prec}{\var{U}} \,
 \langle \Thet{0}, \E{1}, \E{2} \rangle \\
 \end{aligned},\]
we have that either of the two disjuncts, $\mathcal{P}$ or $\mathcal{Q}$, on the right side implies that the unification relation, $\mathcal{R}$,  holds;  so we have the \emph{range-vars property of the unification relation},
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
 \begin{center}
    $
  \begin{aligned}
   &\left\{\begin{aligned}
&\range(\Thet{0}')\cup\vars(\langle  \E{1}', \E{2}' \rangle) \subset \\
  &\range(\Thet{0})\cup\vars(\langle \E{1}, \E{2} \rangle) 
  \end{aligned}\right\}     
    & \begin{aligned}
 &\\
 \end{aligned}\, \\
&\uimplies  \boxed{\langle \Thet{0}', \E{1}', \E{2}' \rangle 
\,  \expsub{\prec}{\var{U}} \,
 \langle \Thet{0}, \E{1}, \E{2} \rangle}                     
  \end{aligned} 
    $
 \end{center}
  & &  \\  \hline
\end{tabular},
\end{center}
and the \emph{size-first property of the unification relation}, 
 
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
 \begin{center}
    $
    \begin{aligned}
      &\left[\begin{aligned}
&\left[\begin{aligned}
 &\left\{\begin{aligned}
 &\range(\Thet{0}')\cup\vars(\langle  \E{1}', \E{2}' \rangle) \subseteq \\
  &\range(\Thet{0})\cup\vars(\langle \E{1}, \E{2} \rangle) 
  \end{aligned}\right\} \uand  \\
  &\size(\E{1}') < \size(\E{1})
  \end{aligned} \right] 
  \end{aligned} \right]
      \\
 & \uimplies \,  \begin{aligned}
 &\boxed{\langle \Thet{0}', \E{1}', \E{2}' \rangle 
 \, \expsub{\prec}{\var{U}}\, 
 \langle \Thet{0}, \E{1}, \E{2} \rangle}
 \end{aligned} 
  \end{aligned} 
    $
 \end{center}
  & &  \\  \hline
\end{tabular}.
\end{center}


By the \emph{resolution rule}, applied to the \emph{range-vars property of the unification relation} and the induction hypothesis

  \begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
%\begin{tabularx} {\linewidth}{| Y | c || c |}
\hline
\begin{center}
{$\begin{aligned}
&\boxed{\langle\Thet{0}', \E{1}', \E{2}'\rangle \, \expsub{\prec}{U} \, \langle\thet{0}, \e{1}, \e{2}\rangle} \uimplies \\
&\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right]\end{aligned}$} \hspace{1cm} 
\end{center}& &  \\  \hline
%\end{tabularx}
\end{tabular}
\end{center}
(taking $\Thet{0}$ to be $\thet{0}$ and $\E{1}$ and $\E{2}$ to be $\e{1}$ and $\e{2}$, respectively)  we obtain the assertion
 \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
& \left\{\begin{aligned}
&\range(\Thet{0}')\cup\vars(\langle  \E{1}', \E{2}' \rangle) \subset \\
  &\range(\Thet{0})\cup\vars(\langle \e{1}, \e{2} \rangle) 
  \end{aligned}\right\} 
\end{aligned} \\
\uimplies  &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
  &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
to be referred to as the \emph{range-vars induction hypothesis}. This says that the induction hypothesis holds if the set of variables in the range of the environment substitution or in the input expressions is strictly reduced.

Similarly, by the \emph{resolution rule} applied to the \emph{size-first property of the unification relation} and the induction hypothesis (taking $\Thet{0}$ to be $\thet{0}$ and $\E{1}$ and $\E{2}$ to be $\e{1}$ and $\e{2}$, respectively), we obtain the new assertion

  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\begin{aligned}
&\left[\begin{aligned}
 &\left\{\begin{aligned}
 &\range(\Thet{0}')\cup\vars(\langle \E{1}', \E{2}' \rangle) \subseteq \\
  &\range(\thet{0})\cup\vars(\langle \e{1}, \e{2} \rangle) 
  \end{aligned}\right\} \uand  \\
  &\size(\E{1}') < \size(\e{1})
  \end{aligned} \right] 
  \end{aligned} 
\end{aligned} \\
 \uimplies &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
to be referred to as the \emph{size-first induction hypothesis}. This says that the induction hypothesis holds if the size of the first expression argument is strictly reduced, and if the  set of variables in the range of the environment substitution and in the input expressions is reduced or remains the same.

In the definition of  $\expsub{\prec}{\var{U}}$, we could use an
 analogous \emph{size-second} relation $\expsub{\prec}{size \, 2}$ instead of $\expsub{\prec}{size \, 1}$; if we choose to use that in the proof, we obtain a symmetric version of the same algorithm.



 In our implemented derivation, these assertions are given to \SNARK\ as lemmas.  In future work, we would like to have \SNARK\ discover the combination of well-founded relations itself.

 \subsubsection{Reversing the Expression Arguments.} In this section, we  use the \emph{size-first induction hypothesis} to introduce a recursive call.

We early on developed the \emph{initial goal}
\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | } \hline 
  & \vspace{-.3cm}\begin{center} $\boxed{{\mgiu}(\thet{0}, \e{1}, \e{2} , \Theta)} $  \end{center}  & \vspace{-5pt}\begin{center}$\Theta$\end{center} \\
\hline
\end{tabularx}.
\end{center}

Applying the \emph{equivalence replacement rule} to the \emph{symmetry property} of the  most-general idempotent-unifier relation, expressed in the valid assertion
 \begin{center}
\begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
 \hline
  \[ \begin{aligned}
  &\boxed{{\mgiu}(\Thet{0}, \E{1}, \E{2}, \Theta)} \,\, \uiff \,\, \\
  &\,\,{\mgiu}(\Thet{0}, \E{2}, \E{1}, \Theta)
 \end{aligned} \]
  & 
  &  \\
\hline
\end{tabular}.
\end{center}
 (taking $\Thet{0}$ to be $\thet{0}$ and $\E{1}$ and $\E{2}$ to be $\e{1}$ and $\e{2}$, respectively) gives us the new goal
\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | } \hline 
  & \vspace{-.3cm}\begin{center} $\boxed{{\mgiu}(\thet{0}, \e{2}, \e{1}, \Theta)} $  \end{center}  & \vspace{-5pt}\begin{center}$\Theta$\end{center} \\
\hline
\end{tabularx},
\end{center}
in which the two expression arguments are reversed.


Applying resolution to the \emph{size-first induction hypothesis},
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\begin{aligned}
&\left[\begin{aligned}
 &\left\{\begin{aligned}
 &\range(\Thet{0}') \cup \vars(\langle \E{1}', \E{2}' \rangle) \subseteq \\
  &\range(\thet{0})\cup\vars(\langle \e{1}, \e{2}, \rangle) 
  \end{aligned}\right\} \uand  \\
  &\size(\E{1}') < \size(\e{1})
  \end{aligned} \right] 
  \end{aligned} 
\end{aligned} \\
 \uimplies &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\boxed{\begin{aligned}
    \,{\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
and the above goal, taking $\Thet{0}'$ to be $\thet{0}$, $\E{1}'$ and $\E{2}'$ to be $ \e{2} $ and $ \e{1}$, respectively, and $\Theta$ to be $\unify(\thet{0}, \e{2}, \e{1})$, we obtain the new goal 
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.41\textwidth}||m{0.29\textwidth}|}
 \hline 
  & 
 \begin{center}
{$\begin{aligned}
 &\begin{aligned}
  &\,\range(\thet{0}) \cup \vars(\langle \e{2}, \e{1}\rangle ) \\ 
  &\,  \subseteq \range(\thet{0}) \cup \vars( \langle \e{1}, \e{2}\rangle )  \\
  & \uand \size(\e{2}) < \size(\e{1})
\end{aligned}  \\
& \uand \boxed{\idem(\thet{0})} 
 \end{aligned} $}
\end{center}
& 
\begin{center}$\unify(\thet{0}, \e{2}, \e{1})$ \end{center}\\
\hline
\end{tabular}.
\end{center}
Here, a recursive call in which the expression arguments are reversed has been introduced into the output column.


We simplify this by resolution with the \emph{initial assertion} that $\thet{0}$ is idempotent,
\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
\vspace{-.3cm}\begin{center}$\idem(\thet{0} )$\end{center} &  & \\
\hline
\end{tabularx},
\end{center}
to obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.41\textwidth}||m{0.29\textwidth}|}
 \hline 
  & 
 \begin{center}
{$\begin{aligned}
 &\begin{aligned}
  &\,\range(\thet{0}) \cup \vars(\langle \e{2}, \e{1}\rangle ) \\ 
  &\,  \subseteq \range(\thet{0}) \cup \vars( \langle \e{1}, \e{2}\rangle )  \\
  & \uand \size(\e{2}) < \size(\e{1})
\end{aligned}  \\
& \uand \boxed{\idem(\thet{0})} 
 \end{aligned} $}
\end{center}
& 
\begin{center}$\unify(\thet{0}, \e{2}, \e{1})$ \end{center}\\
\hline
\end{tabular}.
\end{center} 
We can further simplify this, using the assertion that
 
\begin{center}
\begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
 \hline
  \[ \begin{aligned}
  &\vars(\langle \E{1}, \E{2} \rangle) = 
  \vars(\langle \E{2}, \E{1} \rangle)
 \end{aligned} \]
  & 
  &  \\
\hline
\end{tabular}
\end{center}
and the reflexivity of the subset relation $\subseteq$, to obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.41\textwidth}||m{0.29\textwidth}|}
 \hline 
  & 
 \begin{center}
{$\begin{aligned}
 &\begin{aligned}
  & \size(\e{2}) < \size(\e{1})
\end{aligned}  \\
 \end{aligned} $}
\end{center}
& 
\begin{center}$\unify(\thet{0}, \e{2}, \e{1})$ \end{center}\\
\hline
\end{tabular}.
\end{center} 
In other words, in any case in which the second expression is smaller than the first, we can meet the specification for the unification algorithm simply by reversing the arguments.  In particular, we can reverse arguments if the second argument is a variable (of size 0) and the first a constant (of size 1), or if the second argument is an atom and the first is not.  When the second expression is not smaller, if we introduce this recursive call we are in danger of constructing a nonterminating algorithm.

\subsubsection{Introduction of the Instance Recursive Call.} In this section, we use the \emph{range-vars induction hypothesis} to introduce a recursive call.
Again, we start from the \emph{initial goal}
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.40\textwidth}||m{0.30\textwidth}|} \hline 
  & \begin{center} $\boxed{{\mgiu}(\thet{0}, \e{1}, \e{2} , \Theta)} $  \end{center}  & \begin{center}$\Theta$\end{center} \\
\hline
\end{tabular}.
\end{center}
We have among our valid assertions the \emph{instance} property of most-general idempotent unifiers,
 

\begin{center}
\begin{tabular}{|m{0.45\textwidth}|m{0.05\textwidth}||m{0.30\textwidth}|}
 \hline
% \begin{center}
 \hspace{-20pt}
  {\[\begin{aligned} 
  &\boxed{{\mgiu}(\Thet{0}, \E{1}, \E{2}, \Theta)} \,\, \uiff \,\, \\
  &{\mgiu}(\Thet{0}, \E{1}\!\apply\Thet{0}, \E{2}\!\apply\Thet{0}, \Theta)
 \end{aligned} \]}\hspace{20pt}
 %\end{center}
  & 
  &  \\
\hline
\end{tabular}.
\end{center}
By the \emph{equivalence replacement rule} (taking $\Thet{0}$ to be $\thet{0}$ and $\E{1}$ and $\E{2}$ to be $\e{1}$ and $\e{2}$, respectively), we can obtain the new goal
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.40\textwidth}||m{0.30\textwidth}|} \hline 
  & \begin{center}$ \boxed{{\mgiu}(\thet{0}, \e{1}\apply\thet{0}, \e{2}\apply\thet{0} , \Theta)}$  \end{center}  & \begin{center}$\Theta$\end{center} \\
\hline
\end{tabular}.
\end{center}
Applying resolution to the \emph{range-vars induction hypothesis}, 
     \begin{center}
  \begin{tabular}{|m{0.45\textwidth}|m{0.05\textwidth}||m{0.30\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
& \left\{\begin{aligned}
&\range(\Thet{0}')\cup\vars(\langle  \E{1}', \E{2}' \rangle) \subset \\
  &\range(\Thet{0})\cup\vars(\langle \E{1}, \E{2} \rangle) 
  \end{aligned}\right\} 
\end{aligned} \\
\uimplies  &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
  &\boxed{\begin{aligned}
    {\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}'))
\end{aligned}}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
and the above goal, taking $\Thet{0}'$ to be $\thet{0}$, $\E{1}'$ and $\E{2}'$ to be $ \e{1}\apply\thet{0} $ and $ \e{2}\apply\thet{0}$, respectively, and $\Theta$ to be $\unify(\thet{0}, \e{1}\apply\thet{0}, \e{2}\apply\thet{0})$, we obtain the new goal 
\begin{center}
\begin{tabular}{|m{0.07\textwidth}|m{0.43\textwidth}||m{0.30\textwidth}|}
 \hline 
  & 
 \begin{center}
{$\begin{aligned}
 &\begin{aligned}
  &\,\range(\thet{0}) \cup \vars(
  \boxed{\langle \e{1}\apply\thet{0}, \e{2}\apply\thet{0}\rangle} 
  ) \\ 
  &\quad  \subset \range(\thet{0}) \cup \vars( \langle \e{1}, \e{2}\rangle ) 
\end{aligned}  \\
& \uand \idem(\thet{0}) 
 \end{aligned} $}
\end{center}
& 
\begin{center}$\unify(\thet{0}, \e{1}\apply\,\thet{0}, \e{2}\apply\,\thet{0})$ \end{center}\\
\hline
\end{tabular}.
\end{center}
Here, a recursive call has been introduced into the output column.

We have remarked that substitutions distribute over tuples; that is, we have the valid assertion

  \begin{center}
  \begin{tabular}{|m{0.42\textwidth}|m{0.08\textwidth}||m{0.30\textwidth}|}
\hline
\begin{center}
\vspace{15pt}
{$\begin{aligned}
        \langle \E{1}, \E{2} \rangle \apply \Theta =
        \boxed{\langle \E{1}\apply\Theta, \, \E{2}\apply\Theta \rangle}
    \end{aligned}$}
\end{center}  \hspace{1cm} 
&  & \\  \hline
\end{tabular}.
\end{center} 
By the \emph{equality replacement rule}, right to left, we rewrite the above goal as
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.40\textwidth}||m{0.30\textwidth}|}
 \hline
  & 
 \begin{center}
{$\begin{aligned}
 &\boxed{\begin{aligned}
  &\,\range(\thet{0}) \cup \vars(\langle \e{1}, \e{2}\rangle \apply\thet{0} ) \\ 
  &\,  \subset \range(\thet{0}) \cup \vars( \langle \e{1}, \e{2}\rangle ) 
\end{aligned}}  \\
& \uand \idem(\thet{0}) 
 \end{aligned} $}
\end{center}
& 
\begin{center}$\unify(\thet{0}, \e{1}\apply\,\thet{0}, \e{2}\apply\,\thet{0})$ \end{center}\\
\hline
\end{tabular}.
\end{center}

By the \emph{vars-range proper-subset property}, we have the following valid assertion:
 \begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.10\textwidth}||m{0.30\textwidth}|}
\hline
\begin{center}
$ \begin{aligned}
    &\,
    \boxed{\begin{aligned}
    &\range(\Theta) \cup \vars(\var{E} \apply \Theta) \\
    &\,\subset\, \range(\Theta) \cup \vars(\var{E}) \\    
    \end{aligned}} \,\uimpliedby \\
     &\idem(\Theta) \uand \unot(\misses(\Theta, \var{E}))
\end{aligned}$
\end{center} \hspace{1cm} 
&  & \\  \hline
\end{tabular}.
\end{center} 
By the resolution rule, taking $\Theta$ to be $\thet{0}$ and $\var{E}$ to be $\langle \e{1}, \e{2}\rangle$, we obtain the new goal

\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.40\textwidth}||m{0.30\textwidth}|}
 \hline 
  & 
 \begin{center}
{$
\begin{aligned}
 &\boxed{\idem(\thet{0})} \uand  \\
 &\unot(\misses(\thet{0},\langle \e{1}, \e{2}\rangle)
\end{aligned}
  $}
\end{center}
& 
\vspace{5pt}
\begin{center}$\unify(\thet{0}, \e{1}\apply\,\thet{0}, \e{2}\apply\,\thet{0})$ \end{center}\\
\hline
\end{tabular}.
\end{center}
In other words, when the environment substitution is idempotent and does not miss both the input expressions, a recursive call in which the environment is applied to the inputs will satisfy the specification. 

If the environment $\thet{0}$ were not idempotent, the above recursive call could lead to an infinite computation. For instance, if the environment substitution merely permuted some variables, it would not be idempotent and no reduction in the well-founded relation would be achieved.  But we know by our initial assertion
\begin{center}
\begin{tabular}{|m{0.20\textwidth}|m{0.30\textwidth}||m{0.30\textwidth}|}
 \hline 
\vspace{-.0cm}\begin{center}$\boxed{\idem(\thet{0})} $\end{center} &  & \\
\hline
\end{tabular}
\end{center}
that the environment substitution is idempotent. Applying resolution to that assertion and the most recent goal, we obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.40\textwidth}||m{0.30\textwidth}|}
 \hline 
  & 
 \begin{center}
{$
\begin{aligned}
 &\unot(\misses(\thet{0},\langle \e{1}, \e{2}\rangle)
\end{aligned}
  $}
\end{center}
& 
\vspace{5pt}
\begin{center}$\unify(\thet{0}, \e{1}\apply\,\thet{0}, \e{2}\apply\,\thet{0})$ \end{center}\\
\hline
\end{tabular}.
\end{center}
That is, the recursive call will satisfy the specification as long as the environment substitution misses both input expressions.  

The cases in which $\thet{0}$ does miss both input expressions are handled by other branches of the search space. For instance, this was among the case assumptions when the replacement was introduced. (Section \ref{sec:replacement}) 

\subsubsection{Introduction of the Recursive Calls for Nonatomic expressions.}

This is the most complex part of the derivation. \paragraph{Development of the Nonatomic Induction Hypotheses.}\label{par:nonatomicindhyp} The unification algorithms we obtain employs nested recursive calls when both expressions are nonatomic. This is an instance in which \SNARK\ discovered a program simpler than the one we  anticipated.

In this section, we assume that we have handled the cases in which $\e{1}$ or $\e{2}$ is atomic, or in which $\thet{0}$ does not miss $\e{1}$  or $\e{2}$, obtaining subprograms  $\mathcal{T_1}$, $\mathcal{T_2}$, and $\mathcal{T_3}$, respectively; that is, we include among our assertions the \emph{nonatomic case assumptions} 
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$\boxed{{\unot(\isatm(\e{1}))}}$ 
\vspace{-15pt}
\end{center}  \hspace{1cm} 
&  & \begin{center}$\mathcal{T_1}$
\vspace{-5pt}\end{center}\\  \hline
\end{tabular}
\end{center} 
and
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$\boxed{{\unot(\isatm(\e{2}))}} $  \vspace{-5pt}\hspace{1cm} 
\end{center}&  & \begin{center}$\mathcal{T_2}$ \vspace{-5pt}\end{center}\\  \hline
\end{tabular}.
\end{center} 
and
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$\unot(\misses(\thet{0}, \langle \e{1}, \e{2} \rangle)) $  \vspace{-5pt}\hspace{1cm} 
\end{center}&  & \begin{center}$\mathcal{T_3}$ \vspace{-5pt}\end{center}\\  \hline
\end{tabular},
\end{center} 
in which the satisfying subprograms are output entries.  
applying esolution to these assertions and other rows can add terms or conditional expressions into the output entries of the resulting rows, but we ignore that complication for this discussion.

We assume that we have among our assertions
the \emph{left property} of the occurrence relation, 
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}[t]
    &\boxed{\unot(\isatm(E))} \uimplies \\
    & \lef(E) \occursin E
    \end{aligned}
$
\end{center}
& &  \\  \hline
\end{tabular}.
\end{center}
By two applications of the resolution rule to this assertion and the case assumptions that the input expressions $\e{1}$ and $\e{2}$ are nonatomic, taking $\var{E}$ to be $\e{1}$ and $\e{2}$, respectively,  we obtain 
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
    & \boxed{\lef(\e{1}) \occursin \e{1}}
    \end{aligned}
$
\end{center}
& &  \\  \hline
\end{tabular}
\end{center}
\vspace{5pt}
and 
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
    & \boxed{\lef(\e{2}) \occursin \e{2}}
    \end{aligned}
$
\end{center}
& &  \\  \hline
\end{tabular}.
\end{center}
We have among our valid assertions the property

\vspace{5pt}
\noindent \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}$
\begin{aligned}
    & \boxed{\varsub{D}{1} \occursin \varsub{E}{1}} \uand 
     \boxed{\varsub{D}{2} \occursin \varsub{E}{2}} \uimplies \\
    & \vars(\langle \varsub{D}{1}, \varsub{D}{2} \rangle) \subseteq
      \vars(\langle \varsub{E}{1}, \varsub{E}{2} \rangle)
    \end{aligned}
$
\end{center}& &  \\  \hline
\end{tabular},
%\end{center}
\vspace{10pt}

\noindent 
which follows from the \emph{occurs-subset property} of $\vars$,
\[E_{1}^* \occurseq E_{2}^* \uimplies \vars(E_{1}^*) \subseteq \vars(E_{2}^*),\]
and the \emph{vars-union property} of tuples, that
\[\vars(\langle E_{1}^*, E_{2}^*\rangle) =
\vars(E_{1}^*) \cup \vars(E_{2}^*),\]
and properties of sets. 

Consequently, by two applications of the \emph{resolution rule}, taking $\varsub{D}{1}$ and $\varsub{E}{1}$ to be $\lef(\e{1})$ and $\e{1}$, respectively, and $\varsub{D}{2}$ 
and $\varsub{E}{2}$ to be  $\lef(\e{2})$ and $\e{2}$, respectively, we obtain

\vspace{5pt}
\noindent \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}$
\begin{aligned}
       & \boxed{\vars(\langle \lef(\e{1}), \lef(\e{2}) \rangle)} \subseteq \\
      &\boxed{\vars(\langle \e{1}, \e{2} \rangle)}
    \end{aligned}
$
\end{center}& &  \\  \hline
\end{tabular}.
%\end{center}

 \vspace{10pt}
Similarly, by the resolution rule applied to 
the \emph{left property} of the size function, 
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
    &\boxed{\unot(\isatm(E))} \uimplies \\
    & \size(\lef(E)) < \size(E)
    \end{aligned}
$
\end{center}
& &  \\  \hline
\end{tabular}.
\end{center}
\vspace{5pt}
and the case assumption that $\e{1}$ is nonatomic, we obtain the assertion 
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
    & \boxed{\size(\lef(\e{1})) < \size(\e{1})}
    \end{aligned}
$
\end{center}
& &  \\  \hline
\end{tabular}.
\end{center}

\vspace{10pt}Earlier (in Section \ref{par:wfrelunif}) we developed the \emph{size-first induction hypothesis},
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\begin{aligned}
&\left[\begin{aligned}
 &\left\{\begin{aligned}
 &\range(\Thet{0}')\cup\boxed{\vars(\langle \E{1}', \E{2}' \rangle)} \subseteq \\
  &\range(\thet{0})\cup\boxed{\vars(\langle \e{1}, \e{2} \rangle)} 
  \end{aligned}\right\} \uand  \\
  &\size(\E{1}') < \size(\e{1})
  \end{aligned} \right] 
  \end{aligned} 
\end{aligned} \\
 \uimplies &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}

\noindent By set-theoretic reasoning, using our finding that $ \vars(\langle \lef(\e{1}), \lef(\e{2}) \rangle) \subseteq \\
      \vars(\langle \e{1}, \e{2} \rangle)$
      and taking $\E{1}'$ and $\E{2}'$ to be $\lef(\e{1})$ and $\lef(\e{2})$, respectively, we can reduce this to
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\begin{aligned}
&\left[\begin{aligned}
 &\left\{\begin{aligned}
 &\range(\Thet{0}') \subseteq \\
  &\range(\thet{0})\cup\vars(\langle \e{1}, \e{2} \rangle) 
  \end{aligned}\right\} \uand  \\
  &\boxed{\size(\lef(\e{1})) < \size(\e{1})}
  \end{aligned} \right] 
  \end{aligned} 
\end{aligned} \\
 \uimplies &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \lef(\e{1}), \lef(\e{2}), \\
    &\unify(\Thet{0}', \lef(\e{1}), \lef(\e{2}))) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}

Furthermore, using our finding that $\size(\lef(\e{1})) < \size(\e{1})$, we can further reduce our assertion to
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\begin{aligned}
&\left[\begin{aligned}
 &\left\{\begin{aligned}
 &\range(\Thet{0}') \subseteq \\
  &\range(\thet{0})\cup\vars(\langle \e{1}, \e{2} \rangle) 
  \end{aligned}\right\} 
  \end{aligned} \right] 
  \end{aligned} 
\end{aligned} \\
 \uimplies &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \lef(\e{1}), \lef(\e{2}), \\
    &\unify(\Thet{0}', \lef(\e{1}), \lef(\e{2}))) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}


We can perform the same reasoning using the function $\rig$ rather than $\lef$. We then obtain the symmetric assertion
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\begin{aligned}
&\left[\begin{aligned}
 &\left\{\begin{aligned}
 &\range(\Thet{0}') \subseteq \\
  &\range(\thet{0})\cup\vars(\langle \e{1}, \e{2} \rangle) 
  \end{aligned}\right\} 
  \end{aligned}\right] 
  \end{aligned} 
\end{aligned} \\
 \uimplies &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \rig(\e{1}), \rig(\e{2}), \\
    &\unify(\Thet{0}', \rig(\e{1}), \rig(\e{2}))) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
For the time being, we shall refer to these as the \emph{left} and \emph{right interim inductive assertions}, respectively. 









\paragraph{Treatment of the Left Interim Inductive Assertion.} We  handle the left and right interim inductive assertions differently.  Applying resolution to the left assertion, 
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\begin{aligned}
&\left[\begin{aligned}
 &\boxed{\begin{aligned}
 &\range(\Thet{0}') \subseteq \\
  &\range(\thet{0})\cup\vars(\langle \e{1}, \e{2} \rangle) 
  \end{aligned}} 
  \end{aligned} \right] 
  \end{aligned} 
\end{aligned} \\
 \uimplies &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \lef(\e{1}), \lef(\e{2}), \\
    &\unify(\Thet{0}', \lef(\e{1}), \lef(\e{2}))) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}
\end{center}
and the set theoretic property

\vspace{5pt}
\noindent \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}$
\begin{aligned}
     \boxed{\varsub{S}{1} \subseteq \varsub{S}{1} \cup \varsub{S}{2}}
\end{aligned}
$
\end{center}& &  \\  \hline
\end{tabular},
\vspace{10pt}

\noindent taking $\Thet{0}'$ to be $\thet{0}$ and $\varsub{S}{1}$ and $\varsub{S}{2}$  to be $\range(\thet{0})$ and $\vars(\langle \e{1}, \e{2} \rangle)$, respectively,  we obtain
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 & &\begin{aligned}&\boxed{\idem(\thet{0})} \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\thet{0}, \lef(\e{1}), \lef(\e{2}), \\
    &\unify(\thet{0}, \lef(\e{1}), \lef(\e{2}))) 
\end{aligned}
\end{aligned} \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}

We process this further, by resolution with the \emph{initial assertion} that $\thet{0}$ is idempotent,
\begin{center}
\begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
 \hline 
\begin{center}$\boxed{\idem(\thet{0})}$\end{center} &  & \\
\hline
\end{tabular},
\end{center}
taking $\Thet{0}'$ to be $\thet{0}$, yielding
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
    {\,\mgiu}(&\thet{0}, \lef(\e{1}), \lef(\e{2}), \\
    &\unify(\thet{0}, \lef(\e{1}), \lef(\e{2}))) 
\end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
or, abbreviating  $\unify(\thet{0}, \lef(\e{1}), \lef(\e{2})))$ as  $\thet{l}$,
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
   ${\,\boxed{\mgiu(\thet{0}, \lef(\e{1}), \lef(\e{2}), \thet{l})}}$
   \end{center}  
& &  \\  \hline
\end{tabular}.
\end{center}
We call this the \emph{left induction hypothesis} and \[\thet{l} = \unify(\thet{0}, \lef(\e{1}), \lef(\e{2})))\] the \emph{left recursive call}. 

We established the \emph{idempotence property of the most-general idempotent-unifier relation}, that a substitution that satisfies the most-general idempotent-unifier relation is indeed idempotent:
\begin{center}
  \begin{tabular}{|m{0.58\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
&\begin{aligned}
&\boxed{{\mgiu}(\Thet{0}, \E{1}, \E{2}, \Theta)} \uimplies \\
&\begin{aligned}
\idem(\Theta)
\end{aligned}
\end{aligned}
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}

Applying resolution to the \emph{left induction hypothesis} and this assertion, taking $\Thet{0}$ to be $\thet{0}$, $\E{1}$ and $\E{2}$ to be $\lef(\e{1})$ and $\lef(\e{2}),$ respectively, and $\Theta$ to be $\thet{l}$, we obtain 
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
\idem(\thet{l})
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
That is, the left recursive call is idempotent. 

\paragraph{Treatment of the Right Interim Inductive Assertion.} 
In Section \ref{rprop}, we established the \emph{range bound property} of the most-general idempotent unifier relation, namely
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{\begin{align*} 
 &
 \left[
\begin{aligned} 
 &\mgiu(\Thet{0}, \E{1}, \E{2}, \Theta)  \uand \\
 &\idem(\Thet{0}) \uand \misses(\Thet{0},\langle \E{1}, \E{2}\rangle)
\end{aligned}
\right]
 \uimplies \\
 &\,\boxed{\range(\Theta) \subseteq \range(\Thet{0}) \cup \vars(\E{1}, \E{2})} \end{align*} }  
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
Applying the \emph{resolution rule} to this and the \emph{right interim inductive assertion},
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\begin{aligned}
&\boxed{\begin{aligned}
 &\begin{aligned}
 &\range(\Thet{0}') \subseteq \\
  &\range(\thet{0})\cup\vars(\langle \e{1}, \e{2} \rangle) 
  \end{aligned}
  \end{aligned}} 
  \end{aligned} 
\end{aligned} \\
 \uimplies &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \rig(\e{1}), \rig(\e{2}), \\
    &\unify(\Thet{0}', \rig(\e{1}), \rig(\e{2}))) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
taking $\Theta$ to be $\Thet{0}'$, $\Thet{0}$ to be $\thet{0}$, and $\E{1}$ and $\E{2}$ to be $\e{1}$ and $\e{2}$, respectively, and resolving away the case assumptions $\idem(\thet{0})$ and $\misses(\thet{0}, \langle \e{1}, \e{2} \rangle)$,  we obtain
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}{$\begin{aligned}
&\boxed{\mgiu(\thet{0}, \E{1}, \E{2}, \Thet{0}')}   
 \\
 &\uimplies \left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \rig(\e{1}), \rig(\e{2}), \\
    &\unify(\Thet{0}', \rig(\e{1}), \rig(\e{2}))) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
Applying resolution to this assertion and the \emph{left induction hypothesis},
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
   ${\,\boxed{\mgiu(\thet{0}, \lef(\e{1}), \lef(\e{2}), \thet{l})}}$
   \end{center}  
& &  \\  \hline
\end{tabular},
\end{center}
taking $\Thet{0}'$ to be $\thet{l}$ and $\E{1}$ and $\E{2}$ to be $\lef(\e{1})$ and $\lef(\e{2})$, respectively, yields
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}&\boxed{\idem(\thet{l})} \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\thet{l}, \rig(\e{1}), \rig(\e{2}), \\
    &\unify(\thet{l}, \rig(\e{1}), \rig(\e{2}))) 
\end{aligned}
\end{aligned} \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
Finally, applying resolution to this assertion and our finding that the left recursive call is idempotent,
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
\boxed{\idem(\thet{l})}
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
gives us
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
 &\begin{aligned}
    {\,\mgiu}(&\thet{l}, \rig(\e{1}), \rig(\e{2}), \\
    &\unify(\thet{l}, \rig(\e{1}), \rig(\e{2}))) 
\end{aligned}
\end{aligned} \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
or, abbreviating $\unify(\thet{l}, \rig(\e{1}), \rig(\e{2}))$ as $\thet{r}$,
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
 &\begin{aligned}
    {\,\mgiu}(&\thet{l}, \rig(\e{1}), \rig(\e{2}), \thet{r}) 
\end{aligned}
\end{aligned} \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
We call this the \emph{right induction hypothesis} and 
\[\thet{r}
\begin{aligned}[t]
&= \unify(\thet{l}, \rig(\e{1}), \rig(\e{2})) \\
 &\begin{aligned}[t]
 \,\, = \unify(\unify(\thet{0}, \lef(\e{1}), \lef(\e{2})), \rig(\e{1}), \rig(\e{2}))
\end{aligned}
\end{aligned}
\]
the \emph{nested recursive call}.

The \emph{left recursive call} $\thet{l}$ is the unification of the left components of the input expressions in the context of the input environment $\thet{0}$; the nested recursive call $\thet{r}$  is the unification of the right components of the input expressions in the context of the result of the left recursive call $\thet{l}$. The difference between the treatment of the left and right components of the inputs is reflected in the algorithm we obtain.  If we reverse the roles of left and right in the derivation, we obtain a symmetric version of the same algorithm, in which the nested recursive call is
\[\begin{aligned}
\unify(
\begin{aligned}
   \unify(\thet{0}, 
  \rig(\e{1}),  
 \rig(\e{2})),
   \end{aligned} 
\lef(\e{1}), 
\lef(\e{2}))
 \end{aligned}. \]
Which algorithm \SNARK\ finds first depends on its search settings, and in particular whether $\lef$ or $\rig$ is greater in its symbol ordering.

\paragraph{Expansion and Splitting of the Induction Hypotheses.}
We now expand each of the two induction hypotheses into three separate components, corresponding to the three conjuncts in the definition of the most-general idempotent unifier.  

Our \emph{left induction hypothesis} is
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$\boxed{\begin{aligned}
    {\,\mgiu}(&\thet{0}, \lef(\e{1}), \lef(\e{2}), \thet{l}) 
\end{aligned}}  $  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
where $\thet{l}$ is the abbreviation for the left recursive call, $\unify(\thet{0}, \lef(\e{1}), \lef(\e{2}))$. We can expand this according to the definition of the most-general idempotent-unifier relation $\mgiu$, using the valid assertion
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
 \begin{center} 
${\begin{aligned} 
 &\boxed{\mgiu(\Thet{0}, \E{1}, \E{2}, \Theta)} \uiff \\
 &\quad\begin{aligned}
&\E{1} \apply \Theta = \E{2} \apply \Theta \, \uand 
 \\
 \,\, & \Thet{0} \moregen \Theta \, \uand
\\
  \,\, & {\mgi}(\Thet{0}, \E{1}, \E{2}, \Theta)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
Applying the \emph{equivalence replacement rule}, taking $\E{1}$ and $\E{2}$ to be $\lef(\e{1})$ and  $\lef(\e{2})$, respectively, $\Thet{0}$ to be $\thet{0}$, and $\Theta$ to be $\allowbreak \thet{l},$ we obtain
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
 &\begin{aligned}
&\lef(\e{1}) \apply \thet{l} = 
 \lef(\e{2}) \apply \thet{l} \, \uand 
 \\
 \,\, &\, \thet{0} \moregen  \thet{l} \, \uand
\\
  \,\, &\, {\mgi}(\thet{0}, \E{1}, \E{2}, \ul)
\end{aligned}
\end{aligned}\end{aligned}   $} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
This is decomposed, by \emph{and-splitting}, to three separate assertions:
the \emph{left unify induction hypothesis} (that the left recursive call yields a unifier):
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
 &\begin{aligned}
&\lef(\e{1}) \apply \thet{l} = 
\lef(\e{2}) \apply \thet{l} 
\end{aligned}
\end{aligned}\end{aligned}   $} 
\end{center}& &  \\  \hline
\end{tabular};
\end{center}
 the \emph{left extension induction hypothesis} (that the left recursive call yields an extension of the environment):
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
 &\begin{aligned}
 \,\, &\, \thet{0} \moregen \thet{l} 
\end{aligned}
\end{aligned}\end{aligned}   $} 
\end{center}& &  \\  \hline
\end{tabular};
\end{center}
 and the \emph{left mgi induction hypothesis} (that the left recursive call yields a most-general idempotent substitution with respect to $\lef(\e{1})$ and $\lef(\e{2})$):


\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
 \mgi(\thet{0}, \lef(\e{1}), \lef(\e{2}), \thet{l})
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular}
\end{center}
.
 
We can similarly apply the definition of a most-general idempotent unifier,
\begin{center}
    

  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
 \begin{center} 
${\begin{aligned} 
 &\boxed{\mgiu(\Thet{0}, \E{1}, \E{2}, \Theta)} \uiff \\
 &\quad\begin{aligned}
&\E{1} \apply \Theta = \E{2} \apply \Theta \, \uand 
 \\
 \,\, & \Thet{0} \moregen \Theta \, \uand
\\
  \,\, & {\mgi}(\Thet{0}, \E{1}, \E{2}, \Theta)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
to the \emph{right induction hypothesis}, 
 \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
  \hline
  \begin{center}
{$\mgiu(\thet{l},\rig(\e{1}),\rig(\e{2}), \uu) $}
 \end{center}  
& & \\
\hline
\end{tabular}.
\end{center}
taking $\Thet{0}$ to be $\thet{l},$ $\E{1}$ and $\E{2}$ to be $\rig(\e{1})$ and $\rig(\e{2})$, respectively, and $\Theta$ to be  $\uu$.
Here $\uu$ is our abbreviation for the nested recursive call
\[\begin{aligned}
\unify(
\begin{aligned}
   \unify(\thet{0}, 
  \lef(\e{1}),  
 \lef(\e{2})),
   \end{aligned} 
\rig(\e{1}), 
\rig(\e{2}))
 \end{aligned} \]
 We obtain 
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
&\begin{aligned}
&\begin{aligned}
&\rig(\e{1}) \apply \thet{r} = \rig(\e{2}) \apply \thet{r}  \uand  \\
 \,\, &\, \thet{l} \moregen \thet{r}  \uand
\\
  \,\, &\, {\mgi}(\thet{l}, \rig(\e{1}), \rig(\e{2}), \thet{r})
\end{aligned}
\end{aligned}
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}

As in the left-side case, this is decomposed, by \emph{and-splitting}, into three separate assertions: the \emph{right unify induction hypothesis} (that the right recursive call yields a unifier):
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
&\begin{aligned}
&\begin{aligned}
&\rig(\e{1}) \apply \thet{r} = 
 \rig(\e{2}) \apply \thet{r} 
\end{aligned}
\end{aligned}
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular};
\end{center}
 the \emph{right extension induction hypothesis} (that the right recursive call yields an extension of the environment):
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
&\begin{aligned}
&\begin{aligned}
 \,\, & \thet{l} \moregen \thet{r} 
\end{aligned}
\end{aligned}
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular};
\end{center}
and the \emph{right mgi induction hypothesis} (that the right recursive call yields a most-general idempotent substitution):

\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
&\mgi(\thet{l}, \rig(\e{1}), \rig(\e{2}), \thet{r})
\end{aligned}
 $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
.

The next section shows how the new induction hypotheses allow the introduction of nested recursive calls into the output column.
\paragraph{Development of the Nested Recursive Calls.}

In Section \ref{sec:spec-first} we developed the \emph{expanded initial goal}

\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
  & 
  \begin{center}\vspace{-.5cm} 
${\begin{aligned} 
&\begin{aligned}
&\boxed{\e{1} \apply \Theta = \e{2} \apply \Theta} \, \uand 
 \\
 \,\, & \thet{0} \moregen \Theta \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \Theta)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\Theta$ \end{center} \\
\hline
\end{tabularx}.
\end{center}




A substitution unifies two nonatomic expressions if it unifies its left and right components; this is expressed by the valid assertion

 \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
 &\begin{aligned}
&\left[\begin{aligned}&\unot(\isatm(\E{1}))) \uand \\ 
&\unot(\isatm(\E{2})))\end{aligned}\right] 
\end{aligned} \uimplies \\
&\left[\begin{aligned}
&{\left[\begin{aligned} 
      &\lef(\E{1}) \apply \Theta = \lef(\E{2}) \apply \Theta \uand \,\,\\
      & \rig(\E{1}) \apply \Theta = \rig(\E{2}) \apply \Theta 
     \end{aligned}\right]} \\
    & \uimplies \boxed{\E{1} \apply \Theta = \E{2} \apply \Theta} 
     \end{aligned}\right] 
     \end{aligned}
     $
\end{center}
& &  \\  \hline
\end{tabular},
\end{center}
Applying resolution to this assertion and the \emph{expanded initial goal},
taking $\E{1}$ and $\E{2}$ to be $\e{1}$ and $\e{2}$, respectively, renaming $\Theta$ to be $\Thet{r}$ for pedagogical reasons, and then applying resolution to the result and the two \emph{nonatomic case assumptions}, we obtain,

\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.60\textwidth}||m{0.10\textwidth}|}
 \hline 
  & 
  \begin{center}
{$\begin{aligned}
 &  \lef(\e{1}) \apply \Thet{r} = \lef(\e{2}) \apply \Thet{r} \uand \\
 &\boxed{\rig(\e{1}) \apply \Thet{r} = \rig(\e{2}) \apply \Thet{r}} \, \uand \\
  & \,\thet{0} \moregen \Thet{r} \, \uand \\
  & \,{\mgi}(\thet{0}, \e{1}, \e{2}, \Thet{r})
\end{aligned}$}
\end{center}
& 
\begin{center}$\Thet{r}$ \end{center}\\
\hline
\end{tabular}.
\end{center}

We now apply the resolution rule to this goal and the \emph{right unify induction hypothesis},
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
  \boxed{\begin{aligned}
    \rig(\e{1}) \apply \thet{r} = 
      \rig(\e{2}) \apply \thet{r} 
   \end{aligned}}
\end{aligned} 
$  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
taking  $\Thet{r}$ to be $\thet{r},$ to obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.60\textwidth}||m{0.10\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
 &\begin{aligned}    
 &\boxed{
\begin{aligned}
    &\lef(\e{1}) \apply \thet{r} = 
      \lef(\e{2}) \apply \thet{r} \hspace{-10pt}\end{aligned}}
\end{aligned} \hspace{-7pt} \uand  \\
& \,\thet{0} \moregen \thet{r} \, \uand \\ & 
  \,  \,{\mgi}(\thet{0}, \e{1}, \e{2}, \thet{r})
\end{aligned}$}
\end{center}
& 

\begin{center}
$
\hspace{-10pt}
\begin{aligned}
\thet{r}
\end{aligned}
$
\end{center}
\\[10pt]
\hline
\end{tabular}.
\end{center}
 This is the stage at which the nested recursive call $\thet{r}$, our abbreviation for 
\[\begin{aligned}
\unify(
\begin{aligned}
   \unify(\thet{0}, 
  \lef(\e{1}),  
 \lef(\e{2})),
   \end{aligned} 
\rig(\e{1}), 
\rig(\e{2}))
 \end{aligned}, \]
 is introduced into the output entry.

In the boxed conjunct, we need to show that $\thet{r}$ unifies $\lef(\e{1})$ and $\lef(\e{2})$; it suffices to show that $\thet{l}$ unifies $\lef(\e{1})$ and $\lef(\e{2})$, because $\thet{r}$ is an extension of $\thet{l}$. We here spell out this argument in more detail.

We have established that any extension of a unifier is also a unifier;  that is, we have the valid assertion
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$\begin{aligned}
    &\Thet{1} \moregen \Thet{2} \uimplies \\
    &\begin{aligned}
         & \quad \E{1} \apply \Thet{1} = \E{2} \apply \Thet{1} \uimplies \\
         & \boxed{\quad \E{1} \apply \Thet{2} = \E{2} \apply \Thet{2}}
    \end{aligned}
\end{aligned}$
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
Applying the resolution rule to these rows, taking $\E{1}$ and $\E{2}$ to be
$\lef(\e{1})$ and $\lef(\e{2})$, respectively, and $\Thet{2}$ to be $\thet{r},$ and renaming $\Thet{1}$ to $\Thet{l}$ for pedagogical reasons,  we obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.60\textwidth}||m{0.10\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
 &\Thet{l} \moregen \thet{r}  \uand  \\
  &\boxed{\lef(\e{1}) \apply \Thet{l} = 
          \lef(\e{2}) \apply \Thet{l}} \,\, \uand  \\
&\,
   \,\thet{0} \moregen \thet{r} \,  \uand \\
  &\,  \,{\mgi}(\thet{0}, \e{1}, \e{2}, \thet{r})
\end{aligned}$}
\end{center}
& 
\begin{center}
$
\thet{r}
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}
Applying resolution to this row and the \emph{left unify induction hypothesis},
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
 &\boxed{\begin{aligned}
&\lef(\e{1}) \apply \thet{l} = 
\lef(\e{2}) \apply \thet{l} 
\end{aligned}}
\end{aligned}\end{aligned}   $} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
taking $\Thet{l}$ to be $\thet{l}$, we obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.60\textwidth}||m{0.10\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
 & \boxed{\begin{aligned}
    &\thet{l} \moregen  \thet{r} \hspace {-10pt}
    \end{aligned}}\, \uand  \\
&\,   \,  \thet{0} \moregen \thet{r} \uand  \\
  &\,  \,  {\mgi}(\thet{0}, \e{1}, \e{2}, \thet{r})
\end{aligned}$}
\end{center}
& 
\begin{center}

$ \begin{aligned}
   \thet{r}
 \end{aligned}    
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}
The boxed subexpression is just the \emph{right extension induction hypothesis}, 
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
&\begin{aligned}
&\begin{aligned}
 \,\, & \boxed{\thet{l} \moregen \thet{r}} 
\end{aligned}
\end{aligned}
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
By resolution, we obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.60\textwidth}||m{0.10\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
&  \boxed{\thet{0} \moregen \thet{r}} \uand   \\
  &\,\,{\mgi}(\thet{0}, \e{1}, \e{2}, \thet{r})
\end{aligned}$}
\end{center}
& 
\begin{center}

$ \begin{aligned}
   \thet{r}
 \end{aligned}    
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}



We earlier established the transitivity of the \emph{more-general} relation $\moregen$:
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$\begin{aligned}
&\left[\begin{aligned}
    &\Thet{1} \moregen \Thet{2} \, \uand \\
    &\Thet{2} \moregen \Thet{3}
    \end{aligned}\right]
    \uimplies \\
&\boxed{\Thet{1} \moregen \Thet{3}}
   \end{aligned}$  
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
Applying the resolution rule to these rows, taking $\Thet{1}$ to $\thet{0}$ and $\Thet{3}$ to be $\thet{r}$, and renaming $\Thet{2}$ to be $\Thet{l}$, we obtain

\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.60\textwidth}||m{0.10\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
 & \boxed{\begin{aligned}
    &\thet{0} \moregen  \Thet{l}
    \end{aligned}} \uand \\
 &\boxed{\Thet{l} \moregen \thet{r}}  \uand  \\
  & \,{\mgi}(\thet{0}, \e{1}, \e{2}, \thet{r})
\end{aligned}$}
\end{center}
& 
\begin{center}

$ \begin{aligned}
   \thet{r}
 \end{aligned}    
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}
Applying resolution twice in succession, to this goal,  the \emph{left extension induction hypothesis}:
  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
 &\begin{aligned}
 \,\, &\, \boxed{\thet{0} \moregen \thet{l}} 
\end{aligned}
\end{aligned}\end{aligned}   $} 
\end{center}& &  \\  \hline
\end{tabular}
\end{center}
(taking $\Thet{l}$ to be $\thet{l}$) and the \emph{right extension induction hypothesis}:
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
&\begin{aligned}
&\begin{aligned}
 \,\, &\, \boxed{\thet{l} \moregen \thet{r}} 
\end{aligned}
\end{aligned}
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular}
\end{center}
we are left with
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.60\textwidth}||m{0.10\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
  & \,\boxed{\mgi(\thet{0}, \e{1}, \e{2}, \thet{r})}
\end{aligned}$}
\end{center}
& 
\begin{center}

$ \begin{aligned}
   \thet{r}
 \end{aligned}    
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}
In other words, it suffices to show that $\thet{r}$ is most-general idempotent.

Earlier we established the  \emph{transitivity property of mgi},
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
    &\unot(\isatm(\E{1})) \uand \unot(\isatm(\E{2})) \uimplies\\
&\left[    \begin{aligned}
   &\left[\begin{aligned}
  &\mgi (\Thet{0}, \lef(\E{1}), \lef(\E{2}), \Thet{1})
  \, \uand \\
   &\mgi (\Thet{1}, \rig(\E{1}), \rig(\E{2}), \Thet{2}) 
   \end{aligned}\right] \uimplies \\
  &
  \boxed{\begin{aligned}
  \mgi(\Thet{0}, &\lef(\E{1}) {\cons} \rig(\E{1}), \\
     &\,\lef(\E{2}) {\cons} \rig(\E{2}), \Thet{2})
   \end{aligned}}  
   \end{aligned} \right]
     \end{aligned}
     $
\end{center}
& &  \\  \hline
\end{tabular},
\end{center}

 Applying resolution to this assertion and the above goal, taking $\E{1}$ and $\E{2}$  to be  $\e{1}$ and $\e{2}$, respectively, $\Thet{0}$ and 
$\Thet{2}$ to be  $\thet{0}$ and  $\thet{r}$, respectively, renaming $\Thet{1}$ to be $\Thet{l}$, and then applying resolution with the case assumptions that $\e{1}$ and $\e{2}$ are nonatomic, we obtain                                                               \begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.60\textwidth}||m{0.10\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
  &\boxed{\mgi (\thet{0}, \lef(\e{1}), \lef(\e{2}), \Thet{l})}
  \, \uand \\
   &\boxed{\mgi (\Thet{l}, \rig(\e{1}), \rig(\e{2}), \thet{r})}
   \end{aligned}
$}
\end{center}
& 
\begin{center}

$ \begin{aligned}
   \thet{r}
 \end{aligned}    
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}  
Earlier we have derived the \emph{left mgi induction hypothesis}

\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
 \boxed{\mgi(\thet{0}, \lef(\e{1}), \lef(\e{2}), \thet{l})}
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
and the \emph{right mgi induction hypothesis}
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
\boxed{\mgi(\thet{l}, \rig(\e{1}), \rig(\e{2}), \thet{r})}
\end{aligned}
 $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
  By two applications of the resolution rule, to the above goal and the two induction hypotheses in succession, taking $\Thet{l}$ to be $\thet{l}$, we obtain the final goal 
                                                                 \begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.60\textwidth}||m{0.10\textwidth}|}
 \hline 
  & 
 \true  
& 
\begin{center}

$ \begin{aligned}
   \thet{r}
 \end{aligned}    
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}
Here $\thet{r}$ is our abbreviation for the nested recursive call
\[\begin{aligned}
\unify(
\begin{aligned}
   \unify(\thet{0}, 
  \lef(\e{1}),  
 \lef(\e{2})),
   \end{aligned} 
\rig(\e{1}), 
\rig(\e{2}))
 \end{aligned}. \]

 
 Initially, we omitted the output entries corresponding to the cases in which $\e{1}$ or $\e{2}$ is atomic, which make up the other cases of the conditional expression that comprises the entire unification algorithm.  The entire resolution proof, in \SNARK\ syntax, is included in  Section \ref{proof}.
 \nobreak
\subsection{The Final Program.}
\label{program}  


\vspace{-\baselineskip}
\vspace{10pt}

Here is the program extracted from the proof.  We introduce by hand annotations, in braces (\{ \ldots \}), to indicate some conditions that hold when control passes through the corresponding point in the program. This is merely to make the program easier to read; it has no effect on its evaluation.
\pagebreak
\vspace{-1cm}
%\begin{center}
\[
\begin{aligned}
&\unify(\thet{0}, \e{1}, \e{2}) = \\
&{\ucond 
  {\isprop(\thet{0})}
  {\ucond 
  {\e{1} \occursin \e{2}}
  {\fail}
  {\ucond 
    {\e{1} = \e{2}} 
    {\thet{0}} 
    {\ucond 
      {\iscnst(\e{1})} 
      {\ucond 
       {\iscnst(\e{2})} 
       {\fail} 
       {\ucond 
  {\isvar(\e{2})} 
  {\unify(\thet{0}, \e{2}, \e{1})} 
  {\begin{aligned}[t]
        &\{\unot (\isatm(\e{2}) \} \\
        &{\fail}
        \end{aligned}
        } }  
      }
      {\ucond
      {\isvar(\e{1})}
      {\ucond
{\misses(\thet{0}, \e{2})}
{\ucond
  {\misses(\thet{0}, \e{1})}
  {\thet{0} \compose \repl{\e{1}} {\e{2}}}
  {\unify(\thet{0},\, \e{1}\apply \thet{0},\, \e{2}\apply\thet{0} )}
}
{\unify(\thet{0},\, \e{1}\apply\thet{0},\, \e{2}\apply\thet{0} )}
}
      {\begin{aligned}[t]
&{\{\unot (\isatm(\e{1}))\}} \\
&{\ucond
{\iscnst(\e{2})}
{\fail}
{\ucond
{\isvar(\e{2})}
{\unify(\thet{0}, \e{2}, \e{1})}
{\unify(\!\!\!\begin{aligned}[t]
&\unify(\thet{0},\lef(\e{1}),\lef(\e{2}) \\ 
&\rig(\e{1}),\rig(\e{2}))
\end{aligned})
}
}
}
\end{aligned}}
 %     {\fail}
      }}}
    }
    {\fail} }
    \end{aligned}
\]
%\end{center}



\subsection{The SNARK Proof.} 
\label{proof}
We include the proof for completeness, but it is not easy reading; the reader is forgiven for skimming this section.   It is a refutation, so the conjecture is negated and \SNARK\ derives a contradiction.  All the rows are in clausal form, and in \SNARK\ syntax, which is based on Lisp syntax.  Variables are prefixed by a question mark (?) and suffixed with an indication of their sort (e.g. $?s.subst$).  The refutation begins with all the assertions (axioms, definitions, and lemmas) that are used in the proof.  Each row contains an explanation of how it was obtained.  Some goal rows contain answer terms.  We have truncated the conditionals in the answers because these terms are unoptimized and verbose. For historical reasons, the ordering of the arguments for the relation symbols $\mgi$ and $\mgiu$ was altered.  The final program (Section \ref{program}) was subjected to automatic simplification; e.g., redundant tests were eliminated.

No changes were made in \SNARK\ for finding the derivation, but some modifications were made to the answer extraction mechanism, to allow it to delete orphaned output entries. We were able to alter its strategy by providing weights on the symbols in the theory's vocabulary and an ordering between them.  The weights determined the which row is worked on next, and the ordering determined which part of a given row was the focus of attention. The ordering on symbols we employed was the \emph{recursive path ordering} \citep{dersh}. 

 \SNARK\ was able to find many proofs for the theorem, each giving a different unification algorithm. By altering the symbol ordering, we were able to influence the algorithm \SNARK\ discovered.  For example, in the algorithm we presented, we test if the environment is a proper substitution ($\isprop(\thet{0})$) before we perform the occurs check ($\e{1} \occursin \e{2}$). This is because in the symbol ordering we have declared, the properness symbol $\isprop$ is less than the occurrence symbol $\occursin$.  When we reverse this ordering, we get an algorithm in which we perform the occur check before we test if the environment is proper. Some orderings give us longer proof searches, or no proof at all; some orderings give better programs than others.


\begin{verbatim}
(refutation
(row def-of-is-proper
   (or (is-proper ?x.subst) (= ?x.subst fail))
   assertion)
(row def-of-occurs=-
   (or (not (occurs= ?x.expression ?y.expression))
       (= ?x.expression ?y.expression)
       (occurs< ?x.expression ?y.expression))
   assertion)
(row an-atom-non-const-is-a-var
   (or (not (is-atom ?x.expression)) (is-const ?x.expression)
       (is-var ?x.expression))
   assertion)
(row fail-unifies-everything
   (= (apply-subst ?x.expression fail) 
      (apply-subst ?y.expression fail))
   assertion)
(row apply-subst-equality-substitutivity
   (or (= (apply-subst ?x.expression ?y.subst)
          (apply-subst ?z.expression ?y.subst))
       (not (= ?x.expression ?z.expression)))
   assertion)
(row more-genid-compose-subst
   (or (more-genid ?x.subst (compose-subst ?y.subst ?z.subst))
       (not (more-genid ?x.subst ?y.subst)))
   assertion)
(row apply-subst-replace-id
   (or (= (apply-subst ?x.expression
                       (replace ?x.expression ?y.expression))
          ?y.expression)
       (not (is-var ?x.expression)))
   assertion)
(row apply-subst-replace-not-occurs
   (or (= (apply-subst ?x.expression
                       (compose-subst ?y.subst
                        (replace ?z.expression ?u.expression)))
          ?v.expression)
       (not (= ?x.expression ?v.expression)) 
       (not (is-proper ?y.subst))
       (not (misses ?y.subst ?x.expression))
       (not (is-var ?z.expression))
       (occurs= ?z.expression ?x.expression))
   assertion)
(row apply-subst-compose-subst
   (or (= (apply-subst ?x.expression 
                       (compose-subst ?y.subst ?z.subst))
          ?u.expression)
       (not (= (apply-subst ?x.expression ?z.subst) 
            ?u.expression))
       (not (is-proper ?y.subst)) 
            (not (misses ?y.subst ?x.expression)))
   assertion)
(row unifiable-non-atoms-decomposed
   (or (= (apply-subst ?x.expression ?y.subst)
          (apply-subst ?z.expression ?y.subst))
       (is-atom ?x.expression) (is-atom ?z.expression)
       (not (= (apply-subst (left ?x.expression) ?y.subst)
               (apply-subst (left ?z.expression) ?y.subst)))
       (not (= (apply-subst (right ?x.expression) ?y.subst)
               (apply-subst (right ?z.expression) ?y.subst))))
   assertion)
(row fail-is-least-general-idempotent
   (more-genid ?x.subst fail)
   assertion)
(row def-of-mgiu-implied-by-unifiable
   (or (mgiu ?x.subst ?y.subst ?z.expression ?u.expression)
       (not (more-genid ?x.subst ?y.subst))
       (not (= (apply-subst ?z.expression ?y.subst)
               (apply-subst ?u.expression ?y.subst)))
       (not (mgi ?x.subst ?y.subst ?z.expression ?u.expression)))
   assertion)
(row def-of-mgiu-implies-unifiable
   (or (not (mgiu ?x.subst ?y.subst ?z.expression ?u.expression))
       (more-genid ?x.subst ?y.subst))
   assertion)
(row def-of-mgiu-implies-unifiable
   (or (not (mgiu ?x.subst ?y.subst ?z.expression ?u.expression))
       (= (apply-subst ?z.expression ?y.subst)
          (apply-subst ?u.expression ?y.subst)))
   assertion)
(row def-of-mgiu-implies-unifiable
   (or (not (mgiu ?x.subst ?y.subst ?z.expression ?u.expression))
       (mgi ?x.subst ?y.subst ?z.expression ?u.expression))
   assertion)
(row mgiu-is-commutative
   (or (mgiu ?x.subst ?y.subst ?z.expression ?u.expression)
       (not (mgiu ?x.subst ?y.subst ?u.expression ?z.expression)))
   assertion)
(row mgi-reflexive-=
   (or (mgi ?x.subst ?y.subst ?z.expression ?u.expression)
       (not (= ?x.subst ?y.subst)))
   assertion)
(row mgi-if-const-vs-non-atom
   (or (mgi ?x.subst ?y.subst ?z.expression ?u.expression)
       (not (is-const ?z.expression)) (is-atom ?u.expression))
   assertion)
(row mgi-if-non-atom-vs-const
   (or (mgi ?x.subst ?y.subst ?z.expression ?u.expression)
       (is-atom ?z.expression) (not (is-const ?u.expression)))
   assertion)
(row mgi-replace-id
   (or (mgi ?x.subst
        (compose-subst ?x.subst 
                       (replace ?y.expression ?z.expression))
        ?y.expression ?z.expression)
       (not (is-var ?y.expression)))
   assertion)
(row mgi-if-nonequal-constants
   (or (mgi ?x.subst ?y.subst ?z.expression ?u.expression)
       (not (is-const ?z.expression)) 
       (not (is-const ?u.expression))
       (= ?z.expression ?u.expression))
   assertion)
(row mgi-if-occurs
   (or (mgi ?x.subst ?y.subst ?z.expression ?u.expression)
       (not (occurs< ?z.expression ?u.expression)))
   assertion)
(row induction-hypothesis
   (or (not (wf-ordered u-wfr
             (tuple ?x.subst ?y.expression ?z.expression)
             (tuple sub0 e1 e2)))
       (not (more-genid ?x.subst ?x.subst))
       (mgiu ?x.subst (unify ?x.subst ?y.expression ?z.expression)
        ?y.expression ?z.expression))
   assumption)
(row left-wf-implied-by
   (or (wf-ordered u-wfr
        (tuple ?x.subst (left ?y.expression) (left ?z.expression))
        (tuple ?u.subst ?y.expression ?z.expression))
       (is-atom ?y.expression) (is-atom ?z.expression)
       (not (more-genid ?u.subst ?x.subst)))
   assertion)
(row right-wf-implied-by
   (or (wf-ordered u-wfr
        (tuple ?x.subst (right ?y.expression) 
                        (right ?z.expression))
        (tuple ?u.subst ?y.expression ?z.expression))
       (is-atom ?y.expression) (is-atom ?z.expression)
       (not (more-genid ?u.subst ?x.subst)))
   assertion)
(row misses-3-implies-misses-2
   (or (not (misses ?x.subst ?y.expression ?z.expression))
       (misses ?x.subst ?y.expression))
   assertion)
(row misses-3-implies-misses-2
   (or (not (misses ?x.subst ?y.expression ?z.expression))
       (misses ?x.subst ?z.expression))
   assertion)
(row wf-ordered-or-not-misses-3
   (or (wf-ordered u-wfr
        (tuple ?x.subst (apply-subst ?y.expression ?x.subst)
         (apply-subst ?z.expression ?x.subst))
        (tuple ?x.subst ?y.expression ?z.expression))
       (not (is-var ?y.expression))
       (misses ?x.subst ?y.expression ?z.expression))
   assertion)
(row const-is-var-reverse
   (or (wf-ordered u-wfr 
                   (tuple ?x.subst ?y.expression ?z.expression)
        (tuple ?x.subst ?z.expression ?y.expression))
       (not (is-const ?z.expression)) 
       (not (is-var ?y.expression)))
   assertion)
(row not-is-atom-is-var-reverse
   (or (wf-ordered u-wfr 
                   (tuple ?x.subst ?y.expression ?z.expression)
        (tuple ?x.subst ?z.expression ?y.expression))
       (is-atom ?z.expression) (not (is-var ?y.expression)))
   assertion)
(row unifies-if-unifies-if-mgiu
   (or (not (mgiu ?x.subst ?y.subst ?z.expression ?u.expression))
       (= (apply-subst ?v.expression ?y.subst)
          (apply-subst ?w.expression ?y.subst))
       (not (= (apply-subst ?v.expression ?x.subst)
               (apply-subst ?w.expression ?x.subst))))
   assertion)
(row more-genid-transitive-if-mgiu
   (or (not (mgiu ?x.subst ?y.subst ?z.expression ?u.expression))
       (more-genid ?v.subst ?y.subst)
       (not (more-genid ?v.subst ?x.subst)))
   assertion)
(row mgiu-idempotent
   (or (not (mgiu ?x.subst ?y.subst ?z.expression ?u.expression))
       (more-genid ?y.subst ?y.subst))
   assertion)
(row mgiu-instance-implies-mgiu
   (or (not (mgiu ?x.subst ?y.subst
             (apply-subst ?z.expression ?x.subst) ?u.expression))
       (mgiu ?x.subst ?y.subst ?z.expression ?u.expression))
   assertion)
(row mgiu-instance2-implies-mgiu
   (or (not (mgiu ?x.subst ?y.subst ?z.expression
             (apply-subst ?u.expression ?x.subst)))
       (mgiu ?x.subst ?y.subst ?z.expression ?u.expression))
   assertion)
(row mgi-cons-cons-left-right
   (or (mgi ?x.subst ?y.subst ?z.expression ?u.expression)
       (is-atom ?z.expression) (is-atom ?u.expression)
       (not (mgi ?x.subst ?v.subst (left ?z.expression)
             (left ?u.expression)))
       (not (mgi ?v.subst ?y.subst (right ?z.expression)
             (right ?u.expression))))
   assertion)
(row misses-three-conjecture
   (more-genid sub0 sub0)
   negated_conjecture)
(row misses-three-conjecture
   (not (mgiu sub0 ?x.subst e1 e2))
   negated_conjecture
   answer (ans ?x.subst))
(row 272
   (not (mgiu sub0 ?x.subst e2 e1))
   (resolve misses-three-conjecture mgiu-is-commutative)
   answer (ans ?x.subst))
(row 277
   (or (not (more-genid sub0 ?x.subst))
       (not (= (apply-subst e1 ?x.subst) 
               (apply-subst e2 ?x.subst)))
       (not (mgi sub0 ?x.subst e1 e2)))
   (resolve misses-three-conjecture 
            def-of-mgiu-implied-by-unifiable)
   answer (ans ?x.subst))
(row 278
   (or (is-atom e1) (not (is-var e2))
       (mgiu sub0 (unify sub0 e2 e1) e2 e1))
   (rewrite (resolve induction-hypothesis 
                     not-is-atom-is-var-reverse) 
            misses-three-conjecture))
(row 279
   (or (not (is-const e1)) (not (is-var e2))
       (mgiu sub0 (unify sub0 e2 e1) e2 e1))
   (rewrite (resolve induction-hypothesis 
                     const-is-var-reverse) 
            misses-three-conjecture))
(row 280
   (or (is-atom e1) (is-atom e2) (not (more-genid sub0 ?x.subst))
       (not (more-genid ?x.subst ?x.subst))
       (mgiu ?x.subst (unify ?x.subst (left e1) (left e2)) 
       (left e1)(left e2)))
   (resolve induction-hypothesis left-wf-implied-by))
(row 281
   (or (is-atom e1) (is-atom e2) (not (more-genid sub0 ?x.subst))
       (not (more-genid ?x.subst ?x.subst))
       (mgiu ?x.subst (unify ?x.subst (right e1) (right e2)) 
       (right e1)(right e2)))
   (resolve induction-hypothesis right-wf-implied-by))
(row 282
   (or (not (is-var e1)) (misses sub0 e1 e2)
       (mgiu sub0
        (unify sub0 (apply-subst e1 sub0) (apply-subst e2 sub0))
        (apply-subst e1 sub0) (apply-subst e2 sub0)))
   (rewrite (resolve induction-hypothesis 
                     wf-ordered-or-not-misses-3) 
            misses-three-conjecture))
(row 283
   (or (not (more-genid sub0 ?x.subst))
       (not (= (apply-subst e1 ?x.subst) 
               (apply-subst e2 ?x.subst)))
       (not (mgi sub0 ?x.subst e2 e1)))
   (resolve 272 def-of-mgiu-implied-by-unifiable)
   answer (ans ?x.subst))
(row 284
   (or (is-atom e1) (not (is-var e2)))
   (resolve 272 278)
   answer (ans (unify sub0 e2 e1)))
(row 291
   (or (not (is-const e1)) (not (is-var e2)))
   (resolve 272 279)
   answer (ans (unify sub0 e2 e1)))
(row 298
   (not (mgi sub0 fail e1 e2))
   (rewrite (resolve 277 fail-unifies-everything) 
            fail-is-least-general-idempotent)
   answer (ans fail))
(row 299
   (or (not (= e1 e2)) (not (more-genid sub0 ?x.subst))
       (not (mgi sub0 ?x.subst e1 e2)))
   (resolve 277 apply-subst-equality-substitutivity)
   answer (ans ?x.subst))
(row 300
   (or (not (= (apply-subst e1 ?x.subst)
               (apply-subst e2 
                            (compose-subst ?y.subst ?x.subst))))
       (not (is-proper ?y.subst)) (not (misses ?y.subst e1))
       (not (more-genid sub0 (compose-subst ?y.subst ?x.subst)))
       (not (mgi sub0 (compose-subst ?y.subst ?x.subst) e1 e2)))
   (resolve 277 apply-subst-compose-subst)
   answer (ans (compose-subst ?y.subst ?x.subst)))
(row 302
   (or (is-atom e1) (is-atom e2)
       (not (= (apply-subst (left e1) ?x.subst)
               (apply-subst (left e2) ?x.subst)))
       (not (= (apply-subst (right e1) ?x.subst)
               (apply-subst (right e2) ?x.subst)))
       (not (more-genid sub0 ?x.subst)) 
       (not (mgi sub0 ?x.subst e1 e2)))
   (resolve 277 unifiable-non-atoms-decomposed)
   answer (ans ?x.subst))
(row 304
   (or (not (= e2
               (apply-subst e1
                            (compose-subst ?x.subst
                             (replace ?y.expression 
                                      ?z.expression)))))
       (not (is-proper ?x.subst)) (not (misses ?x.subst e2))
       (not (is-var ?y.expression)) (occurs= ?y.expression e2)
       (not (more-genid sub0
             (compose-subst ?x.subst
              (replace ?y.expression 
                       ?z.expression))))
       (not (mgi sub0
             (compose-subst ?x.subst
              (replace ?y.expression ?z.expression))
             e1 e2)))
   (resolve 277 apply-subst-replace-not-occurs)
   answer (ans (compose-subst ?x.subst
                (replace ?y.expression ?z.expression))))
(row 305
   (not (occurs< e1 e2))
   (resolve 298 mgi-if-occurs)
   answer (ans fail))
(row 306
   (not (= sub0 fail))
   (resolve 298 mgi-reflexive-=)
   answer (ans fail))
(row 307
   (or (is-atom e1) (not (is-const e2)))
   (resolve 298 mgi-if-non-atom-vs-const)
   answer (ans fail))
(row 308
   (or (not (is-const e1)) (is-atom e2))
   (resolve 298 mgi-if-const-vs-non-atom)
   answer (ans fail))
(row 309
   (or (not (is-const e1)) (not (is-const e2)) (= e1 e2))
   (resolve 298 mgi-if-nonequal-constants)
   answer (ans fail))
(row 311
   (is-proper sub0)
   (resolve 306 def-of-is-proper)
   answer (ans fail))
(row 313
   (or (not (= e1 e2)) (not (more-genid sub0 ?x.subst))
       (not (mgi sub0 ?x.subst e2 e1)))
   (resolve 283 apply-subst-equality-substitutivity)
   answer (ans ?x.subst))
(row 341
   (or (not (is-var e1)) (misses sub0 e1 e2)
       (mgiu sub0
        (unify sub0 (apply-subst e1 sub0) (apply-subst e2 sub0)) 
        e1 (apply-subst e2 sub0)))
   (resolve mgiu-instance-implies-mgiu 282))
(row 352
   (or (not (is-var e1)) (misses sub0 e1 e2)
       (mgiu sub0
        (unify sub0 (apply-subst e1 sub0) (apply-subst e2 sub0)) 
                    e1 e2))
   (resolve mgiu-instance2-implies-mgiu 341))
(row 357
   (or (not (is-var e1)) (misses sub0 e1 e2))
   (resolve misses-three-conjecture 352)
   answer (ans (unify sub0 (apply-subst e1 sub0) 
                           (apply-subst e2 sub0))))
(row 403
   (or (is-atom e1) (is-atom e2)
       (mgiu sub0 (unify sub0 (left e1) (left e2)) 
                  (left e1) (left e2)))
   (rewrite (factor 280) misses-three-conjecture))
(row 409
   (or (is-atom e1) (is-atom e2)
       (more-genid sub0 (unify sub0 (left e1) (left e2))))
   (resolve def-of-mgiu-implies-unifiable 403))
(row 411
   (or (is-atom e1) (is-atom e2)
       (mgi sub0 (unify sub0 (left e1) (left e2)) 
                 (left e1) (left e2)))
   (resolve def-of-mgiu-implies-unifiable 403))
(row 412
   (or (is-atom e1) (is-atom e2)
       (more-genid (unify sub0 (left e1) (left e2))
        (unify sub0 (left e1) (left e2))))
   (resolve mgiu-idempotent 403))
(row 413
   (or (is-atom e1) (is-atom e2)
       (= (apply-subst (left e1) 
                       (unify sub0 (left e1) (left e2)))
          (apply-subst (left e2) 
                       (unify sub0 (left e1) (left e2)))))
   (resolve def-of-mgiu-implies-unifiable 403))
(row 417
   (or (is-atom e1) (is-atom e2) (not (more-genid sub0 ?x.subst))
       (not (more-genid ?x.subst ?x.subst))
       (more-genid ?y.subst 
                   (unify ?x.subst (right e1) (right e2)))
       (not (more-genid ?y.subst ?x.subst)))
   (resolve more-genid-transitive-if-mgiu 281))
(row 418
   (or (is-atom e1) (is-atom e2) (not (more-genid sub0 ?x.subst))
       (not (more-genid ?x.subst ?x.subst))
       (mgi ?x.subst (unify ?x.subst (right e1) (right e2)) 
            (right e1)
        (right e2)))
   (resolve def-of-mgiu-implies-unifiable 281))
(row 420
   (or (is-atom e1) (is-atom e2) (not (more-genid sub0 ?x.subst))
       (not (more-genid ?x.subst ?x.subst))
       (= (apply-subst (right e1)
                       (unify ?x.subst (right e1) (right e2)))
          (apply-subst (right e2)
                       (unify ?x.subst (right e1) (right e2)))))
   (resolve def-of-mgiu-implies-unifiable 281))
(row 421
   (or (is-atom e1) (is-atom e2) (not (more-genid sub0 ?x.subst))
       (not (more-genid ?x.subst ?x.subst))
       (= (apply-subst ?y.expression
                       (unify ?x.subst (right e1) (right e2)))
          (apply-subst ?z.expression
                       (unify ?x.subst (right e1) (right e2))))
       (not (= (apply-subst ?y.expression ?x.subst)
               (apply-subst ?z.expression ?x.subst))))
   (resolve unifies-if-unifies-if-mgiu 281))
(row 441
   (or (is-atom e1) (is-atom e2)
       (not (more-genid sub0 (unify sub0 (left e1) (left e2))))
       (mgi (unify sub0 (left e1) (left e2))
        (unify (unify sub0 (left e1) (left e2))
               (right e1) (right e2))
        (right e1) (right e2)))
   (resolve 418 412))
(row 470
   (or (is-atom e1) (is-atom e2) (not (more-genid sub0 ?x.subst))
       (not (more-genid ?x.subst ?x.subst))
       (not (= (apply-subst (left e1)
                            (unify ?x.subst (right e1) 
                                            (right e2)))
               (apply-subst (left e2)
                            (unify ?x.subst (right e1) 
                                            (right e2)))))
       (not (more-genid sub0 (unify ?x.subst (right e1) 
                                             (right e2))))
       (not (mgi sub0 (unify ?x.subst (right e1) (right e2)) 
                       e1 e2)))
   (resolve 302 420)
   answer (ans (unify ?x.subst (right e1) (right e2))))
(row 529
   (or (is-atom e1) (is-atom e2)
       (mgi (unify sub0 (left e1) (left e2))
        (unify (unify sub0 (left e1) (left e2)) 
               (right e1) (right e2))
        (right e1) (right e2)))
   (resolve 441 409))
(row 889
   (or (is-atom e1) (is-atom e2) (not (more-genid sub0 ?x.subst))
       (not (more-genid ?x.subst ?x.subst))
       (not (= (apply-subst (left e1) ?x.subst)
               (apply-subst (left e2) ?x.subst)))
       (not (more-genid sub0 
                        (unify ?x.subst (right e1) (right e2))))
       (not (mgi sub0 
                 (unify ?x.subst (right e1) (right e2)) e1 e2)))
   (resolve 470 421)
   answer (ans (unify ?x.subst (right e1) (right e2))))
(row 890
   (or (is-atom e1) (is-atom e2)
       (not (more-genid sub0 (unify sub0 (left e1) (left e2))))
       (not (more-genid (unify sub0 (left e1) (left e2))
             (unify sub0 (left e1) (left e2))))
       (not (more-genid sub0
             (unify (unify sub0 (left e1) (left e2)) (right e1)
                    (right e2))))
       (not (mgi sub0
             (unify (unify sub0 (left e1) (left e2)) (right e1)
                    (right e2))
             e1 e2)))
   (resolve 889 413)
   answer (ans (unify (unify sub0 (left e1) (left e2)) (right e1)
                      (right e2))))
(row 1828
   (or (is-atom e1) (is-atom e2)
       (not (more-genid sub0 (unify sub0 (left e1) (left e2))))
       (not (more-genid (unify sub0 (left e1) (left e2))
             (unify sub0 (left e1) (left e2))))
       (not (mgi sub0
             (unify (unify sub0 (left e1) (left e2)) (right e1)
                    (right e2))
             e1 e2)))
   (resolve 890 417)
   answer (ans (unify (unify sub0 (left e1) (left e2)) (right e1)
                      (right e2))))
(row 1829
   (or (is-atom e1) (is-atom e2)
       (not (more-genid sub0 (unify sub0 (left e1) (left e2))))
       (not (mgi sub0
             (unify (unify sub0 (left e1) (left e2)) (right e1)
                    (right e2))
             e1 e2)))
   (resolve 1828 412)
   answer (ans (unify (unify sub0 (left e1) (left e2)) (right e1)
                      (right e2))))
(row 1830
   (or (is-atom e1) (is-atom e2)
       (not (mgi sub0
             (unify (unify sub0 (left e1) (left e2)) (right e1)
                    (right e2))
             e1 e2)))
   (resolve 1829 409)
   answer (ans (unify (unify sub0 (left e1) (left e2)) (right e1)
                      (right e2))))
(row 1832
   (or (is-atom e1) (is-atom e2)
       (not (mgi sub0 ?x.subst (left e1) (left e2)))
       (not (mgi ?x.subst
             (unify (unify sub0 (left e1) (left e2)) (right e1)
                    (right e2))
             (right e1) (right e2))))
   (resolve 1830 mgi-cons-cons-left-right)
   answer (ans (unify (unify sub0 (left e1) (left e2)) (right e1)
                      (right e2))))
(row 1833
   (or (is-atom e1) (is-atom e2)
       (not (mgi sub0 (unify sub0 (left e1) (left e2)) (left e1)
             (left e2))))
   (resolve 1832 529)
   answer (ans (unify (unify sub0 (left e1) (left e2)) (right e1)
                      (right e2))))
(row 1835
   (or (is-atom e1) (is-atom e2))
   (resolve 1833 411)
   answer (ans (unify (unify sub0 (left e1) (left e2)) (right e1)
                      (right e2))))
(row 1837
   (or (is-atom e1) (is-const e2) (is-var e2))
   (resolve an-atom-non-const-is-a-var 1835)
   answer (ans (unify (unify sub0 (left e1) (left e2)) (right e1)
                      (right e2))))
(row 1845
   (or (is-atom e1) (is-const e2))
   (resolve 284 1837)
   answer (answer-if (is-var e2) (ans (unify sub0 e2 e1))...))
(row 1846
   (is-atom e1)
   (resolve 307 1845)
   answer (answer-if (is-const e2)...))
(row 1847
   (or (is-const e1) (is-var e1))
   (resolve an-atom-non-const-is-a-var 1846)
   answer (answer-if (is-const e2)...))
(row 1848
   (or (is-const e1) (misses sub0 e1 e2))
   (resolve 357 1847)
   answer (answer-if (is-var e1)...))
(row 1851
   (or (is-const e1)
       (not (= e2
               (apply-subst e1
                            (compose-subst ?x.subst
                             (replace e1 ?y.expression)))))
       (not (is-proper ?x.subst)) (not (misses ?x.subst e2))
       (occurs= e1 e2)
       (not (more-genid sub0
             (compose-subst ?x.subst (replace e1 ?y.expression))))
       (not (mgi sub0
             (compose-subst ?x.subst (replace e1 ?y.expression)) 
             e1 e2)))
   (resolve 304 1847)
   answer (answer-if (is-var e1)
                     (ans (compose-subst ?x.subst
                           (replace e1 ?y.expression)))...))
(row 1855
   (or (misses sub0 e1 e2) (is-atom e2))
   (resolve 308 1848)
   answer (answer-if (is-const e1) (ans fail)...))
(row 1857
   (or (is-atom e2) (misses sub0 e2))
   (resolve misses-3-implies-misses-2 1855)
   answer (answer-if (is-const e1) (ans fail)...))
(row 1858
   (or (is-atom e2) (misses sub0 e1))
   (resolve misses-3-implies-misses-2 1855)
   answer (answer-if (is-const e1) (ans fail)...))
(row 1904
   (or (is-atom e2) (is-const e1)
       (not (= e2
               (apply-subst e1
                            (compose-subst sub0
                             (replace e1 ?x.expression)))))
       (not (is-proper sub0)) (occurs= e1 e2)
       (not (more-genid sub0
             (compose-subst sub0 (replace e1 ?x.expression))))
       (not (mgi sub0 (compose-subst sub0 
                (replace e1 ?x.expression)) e1 e2)))
   (resolve 1851 1857)
   answer (answer-if (misses sub0 e2)
                     (answer-if (is-var e1)...)...))
(row 1911
   (or (is-atom e2)
       (not (= e2
               (apply-subst e1
                            (compose-subst sub0
                             (replace e1 ?x.expression)))))
       (not (is-proper sub0)) (occurs= e1 e2)
       (not (more-genid sub0
             (compose-subst sub0 (replace e1 ?x.expression))))
       (not (mgi sub0 (compose-subst sub0 
                                     (replace e1 ?x.expression)) 
                      e1 e2)))
   (resolve 308 1904)
   answer (answer-if (is-const e1) (ans fail)...))
(row 1912
   (or (not (= (apply-subst e1 (replace e1 ?x.expression)) e2))
       (not (is-proper sub0)) (not (misses sub0 e1)) (is-atom e2)
       (occurs= e1 e2)
       (not (more-genid sub0
             (compose-subst sub0 (replace e1 ?x.expression))))
       (not (mgi sub0 (compose-subst sub0 
                                     (replace e1 ?x.expression))
                      e1 e2)))
   (resolve 1911 apply-subst-compose-subst)
   answer (answer-if (is-const e1)...))
(row 1938
   (or (is-atom e2)
       (not (= (apply-subst e1 (replace e1 ?x.expression)) e2))
       (not (is-proper sub0)) (occurs= e1 e2)
       (not (more-genid sub0
             (compose-subst sub0 (replace e1 ?x.expression))))
       (not (mgi sub0 (compose-subst sub0 
                                     (replace e1 ?x.expression))
             e1 e2)))
   (resolve 1912 1858)
   answer (answer-if (misses sub0 e1)
                     (answer-if (is-const e1))...))
(row 1939
   (or (not (is-var e1)) (is-atom e2) (not (is-proper sub0))
       (occurs= e1 e2)
       (not (more-genid sub0 (compose-subst sub0 
                                            (replace e1 e2))))
       (not (mgi sub0 (compose-subst sub0 
                                     (replace e1 e2)) e1 e2)))
   (resolve 1938 apply-subst-replace-id)
   answer (answer-if (misses sub0 e1)...))
(row 1941
   (or (is-const e1) (is-atom e2) (not (is-proper sub0))
       (occurs= e1 e2)
       (not (more-genid sub0 (compose-subst sub0 
                                            (replace e1 e2))))
       (not (mgi sub0 (compose-subst sub0 
                                     (replace e1 e2)) e1 e2)))
   (resolve 1939 1847)
   answer (answer-if (is-var e1)...))
(row 1943
   (or (is-atom e2) (not (is-proper sub0)) (occurs= e1 e2)
       (not (more-genid sub0 (compose-subst sub0 
                                            (replace e1 e2))))
       (not (mgi sub0 (compose-subst sub0 
                                     (replace e1 e2)) e1 e2)))
   (resolve 308 1941)
   answer (answer-if (is-const e1) (ans fail)...))
(row 1944
   (or (is-atom e2) (not (is-proper sub0)) (occurs= e1 e2)
       (not (mgi sub0 (compose-subst sub0 (replace e1 e2)) 
                 e1 e2)))
   (rewrite (resolve 1943 more-genid-compose-subst) 
            misses-three-conjecture)
   answer (answer-if (is-const e1)...))
(row 1945
   (or (not (is-var e1)) (is-atom e2) (not (is-proper sub0))
       (occurs= e1 e2))
   (resolve 1944 mgi-replace-id)
   answer (answer-if (is-const e1)...))
(row 1947
   (or (is-const e1) (is-atom e2) (not (is-proper sub0))
       (occurs= e1 e2))
   (resolve 1945 1847)
   answer (answer-if (is-var e1)...))
(row 1949
   (or (is-atom e2) (not (is-proper sub0)) (occurs= e1 e2))
   (resolve 308 1947)
   answer (answer-if (is-const e1) (ans fail)...))
(row 1951
   (or (is-atom e2) (not (is-proper sub0)) 
       (= e1 e2) (occurs< e1 e2))
   (resolve def-of-occurs=- 1949)
   answer (answer-if (is-const e1)))
(row 1960
   (or (is-atom e2) (not (is-proper sub0)) (occurs< e1 e2)
       (not (more-genid sub0 ?x.subst)) 
       (not (mgi sub0 ?x.subst e2 e1)))
   (resolve 313 1951)
   answer (answer-if (= e1 e2) (ans ?x.subst)...))
(row 1979
   (or (is-atom e2) (not (is-proper sub0)) (occurs< e1 e2)
       (not (mgi sub0 sub0 e2 e1)))
   (resolve 1960 misses-three-conjecture)
   answer (answer-if (= e1 e2)...))
(row 1981
   (or (is-atom e2) (not (is-proper sub0)) (occurs< e1 e2))
   (rewrite (resolve 1979 mgi-reflexive-=) :code-for-=)
   answer (answer-if (= e1 e2) (ans sub0)...))
(row 1982
   (or (is-atom e2) (not (is-proper sub0)))
   (resolve 305 1981)
   answer (answer-if (occurs< e1 e2)...))
(row 1983
   (is-atom e2)
   (resolve 1982 311)
   answer (answer-if (is-proper sub0)
                     (answer-if (occurs< e1 e2)...)...))
(row 1984
   (or (is-const e2) (is-var e2))
   (resolve an-atom-non-const-is-a-var 1983)
   answer (answer-if (is-proper sub0)
                     (answer-if (occurs< e1 e2)...)...))
(row 1985
   (or (is-const e2) (not (is-const e1)))
   (resolve 291 1984)
   answer (answer-if (is-var e2) (ans (unify sub0 e2 e1))...))
(row 1992
   (or (not (is-const e1)) (= e1 e2))
   (resolve 309 1985)
   answer (answer-if (is-const e2)...))
(row 1994
   (or (misses sub0 e1 e2) (= e1 e2))
   (resolve 1992 1848)
   answer (answer-if (is-const e1)
                     (answer-if (is-const e2))...))
(row 1995
   (or (misses sub0 e1 e2) (not (more-genid sub0 ?x.subst))
       (not (mgi sub0 ?x.subst e2 e1)))
   (resolve 313 1994)
   answer (answer-if (= e1 e2) (ans ?x.subst)...))
(row 1997
   (or (misses sub0 e1 e2) (not (mgi sub0 sub0 e2 e1)))
   (resolve 1995 misses-three-conjecture)
   answer (answer-if (= e1 e2)...))
(row 1999
   (misses sub0 e1 e2)
   (rewrite (resolve 1997 mgi-reflexive-=) :code-for-=)
   answer (answer-if (= e1 e2) (ans sub0)...))
(row 2000
   (misses sub0 e2)
   (resolve misses-3-implies-misses-2 1999)
   answer (answer-if (= e1 e2)...))
(row 2001
   (misses sub0 e1)
   (resolve misses-3-implies-misses-2 1999)
   answer (answer-if (= e1 e2) (ans sub0)...))
(row 2011
   (or (not (= (apply-subst e1 ?x.subst)
               (apply-subst e2 (compose-subst sub0 ?x.subst))))
       (not (is-proper sub0))
       (not (more-genid sub0 (compose-subst sub0 ?x.subst)))
       (not (mgi sub0 (compose-subst sub0 ?x.subst) e1 e2)))
   (resolve 300 2001)
   answer (answer-if (misses sub0 e1)...))
(row 2089
   (or (not (= e2
               (apply-subst e1 
                            (replace ?x.expression 
                                     ?y.expression))))
       (not (is-proper sub0)) (not (misses sub0 e2))
       (not (is-var ?x.expression)) (occurs= ?x.expression e2)
       (not (more-genid sub0
             (compose-subst sub0
              (replace ?x.expression ?y.expression))))
       (not (mgi sub0
             (compose-subst sub0 
                            (replace ?x.expression 
                                     ?y.expression))
             e1 e2)))
   (resolve 2011 apply-subst-replace-not-occurs)
   answer (answer-if (misses sub0 e1)
                     (ans (compose-subst sub0
                           (replace ?x.expression 
                                    ?y.expression)))...))
(row 2743
   (or (not (= e2
               (apply-subst e1 (replace ?x.expression 
                                        ?y.expression))))
       (not (is-proper sub0)) (not (is-var ?x.expression))
       (occurs= ?x.expression e2)
       (not (more-genid sub0
             (compose-subst sub0
              (replace ?x.expression ?y.expression))))
       (not (mgi sub0
                 (compose-subst sub0 (replace ?x.expression 
                                              ?y.expression))
             e1 e2)))
   (resolve 2089 2000)
   answer (answer-if (misses sub0 e2)...))
(row 2745
   (or (is-const e1)
       (not (= (apply-subst e1 (replace e1 ?x.expression)) e2))
       (not (is-proper sub0)) (occurs= e1 e2)
       (not (more-genid sub0
             (compose-subst sub0 (replace e1 ?x.expression))))
       (not (mgi sub0 
                 (compose-subst sub0 (replace e1 ?x.expression))
             e1 e2)))
   (resolve 2743 1847)
   answer (answer-if (is-var e1)
                     (answer-if (misses sub0 e2)...)...))
(row 2748
   (or (not (= (apply-subst e1 (replace e1 ?x.expression)) e2))
       (not (is-proper sub0)) (occurs= e1 e2)
       (not (more-genid sub0
             (compose-subst sub0 (replace e1 ?x.expression))))
       (not (mgi sub0 
                 (compose-subst sub0 (replace e1 ?x.expression))
             e1 e2))
       (= e1 e2))
   (resolve 1992 2745)
   answer (answer-if (is-const e1)
                     (answer-if (is-const e2)...)...))
(row 2906
   (or (not (is-var e1)) (not (is-proper sub0)) (occurs= e1 e2)
       (not (more-genid sub0 
                        (compose-subst sub0 (replace e1 e2))))
       (not (mgi sub0 (compose-subst sub0 (replace e1 e2)) e1 e2))
       (= e1 e2))
   (resolve 2748 apply-subst-replace-id)
   answer (answer-if (is-const e1)
                     (answer-if (is-const e2)...)...))
(row 2908
   (or (is-const e1) (not (is-proper sub0)) (occurs= e1 e2)
       (not (more-genid sub0 
                        (compose-subst sub0 (replace e1 e2))))
       (not (mgi sub0 (compose-subst sub0 (replace e1 e2)) e1 e2))
       (= e1 e2))
   (resolve 2906 1847)
   answer (answer-if (is-var e1)
                     (answer-if (is-const e1)...)...))
(row 2910
   (or (not (is-proper sub0)) (occurs= e1 e2)
       (not (more-genid sub0 
                        (compose-subst sub0 (replace e1 e2))))
       (not (mgi sub0 (compose-subst sub0 (replace e1 e2)) e1 e2))
       (= e1 e2))
   (resolve 1992 2908)
   answer (answer-if (is-const e1)
                     (answer-if (is-const e2)...)...))
(row 2913
   (or (not (is-proper sub0)) (occurs= e1 e2)
       (not (more-genid sub0 
                        (compose-subst sub0 (replace e1 e2))))
       (not (mgi sub0 (compose-subst sub0 (replace e1 e2)) e1 e2))
       (not (more-genid sub0 ?x.subst)) 
       (not (mgi sub0 ?x.subst e1 e2)))
   (resolve 299 2910)
   answer (answer-if (= e1 e2) (ans ?x.subst)...))
(row 2939
   (or (not (is-proper sub0)) (occurs= e1 e2)
       (not (mgi sub0 (compose-subst sub0 (replace e1 e2)) e1 e2))
       (not (more-genid sub0 ?x.subst)) 
       (not (mgi sub0 ?x.subst e1 e2)))
   (rewrite (resolve 2913 more-genid-compose-subst) 
             misses-three-conjecture)
   answer (answer-if (= e1 e2)...))
(row 2940
   (or (not (is-proper sub0)) (occurs= e1 e2)
       (not (mgi sub0 (compose-subst sub0 (replace e1 e2)) e1 e2))
       (not (mgi sub0 sub0 e1 e2)))
   (resolve 2939 misses-three-conjecture)
   answer (answer-if (= e1 e2) (ans sub0)...))
(row 2944
   (or (not (is-var e1)) (not (is-proper sub0)) (occurs= e1 e2)
       (not (mgi sub0 sub0 e1 e2)))
   (resolve 2940 mgi-replace-id)
   answer (answer-if (= e1 e2)...))
(row 2946
   (or (is-const e1) (not (is-proper sub0)) (occurs= e1 e2)
       (not (mgi sub0 sub0 e1 e2)))
   (resolve 2944 1847)
   answer (answer-if (is-var e1)
                     (answer-if (= e1 e2)...)...))
(row 2949
   (or (not (is-proper sub0)) (occurs= e1 e2)
       (not (mgi sub0 sub0 e1 e2)) (= e1 e2))
   (resolve 1992 2946)
   answer (answer-if (is-const e1)
                     (answer-if (is-const e2))...))
(row 2953
   (or (not (is-proper sub0)) (occurs= e1 e2)
       (not (mgi sub0 sub0 e1 e2)) 
       (not (more-genid sub0 ?x.subst))
       (not (mgi sub0 ?x.subst e2 e1)))
   (resolve 313 2949)
   answer (answer-if (= e1 e2) (ans ?x.subst)...))
(row 2957
   (or (not (is-proper sub0)) (occurs= e1 e2)
       (not (mgi sub0 sub0 e1 e2)) (not (mgi sub0 sub0 e2 e1)))
   (resolve 2953 misses-three-conjecture)
   answer (answer-if (= e1 e2)...))
(row 2959
   (or (not (is-proper sub0)) (occurs= e1 e2)
       (not (mgi sub0 sub0 e2 e1)))
   (rewrite (resolve 2957 mgi-reflexive-=) :code-for-=)
   answer (answer-if (= e1 e2) (ans sub0)...))
(row 2960
   (or (not (is-proper sub0)) (occurs= e1 e2))
   (rewrite (resolve 2959 mgi-reflexive-=) :code-for-=)
   answer (answer-if (= e1 e2)...))
(row 2961
   (or (not (is-proper sub0)) (= e1 e2) (occurs< e1 e2))
   (resolve def-of-occurs=- 2960)
   answer (answer-if (= e1 e2) (ans sub0)...))
(row 2962
   (or (not (is-proper sub0)) (occurs< e1 e2)
       (not (more-genid sub0 ?x.subst)) 
       (not (mgi sub0 ?x.subst e2 e1)))
   (resolve 313 2961)
   answer (answer-if (= e1 e2)...))
(row 2964
   (or (not (is-proper sub0)) (occurs< e1 e2)
       (not (mgi sub0 sub0 e2 e1)))
   (resolve 2962 misses-three-conjecture)
   answer (answer-if (= e1 e2) (ans sub0)...))
(row 2966
   (or (not (is-proper sub0)) (occurs< e1 e2))
   (rewrite (resolve 2964 mgi-reflexive-=) :code-for-=)
   answer (answer-if (= e1 e2)...))
(row 2967
   (not (is-proper sub0))
   (resolve 305 2966)
   answer (answer-if (occurs< e1 e2)...))
(row 2968
   false
   (resolve 2967 311)
   answer (answer-if (is-proper sub0)...))
)
\end{verbatim}

The final output entry (after simplification)  is

\begin{verbatim}
(if (is-proper sub0)
   (if (occurs< e1 e2)
       (ans fail)
     (if (equal e1 e2)
         (ans sub0)
       (if (is-const e1)
           (if (is-const e2)
               (ans fail)
             (if (is-var e2) (ans (unify sub0 e2 e1)) (ans fail)))
         (if (is-var e1)
             (if (misses sub0 e2)
                 (if (misses sub0 e1)
                     (ans (compose-subst sub0 (replace e1 e2)))
                   (ans (unify sub0 (apply-subst e1 sub0)
                               (apply-subst e2 sub0))))
               (ans (unify sub0 (apply-subst e1 sub0)
                           (apply-subst e2 sub0))))
           (if (is-const e2)
               (ans fail)
             (if (is-var e2)
                 (ans (unify sub0 e2 e1))
               (ans (unify (unify sub0 (left e1) (left e2)) (right e1)
                           (right e2)))))))))
 (ans fail))
\end{verbatim}

\section{Discussion} As we have remarked, the proof from which the program is extracted establishes the correctness of the derived program and also provides its rationale, an explanation of its working.  Of course, the correctness of the program depends on the correctness of the specification and the assertions we provide; if these have errors, all bets are off.

There are many different proofs of the same conjecture and many programs can be extracted, all meeting the same specification.  Altering the strategic setting of the theorem prover can influence the program we extract. 

The body of knowledge required for the derivation is surprisingly large and assembling it was labor intensive.  One may ask what the point is of devoting so much effort toward constructing a program that is already known.  Furthermore, the automatic construction of the unification algorithm itself required a unification algorithm.

For one thing, the derivation is useful as a case study;  many of the problems that arise, such as the discovery of a well-founded relation or the generalization of the specification appear in other program synthesis problems.

It has been found that theory-specific unification algorithms (e.g. associative-commutative unification  \citep{sti:acu, liv-siek:acu}) can allow a theorem prover in that theory to find proofs more quickly than if the properties of the relevant relation and function symbols are represented by axioms.  If one could construct the appropriate unification algorithm automatically, it would be possible to discard those axioms mid-proof and replace the unification algorithm of the theorem prover with the newly synthesized one, completing the proof with the new algorithm.   For some theories there is no single most-general unifier;  one must find a set or stream of unifiers. This must be reflected in the specification, and the theorem prover must be prepared to incorporate such an algorithm.

Also, the same knowledge allows the derivation of many algorithms, including other unification algorithms and, presumably, other algorithms with the same subject domain, such as pattern matchers and and anti-unification \citep{plo:au} and disunification  \citep{comon:disu} algorithms.


The derivation was challenging for \SNARK\ to discover; perhaps more modern theorem provers would have an easier time of it.    For instance, in current work, the contemporary theorem prover {\sc Vampire} \citep{hoz} is being extended and applied to program synthesis.

Several decisions we made in the design of the theory of expressions were taken to reduce the search space.  For instance, we specified the more-general idempotent relation so that it would imply idempotence of the unifier ----this meant that we did not have to include idempotence as a separate condition.  We decided to treat the failure indicator ($\fail$) as a special substitution which yielded the black hole constant ($\blk$) when applied to any expression.  This meant that we did not have to treat ununifiable expressions as a special case. All of this led to a shorter specification and a correspondingly shorter proof, which was easier to discover.

We did not attempt to discover the proof from first principles---rather we included lemmas that described the properties of the relations in our specification. (In the same way, a number theorist does not attempt to prove a complex theorem using the basic axioms, such as the Peano postulates.)  In proving the main theorem, we did not use the \emph{equality replacement rule}, which coincides with the paramodulation rule in resolution theorem provers. We found that we got better performance when we dispensed with the rule and instead included equality substitutivity properties for the principal function and relation symbols. At this point, all the lemmas we used have been proved, either by \SNARK\ or by hand. In proving the lemmas, we did use the \emph{equality replacement rule}.

\subsubsection{Notes on Large Language Models.}  Recently, impressive results have been obtained using \emph{large language models}  \citep{wik:llm}, which  apply neural net technology to very large collections of information, including text, programs, and images.  Neural-net-based systems are now superior to humans at chess and go. They do a decent job of translating languages.  Some of these systems will produce code in a variety of subject domains and programming languages, and are being used to assist professional programmers as a time saver.  The systems are particularly effective in recovering known algorithms that have been documented in the literature.  

Unfortunately, large language models have been known to pick up erroneous information from their data sources, and confabulate information when it seems opportune.  They can invent plausible references to articles that do not exist, which appear in journals that also do not exist.  One system was unsure about whether “seven" was greater than “eight"; another insisted that 6 was a prime, even after it was told that 2 times 3 is 6.  In our own experiments, a system was unsure whether, say, December 31, 1999 came before or after January 1, 2000.  While the capabilities of these systems are constantly improving, we are not at the point at which we can trust their results. Nor do they always explain or justify their findings.

This brings up the question of whether we can combine the virtues of large language models and deductive methods.
One obstacle for a theorem proving approach is collecting and encoding as axioms in logic the knowledge we require to construct a program; perhaps some of this effort could be relegated to a large language model, with the resulting theory tested for inconsistency and otherwise validated by a theorem prover. The task of formulating a specification in logic is an obstacle to all of us; perhaps an LLM could perform this, with the resulting formula translated back into natural language for confirmation by the user.  Also,  determining the settings a theorem prover requires to be effective is something of a black art; in \SNARK\ we had to determine experimentally the weights we assigned to symbols and the ordering we applied between them.  A large language model might be effective at this; it doesn't seem very different from playing a game.  

This is an active area of research; for instance, the system LeanDojo \citep{leandojo} has been successful in applying a large language model to guide the search in the interactive theorem prover Lean \citep{lean}.  But anything we say here is already out of date, if we're lucky.

\section{Acknowledgments}

This paper is dedicated to the memory of Zohar Manna and Mark Stickel, without whom this work would not have been possible.  We would like to thank the SRI Artificial Intelligence Center for years of support, and for comments and suggestions.  We have had valuable comments from members of the SRI Computer Science Lab, the SRI Crazy Idea Seminar, and the Kestrel Institute.  The paper was influenced by the Flex Project of the Kestrel Institute.  Karthik Nukala read early versions of this paper and made valuable suggestions. We have also had useful discussions with and encouragement and/or criticism from Franz Baader, Maria-Paola Bonacina, Alessandro Coglio, Steve Eker, Cordell Green, Laura Kovacs, Yanhong Annie Liu, Ray Perrault, Kyle Richardson, Natarajan Shankar, Eric Smith, Asuman Suenbuel, Geoff Sutcliffe, Andrei Voronkov, David S. Warren, and Dave Wolf.  Julie Thomas edited the entire draft.








\begin{thebibliography}{apalike}

\bibitem[Avigad et al., 2015] {lean}\citep{lean} Avigad, J.;  Moura, L.; Kong,  S.; 2015: Theorem proving in Lean. 
\url{{http://leanprover.github.io/tutorial/tutorial.pdf}}


\bibitem[Baader and Snyder(2001)]{baa:sny}
\citep{baa:sny}
Baader, F.,  Snyder, W.: 
2001: Unification theory. In: \emph {Handbook of Automated Reasoning} (1), Robinson, J. A., and Voronkov, A. (eds.), 447–533. Elsevier Science Publishers.

\bibitem[Boyer and Moore(1979)]{boy:moo}
\citep{boy:moo}
Boyer, R. S., Moore, J S.
1979: \emph{A Computational Logic}.
New York: Academic Press.



\bibitem[Burstall and Darlington(1977)]{bur:dar}
\citep{bur:dar}
Burstall, R. M., and Darlington, J.
1977: A transformation system for developing recursive programs. In: \emph{Journal of the ACM (JACM)} 24(1):(44--67).

\bibitem[Comon(1994)]{comon:disu}
\citep{comon:disu}
H. Comon. 1994: Disunification: a survey. In: \emph{Computational Logic: Essays in Honor of Alan Robinson.} Lassez, J.-L.; Plotkin, G., eds. MIT Press.

\bibitem[Dershowitz(1982)]{dersh}
\citep{dersh}
Dershowitz, N.
1982: Orderings for term-rewriting systems. In: \emph{Theoretical Computer Science.} 
 17(3):(279--301).

\bibitem[Fages(1987)]{fag:acu}\citep{fag:acu}
Fages, F. 1987: Associative-commutative unification,
In: \emph{Journal of Symbolic Computation.}
3(3):(257--275).
 
\bibitem[Green(1969)]{ccg}\citep{ccg}
Green, C. C.: 1969: Application of theorem proving to problem solving.  In: \emph{Proceedings of the First International Joint Conference on Artificial Intelligence.} 219--239.
Washington, D.C., U.S.A.


\bibitem[Herbrand(1930)]{her}\citep{her}
Herbrand, J. 1930:  Recherches sur la théorie de la demonstration. Ph.D thesis. Université de Paris.


\bibitem[Hozzová, P., et al.(2024)]{hoz}\citep{hoz}
Hozzová, P., Amrollahi, D., Hajdu, M., Kovács, L., Voronkov, A., Wagner, E. M.  2024: Synthesis of Recursive Programs in Saturation. EasyChair Preprint
No. 12145,  \url{{https://easychair.org/publications/preprint/vvC2}}. 

\bibitem[Lassez et al.(2005)]{las:mah:mar}\citep{las:mah:mar}
Lassez, J. L., Maher, M. J., and Marriott, K. 2005:
Unification revisited. In: \emph{Foundations of Logic and Functional Programming.}  Boscarol, M., Carlucci Aiello, L., Levi, G. (eds) Lecture Notes in Computer Science, vol 306. Springer, Berlin, Heidelberg, Germany. 

\bibitem[Livesey and Siekmann(1976)]{liv-siek:acu}
\citep{liv-siek:acu}
Livesey, M., and Siekmann, J. 1976;
Unification of bags and sets.
Technical Report, Institut für Informatik I, Universität Karlsruhe.
1976.

\bibitem[Lowry et al.(1994)]{low} 
\citep{low}
Lowry, M.; Philpot, A.; Pressburger, T; and Underwood, I. 1994: AMPHION: automatic programming for subroutine libraries. In: \emph{Proceedings KBSE '94. Ninth Knowledge-Based Software Engineering Conference}.

\bibitem[Luger and Stubblefield(1997)]{lug}
\citep{lug}
Luger, G. F., and Stubblefield, W. A. 2004;
\emph{Artificial Intelligence: Structures and Strategies for Complex Problem Solving}.   San Francisco. Benjamin/Cummings.

\bibitem[McCarthy et al.(1962)]{jmc}
\citep{jmc}
McCarthy, J.; Abrahams, P. W.; Edwards, D. J.; Hart, T. P.; and Levin, M. I. 1962: \emph{LISP 1.5 Programmer's Manual}.  Cambridge, Massachusetts, USA.
The MIT Press.

\bibitem[Manna and Waldinger(1981)]{man:wal}
\citep{man:wal}
Manna, Z., Waldinger, R.: 
1981: Deductive synthesis of the unification algorithm. In: \emph{Science of Computer Programming} 1(1--2):(5--48).

\bibitem[Norvig(undated)]{nor} 
\citep{nor}
Norvig, P.: 
Correcting a widespread error in unification algorithms.
\url{https://norvig.com/unify-bug.pdf}

\bibitem[Pólya(1957)]{pol}
\citep{pol}
Pólya, G.;
1957: \emph{How to solve it: A new aspect of mathematical method.}
Princeton, New Jersey, USA.: Princeton University Press

\bibitem[Plotkin(1970)]{plo:au}
\citep{plo:au}
Plotkin, G. D.; 1970: A note on inductive generalization. In: \emph{Machine Intelligence.}  Meltzer, B., and Michie, D. (eds.) 5(153–163).

\bibitem[Robinson(1966)]{rob}
\citep{rob}
Robinson, J. A.; 1966: A machine-oriented logic based on the resolution principle. In:
\emph{Journal of the ACM}.
 12(1)23–41.
 
\bibitem[Slagle(1965)]{sla}
\citep{sla}
Slagle, J. 1965: Experiments with a deductive question-answering program. In: \emph{Communications of the ACM}.

\bibitem[Stickel(1981)]{sti:acu}
\citep{sti:acu}
Stickel, M.: A unification algorithm for associative-commutative functions. In: \emph{Journal of the ACM}. 28(3):423--434.

\bibitem[Stickel et al.(2001)]{sti}
\citep{sti}
Stickel, M., Waldinger, R. J.,  Chaudhri, V.: 
2001: \emph{A guide to \SNARK.} SRI International, Menlo Park, California, USA.

\bibitem[Waldinger and Lee(1969)]{wal:lee}
\citep{wal:lee}
Waldinger, R. J.; Lee, R. C. T.  1969: PROW: a step toward automatic program writing. In: \emph{Proceedings of the 1st International Joint Conference on Artificial Intelligence}. 241–252.

\bibitem[Wikimedia Foundation(2023)]{wik:llm}
\citep{wik:llm}
Wikipedia 2023: Large language models. In: \emph{Wikipedia The Free Encyclopedia}.  \url{https://en.wikipedia.org/wiki/Large\_language\_model}. 

\bibitem[Yang et al.(2023)]{leandojo}
\citep{leandojo}
Yang, K.; Swope, A. M.; Gu, A.;  Chalamala, R.; Song, P.; Yu, S.; Godil, S.; Prenger,  R.; Anandkumar, A. 2023: LeanDojo: theorem proving with retrieval-augmented language models.
arXiv:2306.15626. doi:10.48550/arXiv.2306.15626.


\end{thebibliography}
\end{document}
\begin{comment}
junk
\noindent
 \begin{center}
 \begin{tabular} {|m{0.125\textwidth}|m{0.30\textwidth}||m{0.35\textwidth}|}
 \hline
  $\qquad$ & 
 {\begin{align*}\begin{aligned}
\uand(&\mathcal{S}\langle\mathcal{Q}\rangle\apply \theta,   \unot({\expsub{\mathcal{R}}{1} \apply \theta}),\\
&\expsub{\mathcal{R}}{2} \apply \theta)
\end{aligned}\end{align*}} &  {\begin{align*}\cond {\mathcal{P} \uiff \mathcal{Q}\apply \theta} 
{\expsub{t}{2} \apply \theta} 
{\expsub{t}{1} \apply \theta}\end{align*}} \\
  \hline
\end{tabular}
 \end{center}
 \end{comment}
 
 
\begin{alignat*}{1}
 &\e{1} \apply \theta = \e{2} \apply \theta \, \uand \\
 &(\forall \theta') \left[{
 \begin {aligned} &\e{1} \apply \theta' = \e{2} \apply \theta' \, \uimplies\\
                    &\theta \moregen \theta'
   \end{aligned}}
   \right] \end{alignat*}   

   
Here we have assumed that  $\var{z}$ does not occurs in $\var{y} \apply \thet{0}$, because $\var{z}$ is not in $range(\thet{0}).$ Consequently, by the $\thet{z'}$ \emph{lemma},
\begin{align*}
  & \var{y} \apply \thet{0} \compose \thet{z'} = \var{y} \compose \thet{0} \compose \theta \compose \{\var{z} \mapsto \var{z'}\},
 \end{align*}
or [because  $\theta'$  and $\theta$ are both extensions of $\thet{0}$]
\begin{align*}
  & \var{y} \apply \thet{z'} = \var{y} \compose \theta \compose \{\var{z} \mapsto \var{z'}\}.
 \end{align*}
Therefore, because $\var{z}$ occurs in $\var{y} \compose \theta$, we have 
\[\var{z'} \occurseq \var{y} \apply \thet{z'}. \]


Since $\theta'$ is an extension of $\theta,$ we have $\theta \compose \theta' = \theta'.$
We have assumed that $\var{z}$ is in $range(\theta)$ and that
$\var{z} \occurseq (\var{y} \apply \theta).$  Because $\var{z}$ is not in $dom(\theta')$, we have also 
$\var{z} \occurseq (\var{y} \apply \theta \compose \theta'),$ and hence [because $\theta \compose \theta' = \theta' $] \[\var{z} \occurseq (\var{y} \apply \theta').\]  

But, as we have noted, $\var{y} \apply \theta' = \var{z'}$ and hence [because $\var{z} \neq \var{z'}$] $\unot(\var{z} \occurseq  (\var{y} \apply \theta')).$ That is our desired  contradiction.


Because $z$ is in the range of $\theta$ and $\theta$ is idempotent, $z$ only occurs on the right side of the replacements in $\theta.$ Then, there is a variable $y$ in $\dom(\theta)$ such that $z$ occurs in $y \apply \theta.$  We define a new substitution $\theta'$ that is identical to $\theta$ except that $z$ is replaced by a new variable in $\theta'$, one that does not occur in $\theta$, $\thet{0}$, $\e{1}$ or  $\e{2}$.  For every replacement  $v \mapsto e<z>$ in $\theta$, there is a replacement $v \mapsto \v<z'>$ in $\theta'$.  This substitution $\theta'$ has the property that 
\begin{align*} 
 \mathcal{T_1} \apply \theta = \mathcal{T_2}<z> \uiff 
  \mathcal{T_1} \apply \theta' = \mathcal{T_2}<z'>.
\end{align*}
  \end{comment} 
   \end{comment}
%   there cannot be a  $\expsub{\prec}{\expsub{w}{1}$ case for $k$, \, \expsub{a}{k} \expsub{\succ}{\expsub{w}{1}} \, \expsub{a}{k+1}$. cannot hold for any $k$ 
   
%   such that $k \geq j;$ hence the $\expsub{\prec}{\expsub{w}{2}}$ case for $k$, $\expsub{a}{k} = \expsub{a}{k+1}  \uand
%   \expsub{g}{2}(\expsub{a}{k}) \expsub{\succ}{\expsub{w}{2}} \, \expsub{g}{2}(\expsub{a}{k+1}),$ must hold for each $k$ such that $k \geq j$.    But by the well-foundedness of $\expsub{\succ}{\expsub{w}{2}}$ we cannot have $\expsub{b}{j} \expsub{\succ}{\expsub{w}{2}} \, \expsub{b}{j+1} \expsub{\succ}{\expsub{w}{2}} \, \expsub{b}{j+2}\expsub{\succ}{\expsub{w}{2}} \ldots.$
   
%   \noindent Because of the absence of infinite decreasing sequences under $\expsub{\prec}{\expsub{w}{1}}$, we know that the sequence cannot decease indefinitely and must eventually level off. (Otherwise, we could select from it an infinite decreasing sequence.)  Hence, for some natural number , we have $\expsub{a}{j} =  \expsub{a}{j+1}$ and $\expsub{a}{j+1} =  \expsub{a}{j+2}$ and $\expsub{a}{j+2} =  \expsub{a}{j+3} \ldots$  and thus $\expsub{a}{j} \expsub{\not\succ}{\expsub{w}{1}}  \expsub{a}{j+1}$ and $\expsub{a}{j+1} \expsub{\not\succ}{\expsub{w}{1}} \, \expsub{a}{j+2}$ and 
%   $\expsub{a}{j+2}
%   \expsub{\not\succ}{\expsub{w}{1}}
%   \expsub{a}{j+3} .$ That is, the $\expsub{w}{1}$ case does not hold, so the $\expsub{w}{2}$ case must hold.  But then 
%   $\expsub{a}{j} \, \expsub{\succ}{\expsub{w}{2}} \, \expsub{a}{j+1} \, \expsub {\succ}{\expsub{w}{2}} \, \expsub{a}{j+2} \, \expsub {\succ}{\expsub{w}{2}} \, \expsub{a}{j+3} \ldots,$ which is impossible because $\expsub{\prec}{\expsub{w}{2}}$ is well-founded and admits no infinite decreasing sequences.

\begin{comment}
\[\begin{aligned}
\unify(
\begin{aligned}
   \unify(\thet{0}, 
  \lef(\e{1}),  
 \lef(\e{2})),
   \end{aligned} 
\rig(\e{1}), 
\rig(\e{2}))
 \end{aligned}. \]
 \end{comment}
 We shall refer to $\uu$ as the \emph{right recursive call}.


 \begin{comment}
\begin{center}
$ \begin{aligned}
    \unify( \\ \\ \\ \\ \\
\end{aligned} \hspace{-5pt}
  \begin{aligned}
   &\unify(\thet{0},\\ 
   &\enspace\lef(\e{1}), \\ 
   &\enspace\lef(\e{2})),
 \\
&\rig(\e{1}), \\
&\rig(\e{2})) 
 \end{aligned}.    
$
\end{center}
\end{comment}


\begin{comment}
\[\begin{aligned}
    \,\unify( \\ \\ \\
\end{aligned}\hspace{-2pt}\begin{aligned}
     &\thet{l}, \\
     &\,\rig(\e{1}),  \\
     &\,\rig(\e{2}))
    \end{aligned} \],
 \end{comment}  
   \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
    \begin{aligned}
    \mgiu( \\ \\ \\
\end{aligned}\hspace{-3pt}&\begin {aligned}
     &\unify(\thet{0}, \lef(\e{1}), \lef(\e{2})), \\
     &\rig(\e{1}),  \\
     &\rig(\e{2}),
    \end{aligned} \\
    &\uu
\end{aligned} $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}


% found in wrong place
    {$\begin{aligned}
  &\e{1} \apply \theta = \e{2} \apply \theta
  \uiff \\
  &\left[{\begin{aligned}
  &\lef(\e{1}) \apply \theta = \lef(\e{2}) \apply \theta \uand \\
  & \rig(\e{1}) \apply \theta = \rig(\e{2}) \apply \theta
  \end{aligned}} \right].\\[10pt]
\end{aligned}$}


%%% now $\thet{r}$
\begin{center}
$ \begin{aligned}
    \unify( \\ \\ \\ \\ \\
\end{aligned} \hspace{-5pt}
  \begin{aligned}
   &\unify(\thet{0},\\ 
   &\enspace\lef(\e{1}), \\ 
   &\enspace\lef(\e{2})),
 \\
&\rig(\e{1}), \\
&\rig(\e{2})) 
 \end{aligned}    
$
\end{center}


\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.52\textwidth}||m{0.20\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
&\uand \unot(\isatm(\e{1})) \\ &\uand \unot(\isatm(\e{2})) \\
&\, \uand 
   \,\thet{0} \moregen \left[\begin{aligned}
&\unify(
\begin{aligned}
   &\unify(\Thet{l}',\\ 
   &\enspace\lef(\e{1}), \\ 
   &\enspace\lef(\e{2}))
   \end{aligned} \\
&\quad\rig(\e{1}), \\
&\quad\rig(\e{2})
   )
 \end{aligned} \right] \,  \uand \\
  &\,  \,{\mgi}(\thet{0}, \e{1}, \e{2}, \left[\begin{aligned}
&\unify(
\begin{aligned}
   &\unify(\Thet{0}',\\ 
   &\enspace\lef(\e{1}), \\ 
   &\enspace\lef(\e{2}))
   \end{aligned} \\
&\quad\rig(\e{1}), \\
&\quad\rig(\e{2})
   )
 \end{aligned} \right]
\end{aligned}$}
\end{center}
& 
\begin{center}
$
\begin{aligned}
&\unify(
\begin{aligned}
   &\unify(\Thet{0}',\\ 
   &\enspace\lef(\e{1}), \\ 
   &\enspace\lef(\e{2}))
   \end{aligned} \\
&\quad\rig(\e{1}), \\
&\quad\rig(\e{2})
   )
 \end{aligned}
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}
Here nested recursive calls have now been introduced into the output entry.

%______________________________________________


Earlier we  established the \emph{idempotence property of the most-general idempotent unifier relation}, that a substitution that satisfies the most-general idempotent-unifier relation is indeed idempotent:
\begin{center}
  \begin{tabular}{|m{0.58\textwidth}|m{0.11\textwidth}||m{0.11\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
&\begin{aligned}
&\boxed{{\mgiu}(\Thet{0}, \E{1}, \E{2}, \Theta)} \uimplies \\
&\begin{aligned}
\idem(\Theta)
\end{aligned}
\end{aligned}
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}

Applying resolution to this and the (unexpanded) \emph{left induction hypothesis},
  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\boxed{\begin{aligned}
    {\,\mgiu}(&\thet{0}, \lef(\e{1}), \lef(\e{2}), \\
    &\thet{l}) 
\end{aligned}}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
taking $\Thet{0}$ to be $\thet{0}$, $\E{1}$ and $\E{2}$ to be $\lef(\e{1})$ and $\lef(\e{2}),$ respectively, and $\Theta$ to be $\thet{l}$, we obtain 
\begin{center}
  \begin{tabular}{|m{0.58\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$
\begin{aligned}
\idem(\thet{l})
\end{aligned} $}  \hspace{0cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
That is, the left recursive call is idempotent.

Applying resolution to this and our recently derived goal,
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.54\textwidth}||m{0.20\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
 &\boxed{\idem(\thet{l})} \\
&\, \uand 
   \,\thet{0} \moregen \uu
 \,\\ &\quad  \uand \\
  &\,  \,{\mgi}(\thet{0}, \e{1}, \e{2}, \uu)
\end{aligned}$}
\end{center}
& 
\begin{center}
$
\begin{aligned}
 \hspace{-8pt}  \uu
    \end{aligned}
$
\end{center}
\\
\hline
\end{tabular},
\end{center}
we obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.54\textwidth}||m{0.20\textwidth}|}
 \hline 
  & 
   \begin{center}
$\begin{aligned}
 &\,\,\thet{0} \moregen \uu  \uand \\
 &\,\,{\mgi}(\thet{0}, \e{1}, \e{2}, \uu)
\end{aligned}$
\end{center}
& 
\begin{center}
$
\begin{aligned}
 \hspace{-8pt}  \uu
    \end{aligned}
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}

We have established the transitivity of the \emph{more-general} relation $\moregen$:
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.21\textwidth}||m{0.21\textwidth}|}
\hline
\begin{center}
$\begin{aligned}
&\left[\begin{aligned}
    &\Thet{1} \moregen \Thet{2} \, \uand \\
    &\Thet{2} \moregen \Thet{3}
    \end{aligned}\right]
    \uimplies \\
&\Thet{2} \moregen \Thet{3}
   \end{aligned}$  
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
We also have the \emph{left extension induction hypothesis}, 
  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
 &\begin{aligned}
 \,\, &\, \thet{0} \moregen \thet{l} 
\end{aligned}
\end{aligned}\end{aligned}   $} 
\end{center}& &  \\  \hline
\end{tabular}
\end{center}
and the \emph{right extension induction hypothesis}












  \begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline

\begin{center}
{$\begin{aligned}
 &\begin{aligned}
 &\begin{aligned}
&\lef(\e{1}) \apply \thet{l} =
\lef(\e{2}) \apply \thet{l} \, \uand 
 \\
 \,\, &\, \boxed{\thet{0} \moregen \thet{l}} \, \uand
\\
  \,\, &\, {\mgi}(\thet{0}, \E{1}, \E{2}, \thet{l})
\end{aligned}
\end{aligned}\end{aligned}   $} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
taking ...

We can expand this according to the definition of the most-general idempotent-unifier relation $\mgiu$ using the valid assertion

   
 \begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.21\textwidth}||m{0.21\textwidth}|}
\hline
 \begin{center} 
${\begin{aligned} 
 {\mgiu}(&\Thet{0}, \E{1}, \E{2}, \Theta) \uiff \\
&\begin{aligned}
&\E{1} \apply \Theta = \E{2} \apply \Theta \, \uand 
 \\
 \,\, & \Thet{0} \moregen \Theta \, \uand
\\
  \,\, & {\mgi}(\Thet{0}, \E{1}, \E{2}, \Theta)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
By application of the \emph{equivalence replacement rule}, we obtain the new \emph{expanded size induction hypothesis} the assertion
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\left[\begin{aligned}&\langle \E{1}', \E{2}'\rangle \expsub{\prec}{range-vars}  \vars(\langle \e{1}, \e{2}\rangle  ) \uand \\ 
&size(\E{1}') < \, size(\e{1})\end{aligned}\right] 
\end{aligned}\uimplies \\
 &\left\{\begin{aligned}&\idem(\unify(\thet{0}, \lef(\e{1}), \lef(\e{2}))') \uimplies \\
 &\left[\begin{aligned}
&\boxed{
\begin{aligned}
 &\E{1}' \apply \unify(\unify(\thet{0}, \lef(\e{1}), \lef(\e{2}))', \E{1}', \E{2}') =  \\ 
 &\E{2}' \apply \unify(\unify(\thet{0}, \lef(\e{1}), \lef(\e{2}))', \E{1}', \E{2}')
\end{aligned}
} \, \uand 
 \\
 \,\, & \unify(\thet{0}, \lef(\e{1}), \lef(\e{2}))' \moregen \unify(\unify(\thet{0}, \lef(\e{1}), \lef(\e{2}))', \E{1}', \E{2}')) \, \uand
\\
  \,\, & {\mgi}(\unify(\thet{0}, \lef(\e{1}), \lef(\e{2}))', \E{1}, \E{2}, \unify(\unify(\thet{0}, \lef(\e{1}), \lef(\e{2}))', \E{1}', \E{2}')))
\end{aligned}\right]
\end{aligned}\right\}
\end{aligned}   $}  \hspace{1cm} 
 \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
(In the \SNARK\ implementation, clausification splits this into three separate assertions.)

There are two ways of applying the resolution rule to this assertion and our “further expanded" goal, in which, for pedagogical reasons, we have renamed $\Theta$ to $\expsub{\Theta}{r}$:

\begin{center}
\begin{tabular}{|m{0.18\textwidth}|m{0.48\textwidth}||m{0.17\textwidth}|}
 \hline 
  & 
  \begin{center}
{$\begin{aligned}
&\unot(\isatm(\e{1})) \uand \unot(\isatm(\e{2})) \\
 & \uand \lef(\e{1}) \apply \expsub{\Theta}{r} = \lef(\e{2}) \apply \expsub{\Theta}{r} \uand \\
 &\boxed{\rig(\e{1}) \apply \expsub{\Theta}{r} = \rig(\e{2}) \apply \expsub{\Theta}{r}} \uand \\
  & \,\thet{0} \moregen \expsub{\Theta}{r} \, \uand \\
  & \,{\mgi}(\thet{0}, \e{1}, \e{2}, \expsub{\Theta}{r})
\end{aligned}$}
\end{center}
& 
\begin{center}$\expsub{\Theta}{r}$ \end{center}\\
\hline
\end{tabular}.
\end{center}
Each way leads to a slightly different program; the two programs are symmetric.   
We choose to unify the boxed subformulas, taking $\E{1}'$ and $\E{2}'$ to be
$\rig(\e{1})$ and $\rig(\e{2}),$ respectively, and $\expsub{\Theta}{r}$ to be $\unify(\Thet{l}', \rig(\e{1}), \rig(\e{2}))$. For pedagogical reasons, we rename $\Thet{l}'$ to be $\expsub{\Theta}{l}$. We obtain the new goal

\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.58\textwidth}||m{0.14\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
&\vars(\langle \rig(\e{1}), \rig(\e{2})\rangle) \subseteq \, \vars(\langle \e{1}, \e{2}\rangle )  \\
&\uand size(\rig(\e{1})) < \, size(\e{1}) \\
&\uand \idem(\thet{0}) \\
&\uand \unot(\isatm(\e{1})) \uand \unot(\isatm(\e{2})) \\
 &\begin{aligned}    
\, \uand &\lef(\e{1}) \apply \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})) = \\ 
      &\lef(\e{2}) \apply \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})) 
\end{aligned} \\
&\, \uand 
   \,\thet{0} \moregen \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})) \,  \uand \\
  &\,  \,{\mgi}(\thet{0}, \e{1}, \e{2}, \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})))
\end{aligned}$}
\end{center}
& 

\begin{center}
$
\begin{aligned}
&\unify(\expsub{\Theta}{l},\\ 
 &  \quad \rig(\e{1}), \\
 &   \quad \rig(\e{2}))
\end{aligned}
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}
Here we have introduced the recursive call $\unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2}))$ into the output column.

We omit the steps that account for the removal of the subformulas
\[\begin{aligned}
&\vars(\langle \rig(\e{1}), \rig(\e{2})\rangle) \subseteq \, \vars(\langle \e{1}, \e{2}\rangle )  \\
&\uand size(\rig(\e{1})) < \, size(\e{1}) \\
&\uand \idem(\thet{0})
\end{aligned}
\] 
That $\thet{0}$ is idempotent is our initial assertion. 
Clearly the variables that occur in subexpressions of an expression are a subset of the variables that occur in the expression itself; and proper subexpressions are smaller than the given expression.  

We are left with
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.58\textwidth}||m{0.14\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
&\uand \unot(\isatm(\e{1})) \uand \unot(\isatm(\e{2})) \\
 &\begin{aligned}    
\, \uand 
\boxed{
\begin{aligned}
    &\lef(\e{1}) \apply \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})) = \\ 
      &\lef(\e{2}) \apply \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2}))  \end{aligned}}
\end{aligned} \\
&\, \uand 
   \,\thet{0} \moregen \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})) \,  \uand \\
  &\,  \,{\mgi}(\thet{0}, \e{1}, \e{2}, \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})))
\end{aligned}$}
\end{center}
& 

\begin{center}
$
\begin{aligned}
&\unify(\expsub{\Theta}{l},\\ 
 &  \quad \rig(\e{1}), \\
 &   \quad \rig(\e{2}))
\end{aligned}
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}

We established that any extension of a unifier is also a unifier;  that is, we have the valid assertion

\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.21\textwidth}||m{0.21\textwidth}|}
\hline
\begin{center}
$\begin{aligned}
    &\Thet{1} \moregen \Thet{2} \uimplies \\
    &\begin{aligned}
         & \quad \E{1} \apply \Thet{1} = \E{2} \apply \Thet{1} \uimplies \\
         & \boxed{\quad \E{1} \apply \Thet{2} = \E{2} \apply \Thet{2}}
    \end{aligned}
\end{aligned}$
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}

 
 Applying the resolution rule to these rows, taking $\E{1}$ and $\E{2}$ to be
$\lef(\e{1})$ and $\lef(\e{2})$, respectively, and $\Thet{2}$ to be $\unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})),$ we obtain
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.58\textwidth}||m{0.14\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
&\uand \unot(\isatm(\e{1})) \uand \unot(\isatm(\e{2})) \\
 &  \uand 
 \boxed{
\Thet{1} \moregen \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2}))} \\
  &\uand \lef(\e{1}) \apply \Thet{1} = \lef(\e{2}) \apply \Thet{1}
 \\
&\, \uand 
   \,\thet{0} \moregen \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})) \,  \uand \\
  &\,  \,{\mgi}(\thet{0}, \e{1}, \e{2}, \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})))
\end{aligned}$}
\end{center}
& 
\begin{center}
$
\begin{aligned}
&\unify(\expsub{\Theta}{l},\\ 
 &  \quad \rig(\e{1}), \\
 &   \quad \rig(\e{2}))
\end{aligned}
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}

By resolution rule applied to this goal and, again, the \emph{expanded size induction hypothesis},
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\left[\begin{aligned}&\vars(\langle \E{1}', \E{2}'\rangle) \subseteq \, \vars(\langle \e{1}, \e{2}\rangle ) \uand \\ 
&size(\E{1}') < \, size(\e{1})\end{aligned}\right] 
\end{aligned}\uimplies \\
 &\left\{\begin{aligned}&\idem(\Thet{l}') \uimplies \\
 &\left[\begin{aligned}
&
\begin{aligned}
 &\E{1}' \apply \unify(\Thet{l}', \E{1}', \E{2}') =  \\ 
 &\E{2}' \apply \unify(\Thet{l}', \E{1}', \E{2}')
\end{aligned}
 \, \uand 
 \\
 \,\, & \boxed{\Thet{0} \moregen \unify(\Thet{l}', \E{1}', \E{2}')) }\, \uand
\\
  \,\, & {\mgi}(\Thet{0}, \E{1}, \E{2}, \unify(\Thet{l}', \E{1}', \E{2}')))
\end{aligned}\right]
\end{aligned}\right\}
\end{aligned}   $}  \hspace{1cm} 
 \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
taking $\E{1}'$ and $\E{2}'$ to be $\rig(\e{1})$ and $\rig(\e{2})$, again, and $\Thet{0}$ to be $\Thet{1},$ we obtain 
\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.58\textwidth}||m{0.14\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
&\uand \unot(\isatm(\e{1})) \uand \unot(\isatm(\e{2})) \\
 &  \uand 
\boxed{\Thet{1} \moregen \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2}))} \\
  &\uand \lef(\e{1}) \apply \Thet{1} = \lef(\e{2}) \apply \Thet{1}
 \\
&\, \uand 
   \,\thet{0} \moregen \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})) \,  \uand \\
  &\,  \,{\mgi}(\thet{0}, \e{1}, \e{2}, \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})))
\end{aligned}$}
\end{center}
& 
\begin{center}
$
\begin{aligned}
&\unify(\expsub{\Theta}{l},\\ 
 &  \quad \rig(\e{1}), \\
 &   \quad \rig(\e{2}))
\end{aligned}
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}
We again have omitted the steps leading to the elimination of the subformula
\[\begin{aligned}
&\vars(\langle \rig(\e{1}), \rig(\e{2})\rangle) \subseteq \, \vars(\langle \e{1}, \e{2}\rangle )  \\
&\uand size(\rig(\e{1})) < \, size(\e{1}) \\
&\uand \idem(\thet{0})
\end{aligned}
\] 
We have boxed a subformula in anticipation of the next set, another resolution with the \emph{expanded size induction hypothesis}

\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\left[\begin{aligned}&\vars(\langle \E{1}', \E{2}'\rangle) \subseteq \, \vars(\langle \e{1}, \e{2}\rangle ) \uand \\ 
&size(\E{1}') < \, size(\e{1})\end{aligned}\right] 
\end{aligned}\uimplies \\
 &\left\{\begin{aligned}&\idem(\Thet{l}') \uimplies \\
 &\left[\begin{aligned}
&
\begin{aligned}
 &\E{1}' \apply \unify(\Thet{l}', \E{1}', \E{2}') =  \\ 
 &\E{2}' \apply \unify(\Thet{l}', \E{1}', \E{2}')
\end{aligned}
 \, \uand 
 \\
 \,\, & \boxed{\Thet{0} \moregen \unify(\Thet{l}', \E{1}', \E{2}')) }\, \uand
\\
  \,\, & {\mgi}(\Thet{0}, \E{1}, \E{2}, \unify(\Thet{l}', \E{1}', \E{2}')))
\end{aligned}\right]
\end{aligned}\right\}
\end{aligned}   $}  \hspace{1cm} 
 \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
taking $\E{1}'$ and $\E{2}'$ to be $\rig(\e{1})$ and $\rig(\e{2})$, respectively, and $\Thet{0}$ and $\Thet{l}'$ both to be $\expsub{\Theta}{l}$.
We are left (after elimination of the usual subformula) with

\begin{center}
\begin{tabular}{|m{0.10\textwidth}|m{0.58\textwidth}||m{0.14\textwidth}|}
 \hline 
  & 
   \begin{center}
{$\begin{aligned}
&\uand \unot(\isatm(\e{1})) \uand \unot(\isatm(\e{2})) \\
  &\uand \boxed{\lef(\e{1}) \apply \expsub{\Theta}{l} = \lef(\e{2}) \apply \expsub{\Theta}{l}}
 \\
&\, \uand 
   \,\thet{0} \moregen \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})) \,  \uand \\
  &\,  \,{\mgi}(\thet{0}, \e{1}, \e{2}, \unify(\expsub{\Theta}{l}, \rig(\e{1}), \rig(\e{2})))
\end{aligned}$}
\end{center}
& 
\begin{center}
$
\begin{aligned}
&\unify(\expsub{\Theta}{l},\\ 
 &  \quad \rig(\e{1}), \\
 &   \quad \rig(\e{2}))
\end{aligned}
$
\end{center}
\\
\hline
\end{tabular}.
\end{center}
Another resolution step with the \emph{expanded size induction hypothesis},
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\left[\begin{aligned}&\vars(\langle \E{1}', \E{2}'\rangle) \subseteq \, \vars(\langle \e{1}, \e{2}\rangle ) \uand \\ 
&size(\E{1}') < \, size(\e{1})\end{aligned}\right] 
\end{aligned}\uimplies \\
 &\left\{\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\left[\begin{aligned}
&
\boxed{
\begin{aligned}
 &\E{1}' \apply \unify(\Thet{0}', \E{1}', \E{2}') =  \\ 
 &\E{2}' \apply \unify(\Thet{0}', \E{1}', \E{2}')
\end{aligned}}
 \, \uand 
 \\
 \,\, & \Thet{0} \moregen \unify(\Thet{0}', \E{1}', \E{2}')) \, \uand
\\
  \,\, & {\mgi}(\Thet{0}, \E{1}, \E{2}, \unify(\Thet{0}', \E{1}', \E{2}')))
\end{aligned}\right]
\end{aligned}\right\}
\end{aligned}   $}  \hspace{1cm} 
 \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
taking $\E{1}'$ and $\E{2}'$ to be $\lef(\e{1}$ and $\lef(\e{2}$, respectively, and $\expsub{\Theta}{l}$ to be $\unify(\Thet{0}', \lef(\e{1}), \lef(\e{2}))$, and eliminating the usual subformula,  we obtain
$\expsub{\prec}{lex(\expsub{\var{U}}{1}, \expsub{\var{U}}{2})}$, by application of the resolution rule tp  the above assertion and the \emph{reflexive property of the lexicographic combination of relations,}

  \begin{center}
  \begin{tabular}{|m{0.38\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
    \[
    \left[\begin{aligned}
    & \left[\begin{aligned}
 &\langle \Thet{0}', \E{1}', \E{2}' \rangle 
  \expsub{\prec}{\var{U}}\, \\
 &\langle \Thet{0}, \E{1}, \E{2} \rangle \\
 \end{aligned}\right]  \uiff \\
    &\left[\begin{aligned}
 &\left\{\begin{aligned}
&\range(\Thet{0}')\cup\vars(\langle  \E{1}', \E{2}' \rangle) \subset \\
  &\range(\Thet{0})\cup\vars(\langle \E{1}, \E{2} \rangle) 
  \end{aligned}\right\} \uor \\ 
&\left[\begin{aligned}
 &\left\{\begin{aligned}
 &\range(\Thet{0}')\cup\vars(\langle  \E{1}', \E{2}' \rangle) \subseteq \\
  &\range(\Thet{0})\cup\vars(\langle \E{1}, \E{2} \rangle) 
  \end{aligned}\right\} \uand  \\
  &\size(\E{1}') < \size(\E{1})
  \end{aligned} \right] 
  \end{aligned} \right]
  \end{aligned} \right]
  \]
    \end{center}& &  \\  \hline
\end{tabular},
\end{center}
taking $\var{X}$ to be $\langle \Thet{0}',\E{1}', \E{2}'\rangle $,  $\var{Y}$ to be $\langle \thet{0}, \e{1}, \e{2}\rangle$, and  $\expsub{\prec}{U'}$ to be $\expsub{\prec}{\lex(\expsub{\var{G}}{1}(\expsub{\var{U}}{1}),\, \expsub{\var{G}}{2}(\expsub{\var{U}}{2}))}$, \allowbreak and renaming, we obtain the new assertion

  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\left[\begin{aligned}
  &\expsub{\var{G}}{1}(\langle \Thet{0}', \E{1}', \E{2}'\rangle ) \expsub{\prec}{\expsub{\var{W}}{1}} \, \expsub{\var{G}}{1}( \langle \thet{0}, \e{1}, \e{2}\rangle ) \, \uor \, \\
&\left[\begin{aligned}&\expsub{\var{G}}{1}(\langle \E{1}', \E{2}'\rangle) \expsub{\preccurlyeq}{\expsub{\var{W}}{1}} \, \expsub{\var{G}}{1}(\langle \e{1}, \e{2}\rangle ) \uand \\ 
&\expsub{\var{G}}{2}(\langle \E{1}', \E{2}' \rangle) \expsub{\prec}{\expsub{\var{W}}{2}} \, \expsub{\var{G}}{2}(\langle \e{1}, \e{2}\rangle) \end{aligned}\right] 
\end{aligned}\right]\uimplies \\
 &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $} \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
Clausification incorporates the propositional  equivalence 
\[[(\mathcal{P} \uor \mathcal{Q})  
\uimplies \mathcal{R}] \uiff 
[(\mathcal{P} \uimplies \mathcal{R}) \uand 
(\mathcal{Q} \uimplies \mathcal{R})], \]
and the above assertion is split into the two assertions 


  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
  &\expsub{\var{G}}{1}(\langle \E{1}', \E{2}'\rangle ) \expsub{\prec}{\expsub{\var{W}}{1}} \, \expsub{\var{G}}{1}( \langle \e{1}, \e{2}\rangle )  
\end{aligned}\uimplies \\
 &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $} \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}
\end{center}

and




  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\left[\begin{aligned}&\expsub{\var{G}}{1}(\langle \E{1}', \E{2}'\rangle) \expsub{\preccurlyeq}{\expsub{\var{W}}{1}} \, \expsub{\var{G}}{1}(\langle \e{1}, \e{2}\rangle ) \uand \\ 
&\expsub{\var{G}}{2}(\langle \E{1}', \E{2}' \rangle) \expsub{\prec}{\expsub{\var{W}}{2}} \, \expsub{\var{G}}{2}(\langle \e{1}, \e{2}\rangle) \end{aligned}\right] 
\end{aligned}\uimplies \\
 &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}




%following to be revised
we choose to ignore the environment argument $\Thet{0}'$ and take the well-founded relation $\expsub{\prec}{\scriptstyle{U}}$ to be $\expsub{\prec}{\rest(\scriptstyle{U'})}$ on the other two arguments. We do this by application of the resolution rule  (\emph{AA version}) to the induction hypothesis and the valid assertion


\begin{center}
\begin{tabular}{|m{0.46\textwidth}|m{0.18\textwidth}||m{0.18\textwidth}|}
 \hline 
 \begin{center}
 $\begin{aligned}
 &\langle \varsub{X}{1}, \,  \varsub{X}{2},\, \varsub{X}{3}\rangle \, \expsub{\prec}{\rest(\scriptstyle{W})} 
    \langle \varsub{Y}{1}, \,  \varsub{Y}{2}, \,  \varsub{Y}{3} \rangle  \uiff  \\
&\langle \varsub{X}{2},\, \varsub{X}{3}\rangle \expsub{\prec}{\scriptstyle{W}\,} 
  \langle  \varsub{Y}{2}, \varsub{Y}{3} \rangle.
   \end{aligned}$
   \end{center}
  & 
  &  \\
\hline
\end{tabular}.
\end{center}
using a unifier that takes $\var{U}$ to be $\rest(\var{U'})$, we obtain the new assertion


  \begin{center}
  \begin{tabular}{|m{0.38\textwidth}|m{0.22\textwidth}||m{0.22\textwidth}|}
%\begin{tabularx} {\linewidth}{| Y | c || c |}
\hline
\begin{center}
{$\begin{aligned}
&\langle \E{1}', \E{2}'\rangle \expsub{\prec}{U'}  \langle \e{1}, \e{2}\rangle \uimplies \\
&\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right]\end{aligned}$} \hspace{1cm} 
\end{center}& &  \\  \hline
%\end{tabularx}
\end{tabular}.
\end{center}

As we have remarked, the implementation transforms each assertion to a disjunction of literals (atoms or negations of atoms); we retain some implications (and equivalences) to make the derivation easier to understand. We also rename variables freely for clarity.

In a further \emph{deus ex machina} we chose the well-founded relation $\expsub{\prec}{\var{U'}}$ to be a lexicographic combination 
$\expsub{\prec}{lex(\expsub{\var{U}}{1}, \expsub{\var{U}}{2})}$, by applying the resolution rule yo the above assertion and the \emph{reflexive property of the lexicographic combination of relations,}

  \begin{center}
  \begin{tabular}{|m{0.38\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\var{X} \, \expsub{\prec}{\lex(\expsub{\var{G}}{1}(\expsub{\var{W}}{1}),\, \expsub{\var{G}}{2}(\expsub{\var{W}}{2}))}\, \var{Y}
  \uiff \\
 &\left[\begin{aligned}
  &\expsub{\var{G}}{1}(\var{X}) \expsub{\prec}{\expsub{\var{W}}{1}} \, \expsub{\var{G}}{1}(\var{Y}) \, \uor \, \\
&\left[\begin{aligned}&\expsub{\var{G}}{1}(\var{X}) \expsub{\preccurlyeq}{\expsub{\var{W}}{1}} \, \expsub{\var{G}}{1}(\var{Y}) \uand \\ 
&\expsub{\var{G}}{2}(\var{X}) \expsub{\prec}{\expsub{\var{W}}{2}} \, \expsub{\var{G}}{2}(\var{Y}) \end{aligned}\right]
\end{aligned}\right]\end{aligned}$} \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
taking $\var{X}$ to be $\langle \E{1}', \E{2}'\rangle $,  $\var{Y}$ to be $\langle \e{1}, \e{2}\rangle$, and  $\expsub{\prec}{U'}$ to be $\expsub{\prec}{\lex(\expsub{\var{G}}{1}(\expsub{\var{U}}{1}),\, \expsub{\var{G}}{2}(\expsub{\var{U}}{2}))}$, \allowbreak and renaming, we obtain the new assertion

  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\left[\begin{aligned}
  &\expsub{\var{G}}{1}(\langle \E{1}', \E{2}'\rangle ) \expsub{\prec}{\expsub{\var{W}}{1}} \, \expsub{\var{G}}{1}( \langle \e{1}, \e{2}\rangle ) \, \uor \, \\
&\left[\begin{aligned}&\expsub{\var{G}}{1}(\langle \E{1}', \E{2}'\rangle) \expsub{\preccurlyeq}{\expsub{\var{W}}{1}} \, \expsub{\var{G}}{1}(\langle \e{1}, \e{2}\rangle ) \uand \\ 
&\expsub{\var{G}}{2}(\langle \E{1}', \E{2}' \rangle) \expsub{\prec}{\expsub{\var{W}}{2}} \, \expsub{\var{G}}{2}(\langle \e{1}, \e{2}\rangle) \end{aligned}\right] 
\end{aligned}\right]\uimplies \\
 &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $} \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
Clausification incorporates the propositional  equivalence 
\[[(\mathcal{P} \uor \mathcal{Q})  
\uimplies \mathcal{R}] \uiff 
[(\mathcal{P} \uimplies \mathcal{R}) \uand 
(\mathcal{Q} \uimplies \mathcal{R})], \]
and the above assertion is split into the two assertions 


  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
  &\expsub{\var{G}}{1}(\langle \E{1}', \E{2}'\rangle ) \expsub{\prec}{\expsub{\var{W}}{1}} \, \expsub{\var{G}}{1}( \langle \e{1}, \e{2}\rangle )  
\end{aligned}\uimplies \\
 &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $} \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}
\end{center}

and




  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\left[\begin{aligned}&\expsub{\var{G}}{1}(\langle \E{1}', \E{2}'\rangle) \expsub{\preccurlyeq}{\expsub{\var{W}}{1}} \, \expsub{\var{G}}{1}(\langle \e{1}, \e{2}\rangle ) \uand \\ 
&\expsub{\var{G}}{2}(\langle \E{1}', \E{2}' \rangle) \expsub{\prec}{\expsub{\var{W}}{2}} \, \expsub{\var{G}}{2}(\langle \e{1}, \e{2}\rangle) \end{aligned}\right] 
\end{aligned}\uimplies \\
 &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
For the unification derivation, $\expsub{\var{G}}{1}$ and 
$\expsub{\prec}{\expsub{\var{W}}{1}}$ are taken to be the \emph{variables} function $\vars$ and the proper subset relation 
$\subset$, respectively, and  $\expsub{\var{G}}{2}$ and 
$\expsub{\prec}{\expsub{\var{W}}{2}}$ to be $\first$ and $\expsub{\prec}{\expsub{\var{W}}{2}'}$, so the two assertions above become

  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
  &\vars(\langle \E{1}', \E{2}'\rangle ) \subset \, \vars( \langle \e{1}, \e{2}\rangle )  
\end{aligned}\uimplies \\
 &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $} \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}
\end{center}
called the \emph{range-vars induction hypothesis}, and
 \begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
%\begin{tabularx} {\linewidth}{| Y | c || c |}
\hline
\begin{center}
{$\begin{aligned}
&\boxed{\langle\Thet{0}', \E{1}', \E{2}'\rangle \, \expsub{\prec}{U} \, \langle\thet{0}, \e{1}, \e{2}\rangle} \uimplies \\
&\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right]\end{aligned}$} \hspace{1cm} 
\end{center}& &  \\  \hline
%\end{tabularx}
\end{tabular}
\end{center} we obtain the assertion
 \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
& \left\{\begin{aligned}
&\range(\Thet{0}')\cup\vars(\langle  \E{1}', \E{2}' \rangle) \subset \\
  &\range(\Thet{0})\cup\vars(\langle \E{1}, \E{2} \rangle) 
  \end{aligned}\right\} 
\end{aligned} \\
\uimplies  &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
  &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\left[\begin{aligned}&\vars(\langle \E{1}', \E{2}'\rangle) \subseteq \, \vars(\langle \e{1}, \e{2}\rangle ) \uand \\ 
&\first(\langle \E{1}', \E{2}' \rangle) \expsub{\prec}{\expsub{\var{W}}{2}'} \, \first(\langle \e{1}, \e{2}\rangle) \end{aligned}\right] 
\end{aligned}\uimplies \\
 &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
or, by the \emph{equality replacement rule}, using the valid assertion 
$\first(\langle \E{1}, \E{2} \rangle) = \E{1}$,

  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\left[\begin{aligned}&\vars(\langle \E{1}', \E{2}'\rangle) \subseteq \, \vars(\langle \e{1}, \e{2}\rangle ) \uand \\ 
&\E{1}' \expsub{\prec}{\expsub{\var{W}}{2}'} \, \e{1} \end{aligned}\right] 
\end{aligned}\uimplies \\
 &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
Finally, by the \emph{equivalence replacement rule}, taking 
$\expsub{\prec}{\expsub{\var{W}}{2}'}$ to be the induced relation 
$\expsub{\prec}{size(<)}$, and using the definition of the induced relation
$\var{D} \expsub{\prec}{\size(<)} \var{E} \uiff \size(\var{D})  <  \size(\var{E}),$ we obtain the new assertion


  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\left[\begin{aligned}&\vars(\langle \E{1}', \E{2}'\rangle) \subseteq \, \vars(\langle \e{1}, \e{2}\rangle ) \uand \\ 
&size(\E{1}') < \, size(\e{1})\end{aligned}\right] 
\end{aligned}\uimplies \\
 &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
called the \emph{size-first induction hypothesis}.  It is by using the \emph{variable} and \emph{size-first induction hypotheses} in the proof that recursive calls are introduced into the algorithm.
\begin{comment}

\section{for the slides:}


\paragraph{Introducing a Conditional Output}  omit?

 We  earlier developed the following goal:
\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
  & 
  \begin{center}\vspace{-.5cm} 
${\begin{aligned} 
&\begin{aligned}
&\e{1} \apply \Theta = \e{2} \apply \Theta \, \uand 
 \\
 \,\, & \thet{0} \moregen \Theta \, \uand
\\
  \,\, & {\mgi}(\thet{0}, \e{1}, \e{2}, \Theta)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}$\Theta$ \end{center} \\
\hline
\end{tabularx}
\end{center}





\begin{center}
\begin{tabular}{|m{0.42\textwidth}|m{0.18\textwidth}||m{0.18\textwidth}|}
 \hline 
 \begin{center}
 {\begin{align*}
 \begin{aligned}
 &\,{\mgi}(\Thet{0}, \E{1}, \E{2}, \Theta) \,\, \uimpliedby \,\, \\
 &\iscnst(\E{1}) \uand \unot(\isatm(E{2}))
 \end{aligned}
\end{align*}}
\end{center} 
& & \\
\hline
\end{tabular}
\end{center}
and
\begin{center}
\begin{tabular}{|m{0.42\textwidth}|m{0.18\textwidth}||m{0.18\textwidth}|}
 \hline 
 %\begin{center}
 {\begin{align*}
 \begin{aligned}
 &\,{\mgi}(\Thet{0}, \E{1}, \E{2}, \Theta) \,\, \uimpliedby \,\, \\
 &\unot(\isatm(\E{1})) \uand \iscnst(\E{2})
 \end{aligned}
 \end{align*}}
%\end{center} 
 & & \\
\hline
\end{tabular}
\end{center}


  
  \begin{center}
\begin{tabularx}{.99\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline \vspace{-.5cm}
 \begin{center}
 {\begin{align*}
 \begin{aligned}
 &\,{\mgi}(\Thet{0}, \E{1}, \E{2}, \Theta) \,\, \uimpliedby \,\, \\
 &\unot(\isatm(\E{1})) \uand \iscnst(\E{2})
 \end{aligned}
 \end{align*}}
\end{center} 
& & \\
\hline
\end{tabularx}.
\end{center}
\noindent Applying the \emph{assertion-goal version} of the resolution rule to the first of these assertions and the above goal, we obtain the new goal

  \begin{center}
\begin{tabular}{|m{0.19\textwidth}|m{0.42\textwidth}||m{0.20\textwidth}|}
  \hline 
 % \vspace{-2cm}
 & \begin{center}
{\begin{align*}
 \begin{aligned}
 \iscnst(\e{1}) \uand \unot(\isatm(\e{2}))
 \end{aligned}
 \end{align*}}
\end{center} 
 &  \begin{center}$\fail$ \end{center} \\
\hline
\end{tabular}
\end{center}

\noindent In other word, in a case in which $\e{1}$ is a constant and $\e{2}$ is nonatomic, the failure substitution will satisfy the input-output condition of the specification.




\noindent Applying the \emph{goal-goal version} of the \emph{equality replacement rule} to the above two goals, we can replace all occurrences of $\e{1}$ with $\e{2}$, to obtain the new goal
\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
  & 
  \begin{center}\vspace{-.5cm} 
${\begin{aligned} 
&\begin{aligned}
&\iscnst(\e{1}) \uand \\ &\iscnst(\e{2})\, \uand \\
&\e{2} \apply \Theta = \e{2} \apply \Theta \, \uand \\
 \,\, & \thet{0} \moregen \Theta \, \uand \\
  \,\, & {\mgi}(\thet{0}, \e{2}, \e{2}, \Theta)
\end{aligned}\end{aligned}}$\hspace{1cm} 
\end{center} & 
\vspace{.5cm}
\begin{center}
$\cond{\e{1} = \e{2}}{\Theta}{\fail}$
\end{center}
 \\ \hline
\end{tabularx}.
\end{center}
\noindent Here we have introduced a conditional term into the output entry.



\noindent Applying the \emph{assertion-goal version} of the resolution rule to the \emph{reflexivity property} of equality and the above goal, we obtain the new goal
\begin{center}
\begin{tabularx}{.99\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
  & 
  \begin{center}\vspace{-.5cm} 
${\begin{aligned} 
&\begin{aligned}
&\iscnst(\e{1}) \uand \\ &\iscnst(\e{2})\, \uand \\
 \,\, & \thet{0} \moregen \Theta \, \uand \\
  \,\, & {\mgi}(\thet{0}, \e{2}, \e{2}, \Theta)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}\vspace{-.20cm}$\Theta$ \end{center} \\ \hline
\end{tabularx}.
\end{center}

Earlier we have developed the following assertion from the assumption that the environment substitution is idempotent:
\begin{center}
\begin{tabularx}{1.0\textwidth}{V}
 \hline 
 \begin{center}
 \vspace{-.25cm}
$\begin{aligned} \thet{0} \moregen \thet{0} \end{aligned}$
\end{center}
  & 
  &  \\ \hline
\end{tabularx}.
\end{center}

\noindent By the \emph{assertion-goal version} of the \emph{resolution} rule, using the most-general unifier $\{\Theta \mapsto \thet{0}\}$, we obtain the new goal

\begin{center}
\begin{tabularx}{.99\textwidth} {| >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
    \begin{center}\vspace{-.5cm} 
${\begin{aligned} 
&\begin{aligned}
&\iscnst(\e{1}) \uand \\ &\iscnst(\e{2})\, \uand \\
  \,\, & {\mgi}(\thet{0}, \e{2}, \e{2}, \Theta)
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center} & \begin{center}\vspace{-.20cm}$\Theta$ \end{center} \\ \hline
\end{tabularx}.
\end{center}


\begin{align*}
 {\mgi}(\thet{0}, \e{1}, \e{2}, \theta) \,\, \uimpliedby \,\,
[\thet{0} = \theta].
   \end{align*}
   \noindent In other words, the environment is always most-general idempotent for any expressions.
   
 

   \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & $\uand(\expsub{\mathcal{P}}{1},\expsub{\mathcal{R}}{1})$ & $\expsub{t}{1}$ \\
  \hline
\end{tabular}
\end{center}

  \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & $ \uand(\unot (\expsub{\mathcal{P}}{2}),\expsub{\mathcal{R}}{2})$ & $\expsub{t}{2}$ \\
  \hline
\end{tabular}
\end{center}

 \begin{center}
\begin{tabular} {T}
\hline
    $\qquad$ & $\uand(\expsub{\mathcal{R}}{1} \apply \theta, \ \expsub{\mathcal{R}}{2} \apply \theta)$ &  $\cond {\mathcal{P}} {\expsub{t}{1} \apply \theta} {\expsub{t}{2} \apply \theta}$ \\
  \hline
\end{tabular}
\end{center}


      \begin{center}
\begin{tabular}{T}
 \hline
  $ \var{X} \expsub{\prec}{U}\,a   \, \uimplies \mathscr{Q}[\var{X}, \uf(\var{X})]$ &  &  \\ 
 \hline
\end{tabular}.
\end{center}



% \begin{comment}

      \begin{center}
\begin{tabular}{T}
 \hline
  & $\e{1} \occursin \e{2}$ & $\fail$ \\ 
 \hline
\end{tabular}
\end{center}


        
\begin{center}
\begin{tabular}{|m{0.24\textwidth}|m{0.32\textwidth}||m{0.24\textwidth}|}
 \hline 
  & 
  {\begin{center}
${\begin{aligned} 
&\begin{aligned}
&\unot(\e{1} \occursin \e{2}) \uand \\ 
    \,\,&\isprop(\thet{0}) \uand \\
    &\isvar(\e{1}) \\
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center}} & \begin{align*}\begin{aligned}{\emph{if}\, (\e{1} = \e{2}, \thet{0}, \ldots})\end{aligned}\end{align*} \\ \hline
\end{tabular}
\end{center}

%${\emph{if}\, (\e{1} = \e{2}), \thet{0}, \ldots})$

% \begin{align*}{\emph{if}\,\begin{aligned}&\e{1} \occursin \e{2}), \fail, \\ {\begin{aligned}{\,&emph{if}\, (\e{1} = \e{2}, \thet{0}, \ldots})\end{aligned}}}\end{aligned}\end{align*}

        
\begin{center}
\begin{tabular}{|m{0.20\textwidth}|m{0.30\textwidth}||m{0.24\textwidth}|}
 \hline 
  & 
  {\begin{center}
${\begin{aligned} 
&\begin{aligned}
&\isprop(\thet{0}) \uand \\
    &\isvar(\e{1}) \\
\end{aligned}.\end{aligned}}$\hspace{1cm} 
\end{center}} & 
\begin{center}
{\begin{align*}
    \begin{aligned}
\emph{if} \, (&\e{1} \occursin \e{2}), \fail,                \\
    & \emph{if}\, (\e{1} = \e{2}, \thet{0},\ldots))
    \end{aligned}
\end{align*}}
\end{center}\\ \hline
\end{tabular}
\end{center}


%\begin{center}\vspace{-.20cm}$\Theta$ \end{center}

%   \begin{center}
% \begin{tabular} {T}
% \hline
%     $\qquad$ & $\uand(\expsub{\mathcal{R}}{1} \apply \theta, \ \expsub{\mathcal{R}}{2} \apply \theta)$ &  $\cond{\e{1} \occursin \e{2})} {\quad\fail} {\emph{if}(\,\ldots)}$ \
%   \hline
% \end{tabular}
% \end{center}

% \end{comment}

\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
\hline
  & \vspace{-.3cm}\begin{center}$ {\mgiu}(\thet{0}, \e{2}, \e{1}, \Theta)$  \end{center}  & \vspace{-.3cm}\begin{center}$\Theta$\end{center} \\
\hline
\end{tabularx}.
\end{center}


\begin{center}
\begin{tabular}{|m{0.46\textwidth}|m{0.17\textwidth}||m{0.17\textwidth}|}
 \hline 
    {\begin{center}
${\begin{aligned} 
&\begin{aligned}
&\mgiu(\thet{0},\e{2}, \e{1},\unify(\thet{0}, \e{2}, \e{1})) \uor \\ 
    \,\,&\isatm(\e{1}) \uor \\
    &\unot(\isatm(\e{2})) \uor \\
    &\ldots
\end{aligned}\end{aligned}}$\hspace{1cm} 
\end{center}} & &  \\ \hline
\end{tabular}
\end{center}

\noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}

\begin{center}
\begin{tabular}{|m{0.16\textwidth}|m{0.40\textwidth}||m{0.24\textwidth}|}
 \hline 
  &  {\begin{center}
${\begin{aligned} 
&\begin{aligned}
    \,\,&\unot(\isatm(\e{1})) \uand \\
    &\isatm(\e{2}) \uand \\
    &\ldots
\end{aligned}\end{aligned}}$\hspace{1cm} 
\end{center}}  & \begin{align*}\begin{aligned}\unify(\thet{0}, \e{2}, \e{1})\end{aligned}\end{align*} \\ \hline
\end{tabular}
\end{center}

\begin{center}  
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline
 Assertions & Goals & $\,\unify(\thet{0}, \e{1}, \e{2})\,$ \\
 \hline\hline  
  & $\begin{aligned}[t] &\idem(\thet{0}) \uimplies \\  &\,{\mgiu}(\thet{0}, \e{1}, \e{2} , \Theta) \\ \end{aligned}$  & $\Theta$ \\

\hline
\end{tabularx}
\end{center}

  \begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.21\textwidth}||m{0.21\textwidth}|}
%\begin{tabularx} {\linewidth}{| Y | c || c |}
\hline
\begin{center}
{$\begin{aligned}
&\langle\Thet{0}', \E{1}', \E{2}'\rangle \expsub{\prec}{U}  \langle\thet{0}, \e{1}, \e{2}\rangle \uimplies \\
&\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \E{1}', \E{2}', \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right]\end{aligned}$} \hspace{1cm} 
\end{center}& &  \\  \hline
%\end{tabularx}
\end{tabular}
\end{center}
\begin{comment}
We also have the 
the \emph{right property} of the occurrence relation, 
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
    &\boxed{\unot(\isatm(E))} \uimplies \\
    &\rig(E) \occursin E
    \end{aligned}
$
\end{center}
& &  \\  \hline
\end{tabular}.
\end{center}
By two applications of the \emph{resolution rule} to the two case assumptions and the property, taking $\var{E}$ to be $\e{1}$ and $\e{2},$ respectively, we obtain 
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
\hline
\begin{center}
$
\boxed{\rig(\e{1}) \occursin \e{1}}
$
\end{center}
& &  \\  \hline
\end{tabular}
\end{center} 
and
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}
$
\boxed{\rig(\e{2}) \occursin \e{2}}
$
\end{center}
& &  \\  \hline
\end{tabular}.
\end{center}

We have among our valid assertions the property

\vspace{5pt}
\noindent \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}$
\begin{aligned}
    & \boxed{\varsub{D}{1} \occursin \varsub{E}{1}} \uand 
     \boxed{\varsub{D}{2} \occursin \varsub{E}{2}} \uimplies \\
    & \vars(\langle \varsub{D}{1}, \varsub{D}{2} \rangle) \subseteq
      \vars(\langle \varsub{E}{1}, \varsub{E}{2} \rangle)
    \end{aligned}
$
\end{center}& &  \\  \hline
\end{tabular}.
%\end{center}
\vspace{10pt}

\noindent 
which follows from the \emph{occurs-subset property} of $\vars$,
\[DE_{1} \occurseq DE_{2} \uimplies \vars(DE_{1}) \subseteq \vars(DE_{2}),\]
and the \emph{vars-union property} of tuples, that
\[\vars(\langle DE_{1}, DE_{2}\rangle) =
\vars(DE_{1}) \cup \vars(DE_{2}),\]
taking $DE_{1}$ and $DE_{2}$ each to be $\varsub{D}{1}$ and  $\varsub{D}{2}$, and  $\varsub{E}{1}$ and  $\varsub{E}{2}$, respectively, and properties of sets. Consequently, by two applications of the \emph{resolution rule}, taking $\varsub{D}{1}$ and $\varsub{E}{1}$ to be $\rig(\e{1})$ and $\e{1}$, respectively, and $\varsub{D}{2}$ and $\varsub{E}{2}$ to be $\rig(\e{2})$ and $\e{2}$, respectively, we obtain

\vspace{5pt}
\noindent \begin{tabular}{|m{0.40\textwidth}|m{0.20\textwidth}||m{0.20\textwidth}|}
\hline
\begin{center}$
\begin{aligned}
       & \vars(\langle \rig(\e{1}), \rig(\e{2}) \rangle) \subseteq \\
      &\vars(\langle \e{1}, \e{2} \rangle)
    \end{aligned}
$
\end{center}& &  \\  \hline
\end{tabular}.
%\end{center}
\vspace{10pt}

Similarly, by two applications of the resolution rule to the two case assumptions and the \emph{right property} of the size function, 
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.21\textwidth}||m{0.21\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
    &\boxed{\unot(\isatm(E))} \uimplies \\
    & \size(\rig(E)) < \size(E)
    \end{aligned}
$
\end{center}
& &  \\  \hline
\end{tabular},
\end{center}
taking $\var{E}$ to be $\e{1}$ and $\e{2}$, respectively, we obtain
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.21\textwidth}||m{0.21\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
    & \size(\rig(\e{1})) < \size(\e{1})
    \end{aligned}
$
\end{center}
& &  \\  \hline
\end{tabular}
\end{center}
and
\begin{center}
  \begin{tabular}{|m{0.40\textwidth}|m{0.21\textwidth}||m{0.21\textwidth}|}
\hline
\begin{center}
$
\begin{aligned}
    & \size(\rig(\e{2})) < \size(\e{2})
    \end{aligned}
$
\end{center}
& &  \\  \hline
\end{tabular}.
\end{center}



Similarly, by several applications of the resolution rule to the \

By several applications of the resolution rule to the case assumptions and the properties, taking $\var{E}$ to be $\e{1}$ or $\e{2}$ as appropriate, we obtain 


By repeated application of the resolution rule to the \emph{size-first induction hypothesis}, the \emph{occurrence subset property} of the function \emph{vars},  the \emph{right property} of the occurrence relation, and the \emph{right property} of the size function, taking $\E{1}, \E{2},\E{1}',$ and $\E{2}'$ to be $\e{1}, \e{2}, \rig(\e{1}),$ and $\rig(\e{2})$, respectively, we obtain


  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}
&\left[\begin{aligned}&\unot(\isatm(\e{1}))) \uand \\ 
&\unot(\isatm(\e{2})))\end{aligned}\right] 
\end{aligned}\uimplies \\
 &\left[\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \rig(\e{1}), \rig(\e{2}), \\
    &\unify(\Thet{0}', \rig(\e{1}), \rig(\e{2}))) 
\end{aligned}
\end{aligned}\right] \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center}
\end{comment}

Similarly, applying instead the \emph{left property} of the occurrence relation, the \emph{left property} of the size function, plus resolutions with the \emph{nonatomic assumptions} to the \emph{size induction hypothesis}, we obtain

  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}&\idem(\Thet{0}') \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}', \lef(\e{1}), \lef(\e{2}), \\
    &\unify(\Thet{0}', \lef(\e{1}), \lef(\e{2}))) 
\end{aligned}
\end{aligned} \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular}.
\end{center} 




Applying resolution to this and the \emph{restricted right induction hypothesis},
  \begin{center}
  \begin{tabular}{|m{0.54\textwidth}|m{0.12\textwidth}||m{0.12\textwidth}|}
\hline
\begin{center}
{$\begin{aligned}
 &\begin{aligned}&\boxed{\idem(\Thet{l})} \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{l}, \rig(\e{1}), \rig(\e{2}), \\
    &\unify(\Thet{l}, \rig(\e{1}), \rig(\e{2}))) 
\end{aligned}
\end{aligned} \end{aligned}  $}  \hspace{1cm} 
\end{center}& &  \\  \hline
\end{tabular},
\end{center}
taking $\Thet{l}$  to be $\thet{l}$, we obtain the \emph{right induction hypothesis},
\begin{center}
  \begin{tabular}{|m{0.60\textwidth}|m{0.10\textwidth}||m{0.10\textwidth}|}
  \hline
  \begin{center}
{$\mgiu(\thet{l},\rig(\e{1}),\rig(\e{2}), \uu) $}
 \end{center}  
& & \\
\hline
\end{tabular}.
\end{center}
where $\uu$ is an abbreviation for 
$\unify(\thet{l},\rig(\e{1}),\rig(\e{2}))$, that is, 
\[\begin{aligned}
\unify(
\begin{aligned}
   \unify(\thet{0}, 
  \lef(\e{1}),  
 \lef(\e{2})),
   \end{aligned} 
\rig(\e{1}), 
\rig(\e{2}))
 \end{aligned}. \]

  % Also [because  $\var{z} \occurseq (\var{y} \apply \theta)$], \[\var{z}' \occurseq (\var{y} \apply \theta) \apply \{\var{z} \mapsto \nolinebreak \var{z'} \},\] that is [by the definition of $\thet{z'}$, because $\var{y}$ is in $\dom(\theta)$],   $\var{z}' \occurseq (\var{y} \apply \thet{z'})$.



    
\end{comment}


\begin{comment}
Because there are three inputs, we form them into a triple (3-tuple) which we treat as a single entity.  We can conduct the proof under the induction hypothesis that recursive calls $\unify(\Thet{0}, \E{1}',\E{2}')$ to the program $\unify$ we are in the process of constructing will satisfy the input-output condition  \begin{align*}\begin{aligned}[t] &\idem(\Thet{0}) \uimplies \\ &{\mgiu}(\Thet{0}, \E{1}, \E{2} , \unify(\Thet{0}', \E{1}', \E{2}'))\end{aligned}\end{align*}
for any input triple $\langle \Thet{0}', \E{1}', \E{2}' \rangle$ such that $\langle\Thet{0}', \E{1}', \E{2}'\rangle \expsub{\prec}{U} \langle\thet{0}, \e{1}, \e{2}\rangle.$ (Here $\Thet{0}'$, $\E{1}'$, $\E{2}'$, and $\var{U}$, as well as $\Theta,$ are variables.)  We add this induction hypothesis to the initial tableau as an assertion.

    



\noindent 


  \begin{center}
  \begin{tabular}{T}
%\begin{tabularx} {\linewidth}{| Y | c || c |}
\hline
\begin{center}
{$\begin{aligned}
&\langle\Thet{0}', \E{1}', \E{2}'\rangle \expsub{\prec}{U}  \langle\thet{0}, \e{1}, \e{2}\rangle \uimplies \\
&\left[\begin{aligned}&\idem(\Thet{0}) \uimplies \\
 &\begin{aligned}
    {\,\mgiu}(&\Thet{0}, \E{1}, \E{2}, \\
    &\unify(\Thet{0}', \E{1}', \E{2}')) 
\end{aligned}
\end{aligned}\right]\end{aligned}$} \hspace{1cm} 
\end{center}& &  \\  \hline
%\end{tabularx}
\end{tabular}.
\end{center}

\end{comment}
\begin{comment}
Our initial goal was 
\begin{center}
\begin{tabularx}{1.0\textwidth} { 
  | >{\raggedright\arraybackslash}X 
  | >{\raggedright\arraybackslash}X 
  || >{\raggedright\arraybackslash}X | }
 \hline 
  & \begin{center}\vspace{-.5cm}$\begin{aligned}[t] &\idem(\thet{0}) \uimplies \\  &\,{\mgiu}(\thet{0}, \e{1}, \e{2} , \Theta) \\ \end{aligned}$\end{center}  & \vspace{-.3cm}\begin{center}$\Theta$ \end{center} \\
\hline
\end{tabularx}.
\end{center}
\end{comment}
 \begin{comment}
     
 
\subsubsection{Most-General Idempotent Unifiers.} A substitution $\theta$ is a \emph{most-general idem\-potent unifier} of two expressions $\e{1}$ and $\e{2}$ if $\theta$ is is a unifier and $\theta$ is more-general idempotent than any unifier $\theta'$; that is, if
\vspace*{-.4cm}

 
\begin{alignat*}{1}
 &\e{1} \apply \theta = \e{2} \apply \theta \, \uand \\
 &(\forall \theta') \left[{
 \begin {aligned} &\e{1} \apply \theta' = \e{2} \apply \theta' \, \uimplies\\
                    &\theta \moregen \theta'
   \end{aligned}}
   \right] \end{alignat*} 

   
\noindent For example, $\{\var{X} \mapsto \var{Y}\}$ is a most-general idempotent unifier of $\var{X}$ and $\var{Y}$, and so is 
   $\{\var{Y} \mapsto \var{X}\}$;  even most-general idempotent unifiers are not unique.  


  The definition implies that (as we might expect) a most-general idempotent unifier is indeed idempotent.  To see this, take $\theta'$ in the definition to be $\theta$ itself; we can conclude that $\theta \moregen \theta$, that is, $\theta$ is idempotent.



A substitution $\theta$ is a \emph{unifier of two expressions} $\e{1}$ and $\e{2}$ \emph{with respect to an environment substitution} $\thet{0}$ if $\theta$ is a unifier of the expressions and an extension of the environment. For example, the substitution $\{\var{X} \mapsto a, \var{Y} \mapsto b\}$ is a unifier of $(\var{X} \cons b)$ and $(a \cons \var{Y})$ with respect to the environment $\{\var{X} \mapsto a\}$, but not with respect to the environment $\{\var{X} \mapsto c\}$, because $\{\var{X} \mapsto a, \var{Y} \mapsto b\}$ is an extension of $\{\var{X} \mapsto a\}$ but not of $\{\var{X} \mapsto c\}$.

The substitution $\theta$ is a \emph{most-general idempotent unifier of two expressions $\e{1}$ and $\e{2}$ relative to an environment} $\thet{0}$ if $\theta$ is a unifier relative to $\thet{0}$ and $\theta$ is more-general idempotent than any unifier $\theta'$ relative to $\thet{0}$; that is, if
\begin{align*}
%\begin{alignat*}{1}
 &\e{1} \apply \theta = \e{2} \apply \theta \, \uand \\
 &\thet{0} \moregen \theta \, \uand \\
 &(\forall \theta') \left[{
 \begin {aligned} &\e{1} \apply \theta' = \e{2} \apply \theta' \, \uand
  \
  \,\thet{0} \moregen \theta' \,\uimplies \\
                    &\theta \moregen \theta'
   \end{aligned}}
   \right] \end{align*}


  
\noindent It is easy to see that the definition implies the reflexive lexicographic property, because $\expsub{g}{1}(\var{x}) = \expsub{g}{1}(\var{y})$ implies $\expsub{g}{1}(\var{x})\, \expsub{\preccurlyeq}{\expsub{w}{1}} \, \expsub{g}{1}(\var{y})$. 
  In the other direction, if the right side of the reflexive lexicographic property holds and the first disjunct $\expsub{g}{1}(\var{x}) \expsub{\prec}{\expsub{w}{1}} \, \expsub{g}{1}(\var{y})$ is true, then  the right side of the definition holds.
  But suppose the right side of the reflexive lexicographic property holds but the first disjunct $\expsub{g}{1}(\var{x}) \expsub{\prec}{\expsub{w}{1}} \, \expsub{g}{1}(\var{y})$ is false;  then the second disjunct \[[\expsub{g}{1}(\var{x}) \expsub{\preccurlyeq}{\expsub{w}{1}} \, \expsub{g}{1}(\var{y}) \uand
  \varsub{x}{2} \expsub{\prec}{\expsub{w}{2}} \, \expsub{g}{2}(\var{y})]\] is true and hence [because $\expsub{g}{1}(\var{x}) \expsub{\prec}{\expsub{w}{1}} \, \expsub{g}{1}(\var{y})$ is false]
  \[ [\expsub{g}{1}(\var{x}) = \expsub{g}{1}(\var{y}) \uand \varsub{x}{2} \expsub{\prec}{\expsub{w}{2}} \, \expsub{g}{2}(\var{y})]. \]
  But that is the right side of the definition.
 \end{comment}
 \begin{comment}
\subsubsection{Lexicographic Combination of Well-Founded Relations.} If $\expsub{\prec}{\expsub{w}{1}}$ and $\expsub{\prec}{\expsub{w}{2}}$ are both well-founded relations, so is their lexicographic combination \[{\lex(\expsub{g}{1}(\expsub{w}{1}),\, \expsub{g}{2}(\expsub{w}{2}))}.\]  For suppose, to the contrary, there is an infinite decreasing sequence $\{\expsub{a}{0}, \expsub{a}{1}, \expsub{a}{2},\allowbreak \ldots \}$, that is, one such that
  \[\expsub{a}{0}\, \expsub{\succ}{\lex(\expsub{g}{1}(\expsub{w}{1}),\, \expsub{g}{2}(\expsub{w}{2}))} \, \expsub{a}{1}\, \allowbreak \expsub{\succ}{\lex(\expsub{g}{1}(\expsub{w}{1}),\, \expsub{g}{2}(\expsub{w}{2}))} \,\allowbreak \expsub{a}{2} \, \expsub{\succ}{\lex(\expsub{g}{1}(\expsub{w}{1}),\, \expsub{g}{2}(\expsub{w}{2}))} \,\ldots .\]  By the definition of the lexicographic combination, we know that, for each natural number $i$, we have either
   \begin{align*}
       & \expsub{g}{1}(\expsub{a}{i}) \, \expsub{\succ}{\expsub{w}{1}} \, \expsub{g}{1}(\expsub{a}{i+1}) \uor  && [\textit{the $\expsub{\prec}{\expsub{w}{1}}$ case for $i$}]\\ 
       & \expsub{g}{1}(\expsub{a}{i}) = \expsub{g}{1}(\expsub{a}{i+1})  \uand
  \expsub{g}{2}(\expsub{a}{i}) \expsub{\succ}{\expsub{w}{2}} \, \expsub{g}{2}(\expsub{a}{i+1})  && [\textit{the $\expsub{\prec}{\expsub{w}{2}}$ case for $i$}].
   \end{align*}
   \noindent In either case, we have $\expsub{g}{1}(\expsub{a}{i}) \,\expsub{\succcurlyeq}{\expsub{w}{1}} \, \expsub{g}{1}(\expsub{a}{i+1})$ for each natural number $i$.  But since $\expsub{\prec}{\expsub{w}{1}}$ is well-founded, we know (from the \emph{weakly-decreasing sequence property}) that the sequence cannot weakly decrease indefinitely and hence must converge at some natural number $j$; thus for each $k$ such that $k \geq j,$ we have $\expsub{g}{1}(\expsub{a}{k})  =  \expsub{g}{1}(\expsub{a}{k+1}).$   But then (by the irreflexivity of well-founded relations), for each $k$ such that $k \geq j,$ the  $\expsub{\prec}{\expsub{w}{1}}$ case for $k$ cannot hold, and therefore the $\expsub{\prec}{\expsub{w}{2}}$ case for $k$ must hold.
   Hence, for each $k$ such that $k \geq j,$ we have $\expsub{g}{2}(\expsub{a}{k}) \expsub{\succ}{\expsub{w}{2}} \, \expsub{g}{2}(\expsub{a}{k+1}),$ but this contradicts the well-foundedness of $\expsub{\prec}{\expsub{w}{2}}$.  Thus no decreasing sequence of pairs can exist under the lexicographic combination, so the lexicographic combination must be well-founded.
   \end{comment}
   \begin{comment}
   \subsubsection{Conventional Lexicographic Relation.}  The more conventional lexicographic combination of relations is between two tuples, obtained (for pairs, for instance) by taking $\expsub{g}{1}$ and $\expsub{g}{2}$ to be $\ufirst$ and $\usecond$. respectively.  Recall that
\[\quad \ufirst(\langle \x{1}, \x{2} \rangle)  = \x{1} \] 
\noindent and 
\[\usecond(\langle \x{1}, \x{2} \rangle)  =  \x{2}.\]
Then, we have 
\begin{alignat*}{2}
  \begin{split}
  &\langle \x{1}, \x{2} \rangle \, \expsub{\prec}{\lex(\ufirst(\expsub{w}{1}),\, \usecond(\expsub{w}{2}))}\, \langle \y{1}, \y{2} \rangle
  \uiff \\
  &\left(\begin{aligned}
  &\ufirst(\langle \x{1}, \x{2} \rangle)\, \expsub{\prec}{\expsub{w}{1}} \, \ufirst(\langle \y{1}, \y{2} \rangle) \, \uor \, \\
  & \left(\begin{aligned}
  \ufirst(\langle \x{1}, \x{2} \rangle) &= \ufirst(\langle \y{1}, \y{2} \rangle) \uand \\
  \usecond(\langle \x{1}, \x{2} \rangle)  & \, \expsub{\prec}{\expsub{w}{2}} \, \usecond(\langle \y{1}, \y{2} \rangle) 
  \end{aligned}\right)
  \end{aligned}\right),
  \end{split}
\end{alignat*} 
   that is,
\begin{alignat*}{2}
  \begin{split}
  &\langle \x{1}, \x{2} \rangle \, \expsub{\prec}{\lex(\ufirst(\expsub{w}{1}),\, \usecond(\expsub{w}{2}))}\, \langle \y{1}, \y{2} \rangle
  \uiff \\
  &\left(\begin{aligned}
  &\x{1} \expsub{\prec}{\expsub{w}{1}} \, \y{1}\, \uor \, \\
  &\x{1} = \y{1}\uand
  \x{2} \expsub{\prec}{\expsub{w}{2}} \, \y{2} 
  \end{aligned}\right).
  \end{split}
\end{alignat*} 
But for the unification derivation we use the more general form of the lexicographic relation.
 \end{comment}
